{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this notebook covers how to compute the logprobs / token probabilites and the perplexity when using langchain with huggingface\n",
    "- as the return of the necessary outputs (i.e. logits) is not possible out of the box, some langchain and huggingface methods need to be overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 1024,\n",
      "  \"output_hidden_states\": [\n",
      "    true\n",
      "  ],\n",
      "  \"output_logits\": [\n",
      "    true\n",
      "  ],\n",
      "  \"output_scores\": [\n",
      "    true\n",
      "  ],\n",
      "  \"repetition_penalty\": 1.2,\n",
      "  \"return_dict_in_generate\": [\n",
      "    true\n",
      "  ],\n",
      "  \"temperature\": 0.0001,\n",
      "  \"top_p\": 0\n",
      "}\n",
      "\n",
      "[{'logits': (tensor([[-422.0000,    0.4844,    2.5625,  ...,   -5.5000,   -4.0000,\n",
      "           -3.5625]]), tensor([[-302.0000,   -6.4062,   -0.3145,  ...,   -5.9688,   -4.7188,\n",
      "           -6.5312]]), tensor([[-239.0000,   -8.5000,    3.4531,  ...,   -7.2812,   -8.3125,\n",
      "           -6.4062]]), tensor([[-258.0000,   -8.3125,    4.4688,  ...,   -7.0625,   -7.7188,\n",
      "           -7.4688]]), tensor([[-274.0000,   -7.5312,    2.7344,  ...,   -7.6875,   -7.5625,\n",
      "           -7.2500]]), tensor([[-298.0000,   -8.1250,    3.2031,  ...,   -6.8438,   -8.0625,\n",
      "           -7.5625]]), tensor([[-213.0000,   -9.5625,    3.4688,  ...,   -6.5312,   -8.6875,\n",
      "           -7.6250]]), tensor([[-254.0000,   -9.0000,    4.2500,  ...,   -7.2812,   -8.4375,\n",
      "           -9.3125]]), tensor([[-179.0000,   -8.2500,    2.2031,  ...,   -4.8438,   -6.1562,\n",
      "           -7.0312]]), tensor([[-306.0000,   -6.9062,    2.4219,  ...,   -5.3750,   -5.3125,\n",
      "           -5.6875]]), tensor([[-2.6800e+02, -6.7500e+00,  2.4609e-01,  ..., -4.5625e+00,\n",
      "         -4.8125e+00, -5.5000e+00]]), tensor([[-226.0000,   -8.4375,    1.9062,  ...,   -7.5625,   -9.6250,\n",
      "           -6.7812]]), tensor([[-200.0000,   -7.6250,    1.6094,  ...,   -4.5000,   -6.1250,\n",
      "           -6.0625]]), tensor([[-126.0000,   -5.9688,    5.4375,  ...,   -3.0312,   -4.2188,\n",
      "           -2.8125]]), tensor([[-106.5000,   -6.7188,    5.0312,  ...,   -1.2812,   -7.0625,\n",
      "           -5.6875]]), tensor([[-37.7500, -10.8750,   5.1875,  ...,  -9.0000,  -9.1250,  -7.1562]]), tensor([[-282.0000,   -8.6250,    3.4375,  ...,   -8.4375,  -10.3750,\n",
      "           -7.3438]]), tensor([[-328.0000,   -9.4375,    6.4375,  ...,   -8.8750,   -9.9375,\n",
      "           -7.9688]]), tensor([[-426.0000,   -6.2500,    6.0312,  ...,   -7.5938,   -6.8750,\n",
      "           -7.1562]]), tensor([[-412.0000,   -5.8750,    4.0000,  ...,   -6.7812,   -6.8125,\n",
      "           -6.5938]]), tensor([[-384.0000,   -7.1250,    3.7812,  ...,   -8.0000,   -9.3125,\n",
      "           -6.4688]]), tensor([[-228.0000,   -7.6562,    3.0938,  ...,   -7.7500,   -5.6875,\n",
      "           -5.8438]]), tensor([[-262.0000,   -8.3125,    4.4062,  ...,   -7.3438,   -8.9375,\n",
      "           -7.6875]]), tensor([[-253.0000,   -7.1562,    4.4062,  ...,   -7.4375,   -7.9375,\n",
      "           -6.6250]]), tensor([[-198.0000,   -7.5938,    4.2812,  ...,   -7.5000,   -7.3750,\n",
      "           -5.3125]]), tensor([[-193.0000,   -8.3125,    3.6719,  ...,   -7.9062,   -7.1875,\n",
      "           -6.3438]]), tensor([[-109.5000,   -4.5312,    2.1094,  ...,   -2.0469,   -2.8594,\n",
      "           -2.5469]]), tensor([[-163.0000,   -9.4375,    6.6562,  ...,   -9.0625,   -8.3750,\n",
      "           -7.0312]]), tensor([[-252.0000,   -7.9062,    6.5312,  ...,   -8.8125,   -8.5625,\n",
      "           -7.8438]]), tensor([[-238.0000,   -8.8750,    6.9688,  ...,   -6.5938,   -8.7500,\n",
      "           -7.4062]]), tensor([[-167.0000,   -6.2188,    6.3438,  ...,   -4.7500,   -4.9375,\n",
      "           -5.8750]]), tensor([[-140.0000,   -9.7500,    6.8750,  ...,   -7.3438,   -6.7500,\n",
      "           -7.2812]]), tensor([[-204.0000,   -9.5625,    6.3438,  ...,   -9.1250,   -7.6562,\n",
      "           -6.9375]]), tensor([[-374.0000,   -5.5000,    5.9688,  ...,   -9.0000,   -7.6875,\n",
      "           -7.1250]]), tensor([[-470.0000,   -5.4688,    6.3750,  ...,   -5.2188,   -6.8750,\n",
      "           -5.1250]]), tensor([[-380.0000,   -6.9062,    4.1250,  ...,   -4.8125,   -6.3438,\n",
      "           -4.9062]]), tensor([[-278.0000,   -8.6875,    6.4062,  ...,   -7.4062,   -7.1562,\n",
      "           -7.4375]]), tensor([[-226.0000,   -7.5625,    5.0938,  ...,   -7.4062,   -6.8438,\n",
      "           -7.0938]]), tensor([[-344.0000,   -7.1875,    7.2500,  ...,   -5.3750,   -9.8125,\n",
      "           -8.1875]]), tensor([[-248.0000,   -7.0938,    6.3750,  ...,   -6.7500,   -8.6250,\n",
      "           -8.0000]]), tensor([[-264.0000,   -7.7812,    6.6250,  ...,   -9.0000,   -7.2500,\n",
      "           -5.2812]]), tensor([[-448.0000,   -6.4688,    4.8750,  ...,   -6.0938,   -5.9062,\n",
      "           -6.0625]]), tensor([[-358.0000,   -7.0938,    4.5000,  ...,   -6.5000,   -7.3125,\n",
      "           -6.6875]]), tensor([[-151.0000,   -4.8438,    5.1875,  ...,   -4.6875,   -4.0938,\n",
      "           -5.0000]]), tensor([[-368.0000,   -6.3438,    4.0938,  ...,   -5.5625,   -6.9062,\n",
      "           -6.4375]]), tensor([[-4.1000e+02, -4.4375e+00,  2.3594e+00,  ..., -2.5156e+00,\n",
      "         -2.9883e-01, -2.0000e+00]]), tensor([[-145.0000,   -4.9688,    5.6875,  ...,   -7.1875,   -4.1562,\n",
      "           -4.3438]]), tensor([[-388.0000,   -4.2812,    3.6250,  ...,   -5.4688,   -4.1250,\n",
      "           -6.1250]]), tensor([[-177.0000,   -5.2188,    2.4688,  ...,   -4.8125,   -4.1250,\n",
      "           -4.2812]]), tensor([[-282.0000,   -8.9375,    2.4219,  ...,   -9.3125,   -6.1562,\n",
      "           -6.1562]]), tensor([[-394.0000,   -7.6250,    1.0859,  ...,   -7.6250,   -7.3438,\n",
      "           -7.0938]]), tensor([[-386.0000,   -4.9062,    5.3750,  ...,   -6.7500,   -6.0000,\n",
      "           -6.0938]]), tensor([[-284.0000,   -6.7188,    2.7188,  ...,   -6.4062,   -7.3438,\n",
      "           -4.9375]]), tensor([[-244.0000,   -6.7500,    3.9219,  ...,   -5.1875,   -8.0000,\n",
      "           -6.3125]]), tensor([[-236.0000,   -7.2188,    7.7188,  ...,   -9.0625,   -8.0000,\n",
      "           -7.2500]]), tensor([[-346.0000,   -6.6250,    3.5156,  ...,   -5.5312,   -6.0625,\n",
      "           -5.8438]]), tensor([[-196.0000,   -6.5625,    4.0938,  ...,   -5.5312,   -4.5938,\n",
      "           -6.0000]]), tensor([[-282.0000,   -6.7812,    4.3438,  ...,   -6.9375,   -7.6875,\n",
      "           -5.6875]]), tensor([[-180.0000,   -7.9688,    3.8906,  ...,   -5.9688,   -6.1562,\n",
      "           -3.5312]]), tensor([[-288.0000,   -7.2500,    7.9062,  ...,   -5.0000,   -8.8125,\n",
      "           -7.8438]]), tensor([[-241.0000,   -7.8438,    7.7500,  ...,   -5.2500,   -8.1250,\n",
      "           -6.7500]]), tensor([[-292.0000,   -7.6250,    5.8438,  ...,   -8.1250,   -8.2500,\n",
      "           -7.6250]]), tensor([[-268.0000,   -8.1250,    6.0625,  ...,   -7.2500,   -7.3125,\n",
      "           -5.0000]]), tensor([[-199.0000,   -9.5625,    9.6875,  ...,   -8.7500,   -8.8750,\n",
      "           -6.5938]]), tensor([[-310.0000,   -7.2812,    5.9062,  ...,   -8.8750,   -7.6250,\n",
      "           -4.2812]]), tensor([[-528.0000,   -4.1875,    7.0625,  ...,   -5.8750,   -6.3438,\n",
      "           -5.5938]]), tensor([[-440.0000,   -4.1875,    4.1562,  ...,   -3.7031,   -3.7812,\n",
      "           -3.7188]]), tensor([[-470.0000,   -3.8906,    2.4375,  ...,   -2.1094,   -3.1250,\n",
      "           -1.9141]]), tensor([[-378.0000,   -6.3750,    1.8516,  ...,   -5.5938,   -5.4375,\n",
      "           -5.0938]]), tensor([[-308.0000,   -6.6250,    3.0625,  ...,   -5.3125,   -9.1250,\n",
      "           -7.0000]]), tensor([[-410.0000,   -5.9062,    5.5625,  ...,   -4.7500,   -6.5938,\n",
      "           -6.2188]]), tensor([[-564.0000,   -3.3906,    6.7500,  ...,   -6.3438,   -5.9375,\n",
      "           -6.8125]]), tensor([[-236.0000,   -2.5000,    2.9844,  ...,   -1.5234,   -4.8125,\n",
      "           -4.6562]]), tensor([[-187.0000,   -7.7500,    5.1250,  ...,   -6.0625,   -7.0000,\n",
      "           -7.2188]]), tensor([[-136.0000,    0.8477,    2.9688,  ...,   -0.3145,   -2.2500,\n",
      "            0.3867]]), tensor([[-358.0000,   -4.3438,    4.4062,  ...,   -3.4219,   -5.9062,\n",
      "           -4.2188]]), tensor([[-612.0000,   -6.5312,    2.9844,  ...,   -7.8438,   -6.2500,\n",
      "           -6.3125]]), tensor([[-430.0000,   -6.9375,    1.9375,  ...,   -3.5312,   -4.0938,\n",
      "           -3.8438]]), tensor([[-472.0000,   -8.1875,    3.4688,  ...,   -7.3125,   -7.0312,\n",
      "           -4.1562]]), tensor([[-6.4800e+02, -5.6875e+00, -2.2339e-02,  ..., -8.7500e+00,\n",
      "         -6.9062e+00, -4.7812e+00]]), tensor([[-4.4600e+02, -6.8125e+00, -1.9238e-01,  ..., -6.3125e+00,\n",
      "         -7.2188e+00, -4.3750e+00]]), tensor([[-4.6000e+02, -7.4062e+00, -1.5820e-01,  ..., -5.6250e+00,\n",
      "         -6.8438e+00, -6.3438e+00]]), tensor([[-160.0000,   -2.7031,    1.5469,  ...,   -2.7656,   -2.1719,\n",
      "           -3.0000]]), tensor([[-189.0000,   -5.9688,    0.9727,  ...,   -5.2812,   -4.6562,\n",
      "           -5.3125]]), tensor([[-286.0000,   -6.0312,    0.9180,  ...,   -7.3750,   -5.9375,\n",
      "           -4.4688]]), tensor([[-3.8600e+02, -6.5000e+00,  3.8281e-01,  ..., -7.8125e+00,\n",
      "         -5.4688e+00, -5.5625e+00]]), tensor([[-424.0000,   -5.7500,    0.7461,  ...,   -7.8438,   -6.0312,\n",
      "           -4.8125]]), tensor([[-368.0000,   -5.7812,    0.9219,  ...,   -5.7500,   -6.3125,\n",
      "           -2.5781]]), tensor([[-308.0000,   -2.9375,    0.3359,  ...,   -4.3125,   -3.6719,\n",
      "           -3.1875]]), tensor([[-237.0000,   -2.8906,    2.3750,  ...,   -4.0938,   -4.5312,\n",
      "           -3.1094]]), tensor([[-206.0000,   -8.0625,    3.6250,  ...,   -8.6875,   -7.7188,\n",
      "           -6.2812]]), tensor([[-209.0000,   -7.6562,    2.3281,  ...,   -8.6250,   -4.8750,\n",
      "           -5.6562]]), tensor([[-416.0000,   -3.8125,   -0.6484,  ...,   -6.2500,   -4.5938,\n",
      "           -4.7812]]), tensor([[-4.3200e+02, -4.5000e+00,  9.5367e-04,  ..., -6.0625e+00,\n",
      "         -6.8125e+00, -5.4062e+00]]), tensor([[-8.9000e+01, -5.2734e-01, -5.2979e-02,  ..., -2.1406e+00,\n",
      "          5.1953e-01, -4.3640e-03]]), tensor([[-233.0000,    0.7031,    2.3906,  ...,   -1.5703,   -1.5156,\n",
      "           -1.4375]]), tensor([[-280.0000,   -7.0000,    2.4688,  ...,   -6.8125,   -6.7188,\n",
      "           -6.2812]]), tensor([[-4.5800e+02, -7.0000e+00,  2.9883e-01,  ..., -7.0625e+00,\n",
      "         -5.9688e+00, -5.8125e+00]]), tensor([[-296.0000,   -6.3438,    5.2188,  ...,   -5.9062,   -5.4375,\n",
      "           -3.3438]]), tensor([[-358.0000,   -5.4375,    0.5469,  ...,   -4.5312,   -1.5625,\n",
      "           -2.9062]]), tensor([[-171.0000,   -3.0469,    0.3477,  ...,   -2.9844,   -4.1250,\n",
      "           -3.7969]]), tensor([[-180.0000,   -3.7188,    1.3125,  ...,   -5.0938,   -1.0781,\n",
      "           -3.3750]]), tensor([[-203.0000,   -6.2812,    1.3203,  ...,   -4.1875,   -2.5781,\n",
      "           -5.5000]]), tensor([[-274.0000,   -8.1875,    0.9844,  ...,   -6.9375,   -5.2812,\n",
      "           -6.4688]]), tensor([[-440.0000,   -3.0469,   -1.1953,  ...,   -5.7188,   -5.1562,\n",
      "           -4.8750]]), tensor([[-222.0000,   -3.5469,    1.7734,  ...,   -4.0625,   -3.6094,\n",
      "           -5.4688]]), tensor([[-456.0000,   -6.2188,    0.4805,  ...,   -7.9375,   -5.8750,\n",
      "           -6.0625]]), tensor([[-536.0000,   -4.8125,    0.9414,  ...,   -4.1875,   -3.3906,\n",
      "           -4.7188]]), tensor([[-406.0000,   -6.1875,    1.0391,  ...,   -4.9062,   -6.0312,\n",
      "           -3.8594]]), tensor([[-498.0000,   -6.8125,    1.5469,  ...,   -6.1250,   -7.6875,\n",
      "           -4.4062]]), tensor([[-262.0000,   -4.7812,    2.1250,  ...,   -6.5000,   -5.3125,\n",
      "           -4.2812]]), tensor([[-330.0000,   -2.1719,    1.2188,  ...,   -4.9688,   -4.4688,\n",
      "           -1.8281]]), tensor([[-466.0000,   -6.7188,    2.4375,  ...,   -6.4062,   -6.1562,\n",
      "           -5.6875]]), tensor([[-352.0000,   -6.8750,    1.3281,  ...,   -5.2500,   -7.0625,\n",
      "           -6.4062]]), tensor([[-3.8200e+02, -7.5625e+00,  2.0996e-01,  ..., -6.4688e+00,\n",
      "         -7.3750e+00, -5.5938e+00]]), tensor([[-312.0000,   -7.2188,    1.9062,  ...,   -7.1562,   -2.7031,\n",
      "           -6.3750]]), tensor([[-416.0000,   -5.8750,    1.3281,  ...,   -4.7500,   -5.1250,\n",
      "           -5.4062]]), tensor([[-262.0000,   -3.5000,    1.5469,  ...,   -5.1250,   -4.8438,\n",
      "           -5.7812]]), tensor([[-77.0000,  -2.8438,   2.3438,  ...,  -8.5000,  -3.9219,  -4.5625]]), tensor([[-245.0000,   -8.5000,    2.9688,  ...,   -9.9375,   -7.1562,\n",
      "           -6.1875]]), tensor([[-524.0000,   -5.5000,    1.9297,  ...,   -5.3750,   -5.4375,\n",
      "           -5.5000]]), tensor([[-123.5000,   -2.8281,    2.2188,  ...,   -6.2500,   -4.0938,\n",
      "           -2.0781]]), tensor([[-214.0000,   -0.9414,    1.0391,  ...,   -3.1719,   -2.7031,\n",
      "           -2.5625]]), tensor([[-215.0000,   -8.1875,    1.7266,  ...,   -9.5625,   -8.1250,\n",
      "           -7.1562]]), tensor([[-5.1600e+02, -4.5312e+00,  2.1777e-01,  ..., -5.3750e+00,\n",
      "         -6.0625e+00, -5.8125e+00]]), tensor([[-312.0000,   -4.5625,    0.9297,  ...,   -5.2500,   -4.6562,\n",
      "           -5.7188]]), tensor([[-260.0000,   -6.2188,    2.8438,  ...,   -4.6875,   -7.5625,\n",
      "           -7.9062]]), tensor([[-376.0000,   -4.9375,    3.0000,  ...,   -4.0312,   -4.5312,\n",
      "           -4.5312]]), tensor([[-228.0000,   -9.1875,    3.9219,  ...,  -12.0625,   -7.5312,\n",
      "           -6.9375]]), tensor([[-4.4400e+02, -7.0625e+00, -3.9258e-01,  ..., -7.2188e+00,\n",
      "         -4.9688e+00, -6.6875e+00]]), tensor([[-4.8600e+02, -5.5312e+00, -1.9238e-01,  ..., -5.3438e+00,\n",
      "         -5.0938e+00, -4.0625e+00]]), tensor([[-4.3200e+02, -5.1562e+00,  8.6914e-02,  ..., -4.5000e+00,\n",
      "         -4.9688e+00, -4.4062e+00]]), tensor([[-117.0000,   -5.0312,    2.2812,  ...,   -7.3125,   -4.4688,\n",
      "           -4.5312]]), tensor([[-189.0000,   -6.0312,    2.3281,  ...,   -7.0625,   -5.6250,\n",
      "           -4.8125]]), tensor([[-254.0000,   -7.3438,    2.2656,  ...,   -9.1875,   -4.3125,\n",
      "           -6.0938]]), tensor([[-3.7800e+02, -7.4062e+00, -4.4189e-02,  ..., -6.4062e+00,\n",
      "         -6.0000e+00, -4.3438e+00]]), tensor([[-4.9800e+02, -5.6875e+00, -5.8838e-02,  ..., -5.1562e+00,\n",
      "         -5.8125e+00, -6.6875e+00]]), tensor([[-140.0000,   -4.5000,    1.5234,  ...,   -4.7500,   -2.1719,\n",
      "           -2.8438]]), tensor([[-304.0000,   -0.5938,    1.8047,  ...,   -2.3281,   -2.6719,\n",
      "           -2.4844]]), tensor([[-266.0000,   -6.5938,    2.0156,  ...,   -6.8125,   -5.5625,\n",
      "           -5.6875]]), tensor([[-5.0000e+02, -7.2500e+00,  4.4141e-01,  ..., -6.9688e+00,\n",
      "         -6.1250e+00, -6.4375e+00]]), tensor([[-284.0000,   -5.6875,    2.9375,  ...,   -6.1562,   -5.3125,\n",
      "           -6.5938]]), tensor([[-208.0000,   -7.5312,    1.9922,  ...,   -7.5000,   -3.1094,\n",
      "           -5.5312]]), tensor([[-342.0000,   -6.0312,    2.6250,  ...,   -5.1250,   -5.5938,\n",
      "           -6.0938]]), tensor([[-422.0000,   -6.3438,    2.3906,  ...,   -5.1875,   -6.1562,\n",
      "           -6.5312]]), tensor([[-468.0000,   -5.5312,    2.5000,  ...,   -5.4375,   -6.0625,\n",
      "           -4.7188]]), tensor([[-214.0000,   -4.3750,    3.5312,  ...,   -2.2344,   -3.8594,\n",
      "           -3.5156]]), tensor([[-256.0000,   -2.8438,    1.9141,  ...,   -1.6875,   -0.4531,\n",
      "           -0.7148]]), tensor([[-206.0000,   -4.6250,    2.5625,  ...,   -5.4062,   -4.3750,\n",
      "           -3.3438]]), tensor([[-192.0000,   -4.8125,    1.2031,  ...,   -5.3438,   -5.0000,\n",
      "           -4.8750]]), tensor([[-247.0000,   -7.1562,    2.9062,  ...,   -7.3438,   -4.4688,\n",
      "           -5.4688]]), tensor([[-348.0000,   -6.6250,    3.8125,  ...,   -3.5781,   -4.9062,\n",
      "           -6.0938]]), tensor([[-440.0000,   -7.3125,    2.0469,  ...,   -3.8906,   -5.1562,\n",
      "           -5.5938]]), tensor([[-368.0000,   -6.4375,    2.5938,  ...,   -7.4688,   -5.4062,\n",
      "           -4.8438]]), tensor([[-172.0000,   -5.4062,    2.1094,  ...,   -5.5625,   -5.7188,\n",
      "           -4.0938]]), tensor([[-228.0000,   -6.5000,    2.4688,  ...,   -5.8750,   -5.5938,\n",
      "           -5.8750]]), tensor([[-282.0000,   -7.6562,    1.8906,  ...,   -6.8125,   -5.4688,\n",
      "           -6.5625]]), tensor([[-382.0000,   -6.0312,    1.0547,  ...,   -5.5625,   -5.9062,\n",
      "           -6.4375]]), tensor([[-396.0000,   -5.0312,    0.5898,  ...,   -6.3438,   -5.8438,\n",
      "           -3.5469]]), tensor([[-107.0000,   -0.3184,    1.1953,  ...,   -0.9648,   -0.6680,\n",
      "           -1.2812]]), tensor([[-198.0000,   -0.5430,    1.7656,  ...,   -0.9922,    4.2188,\n",
      "           -1.5703]]), tensor([[-208.0000,   -3.2188,    2.2656,  ...,   -4.6875,   -3.4219,\n",
      "           -4.3750]]), tensor([[-256.0000,   -7.1875,    1.7891,  ...,   -6.9062,   -7.2500,\n",
      "           -5.6875]]), tensor([[-336.0000,   -6.6562,    1.3906,  ...,   -5.0000,   -6.3750,\n",
      "           -4.7188]]), tensor([[-394.0000,   -5.3125,    0.5000,  ...,   -5.6562,   -5.7812,\n",
      "           -4.3125]]), tensor([[-404.0000,   -4.0312,    0.7266,  ...,   -3.0938,   -5.5625,\n",
      "           -3.4062]]), tensor([[-178.0000,   -4.7812,    1.1797,  ...,   -4.2812,   -2.1406,\n",
      "           -4.2500]]), tensor([[-236.0000,   -9.0000,    3.6250,  ...,  -10.0000,   -7.0625,\n",
      "           -6.9688]]), tensor([[-488.0000,   -5.2188,    1.0078,  ...,   -6.2500,   -5.4688,\n",
      "           -6.0625]]), tensor([[-204.0000,   -5.2812,    2.0625,  ...,   -6.4062,   -4.3125,\n",
      "           -4.0938]]), tensor([[-304.0000,   -1.1953,    2.5781,  ...,   -0.9648,    0.4395,\n",
      "           -0.9648]]), tensor([[-125.0000,   -4.0312,    0.1719,  ...,   -5.5625,   -2.5938,\n",
      "           -0.7656]]), tensor([[-238.0000,   -0.5312,    2.6094,  ...,   -1.7578,   -2.7812,\n",
      "           -1.2109]]), tensor([[-310.0000,   -9.3125,    3.0781,  ...,   -9.5625,   -7.1250,\n",
      "           -6.5938]]), tensor([[-428.0000,   -4.7188,   -1.1328,  ...,   -5.4688,   -5.0625,\n",
      "           -6.9062]]), tensor([[-3.0200e+02,  1.6113e-01, -7.3242e-02,  ..., -2.6250e+00,\n",
      "         -2.3281e+00, -2.5000e+00]]), tensor([[-249.0000,   -6.4688,    3.2500,  ...,   -9.3750,   -6.0625,\n",
      "           -8.0625]]), tensor([[-516.0000,   -4.6875,    1.6719,  ...,   -6.9062,   -5.6562,\n",
      "           -6.3438]]), tensor([[-450.0000,   -2.7500,    8.5625,  ...,   -5.9688,   -6.9062,\n",
      "           -5.1562]]), tensor([[-179.0000,   -6.9375,    5.8438,  ...,   -7.9062,   -6.6562,\n",
      "           -4.4375]]), tensor([[-171.0000,   -6.6562,    5.1562,  ...,   -6.1562,   -4.4688,\n",
      "           -5.0625]]), tensor([[-153.0000,   -2.9062,    6.8125,  ...,   -4.0625,   -5.0312,\n",
      "           -2.1406]]), tensor([[-241.0000,   -4.2188,    5.8750,  ...,   -6.2812,   -6.0000,\n",
      "           -4.1562]]), tensor([[-484.0000,   -5.1562,    8.6875,  ...,   -8.8750,   -6.7500,\n",
      "           -5.9375]]), tensor([[-282.0000,   -6.9062,    3.5156,  ...,   -8.1875,   -7.9375,\n",
      "           -6.8750]]), tensor([[-192.0000,   -8.0000,    7.8125,  ...,   -6.9062,   -6.6562,\n",
      "           -5.7188]]), tensor([[-286.0000,   -7.5938,    6.8438,  ...,   -9.1875,   -7.5938,\n",
      "           -8.7500]]), tensor([[-340.0000,   -6.3125,    4.8750,  ...,   -5.4375,   -6.2500,\n",
      "           -6.8438]]), tensor([[-400.0000,   -6.7500,    7.0938,  ...,   -8.3125,   -8.1250,\n",
      "           -5.9062]]), tensor([[-272.0000,   -5.5312,    6.6250,  ...,   -5.1250,   -4.7500,\n",
      "           -3.2344]]), tensor([[-154.0000,   -8.5625,    7.1875,  ...,   -8.2500,   -7.2188,\n",
      "           -6.1250]]), tensor([[-210.0000,   -9.8750,    8.7500,  ...,   -8.4375,   -8.9375,\n",
      "           -7.7188]]), tensor([[-194.0000,   -8.2500,    7.6250,  ...,   -7.3438,   -8.0625,\n",
      "           -6.0312]]), tensor([[-153.0000,   -8.0625,    8.0000,  ...,   -7.5625,   -7.5938,\n",
      "           -4.8125]]), tensor([[-183.0000,   -8.0000,    6.9688,  ...,   -8.1250,   -7.6562,\n",
      "           -6.7188]]), tensor([[-75.0000,  -4.7812,   2.8125,  ...,  -1.9141,  -2.2969,  -2.2812]]), tensor([[-155.0000,  -10.2500,    9.1250,  ...,  -10.3750,   -8.6875,\n",
      "           -7.4062]]), tensor([[-186.0000,   -8.6250,    7.9062,  ...,   -9.5000,   -8.3125,\n",
      "           -7.4688]]), tensor([[-178.0000,   -8.6875,    6.5625,  ...,   -6.3750,   -7.5625,\n",
      "           -6.5312]]), tensor([[-142.0000,   -9.2500,    6.9375,  ...,   -7.0625,   -6.2812,\n",
      "           -5.0312]]), tensor([[-255.0000,   -9.5000,   10.8750,  ...,   -8.7500,   -8.5000,\n",
      "           -7.0938]]), tensor([[-272.0000,   -9.0000,   10.3750,  ...,   -6.3750,   -9.0625,\n",
      "           -7.6875]]), tensor([[-157.0000,   -5.9062,    7.6250,  ...,   -4.1875,   -4.8125,\n",
      "           -5.9062]]), tensor([[-138.0000,   -9.8125,    7.8438,  ...,   -6.3438,   -6.5000,\n",
      "           -6.5000]]), tensor([[-143.0000,  -11.9375,    8.3750,  ...,   -9.3125,   -7.8750,\n",
      "           -7.8438]]), tensor([[-203.0000,   -7.7188,    6.6250,  ...,   -7.3750,   -6.9062,\n",
      "           -6.9688]]), tensor([[-187.0000,   -8.5000,    6.5000,  ...,   -7.8750,   -5.5938,\n",
      "           -6.3750]]), tensor([[-171.0000,   -7.3750,    4.9688,  ...,   -6.1250,   -4.2188,\n",
      "           -5.4062]]), tensor([[-152.0000,   -7.7500,    6.0312,  ...,   -7.7812,   -4.4062,\n",
      "           -6.1250]]), tensor([[-112.5000,   -9.6875,    7.0625,  ...,   -9.8750,   -7.6875,\n",
      "           -6.4688]]), tensor([[-86.0000,  -7.6250,   3.5781,  ...,  -8.8125,  -5.8438,  -5.4688]]), tensor([[-166.0000,   -9.9375,    5.2500,  ...,   -7.5625,   -5.5938,\n",
      "           -5.3125]]), tensor([[-201.0000,   -9.2500,    8.8125,  ...,   -7.4375,   -6.1250,\n",
      "           -5.6250]]), tensor([[-226.0000,   -9.4375,    5.9688,  ...,   -7.0938,   -4.6875,\n",
      "           -5.0000]]), tensor([[-153.0000,   -9.0625,    3.2969,  ...,   -6.3750,   -4.9375,\n",
      "           -4.1875]]), tensor([[-177.0000,   -9.6875,    6.5625,  ...,   -8.0000,   -6.0000,\n",
      "           -7.3125]]), tensor([[-322.0000,   -9.1875,    8.6875,  ...,   -8.6875,   -6.1875,\n",
      "           -6.4688]]), tensor([[-223.0000,   -6.7812,    7.9375,  ...,   -5.3750,   -5.9375,\n",
      "           -4.0000]]), tensor([[-209.0000,   -8.8750,    7.2812,  ...,   -8.6875,   -7.0000,\n",
      "           -5.5625]]), tensor([[-274.0000,   -9.6875,    9.7500,  ...,   -9.8750,   -6.8438,\n",
      "           -8.8125]]), tensor([[-167.0000,   -7.4688,    5.5625,  ...,   -9.3750,   -6.6562,\n",
      "           -4.5625]]), tensor([[-147.0000,   -7.3750,    5.9688,  ...,   -6.6250,   -6.4375,\n",
      "           -6.5625]]), tensor([[-203.0000,   -7.3125,    7.2500,  ...,   -6.0000,   -8.0000,\n",
      "           -7.7188]]), tensor([[-172.0000,   -6.7812,    6.2812,  ...,   -8.6875,   -6.5625,\n",
      "           -6.5938]]), tensor([[-228.0000,   -8.8125,    8.2500,  ...,  -11.1875,   -8.2500,\n",
      "           -7.3750]]), tensor([[-159.0000,   -7.9062,    4.6250,  ...,   -6.2812,   -6.6250,\n",
      "           -6.5312]]), tensor([[-129.0000,   -7.5312,    5.6562,  ...,   -6.3750,   -5.5000,\n",
      "           -5.7500]]), tensor([[-128.0000,   -8.5625,    6.3438,  ...,   -9.1250,   -6.4688,\n",
      "           -6.1250]]), tensor([[-190.0000,   -8.8750,    7.8125,  ...,   -8.1875,   -6.6875,\n",
      "           -7.3750]]), tensor([[-133.0000,   -7.6562,    5.0625,  ...,   -9.1875,   -6.2812,\n",
      "           -4.7188]]), tensor([[-149.0000,   -7.8438,    4.3125,  ...,   -5.9375,   -6.6875,\n",
      "           -5.7500]]), tensor([[-160.0000,   -8.3125,    5.5000,  ...,   -5.2500,   -6.3125,\n",
      "           -4.7500]]), tensor([[-260.0000,   -9.8125,   10.5000,  ...,   -9.6875,   -6.9062,\n",
      "           -6.5625]]), tensor([[-165.0000,   -9.1875,    5.1250,  ...,   -6.8750,   -8.7500,\n",
      "           -4.3125]]), tensor([[-152.0000,   -9.3750,    9.1250,  ...,   -7.3438,   -8.7500,\n",
      "           -7.0000]]), tensor([[-214.0000,   -8.1250,    8.0625,  ...,   -5.9375,   -6.1875,\n",
      "           -7.2500]]), tensor([[-143.0000,   -8.6250,    6.9688,  ...,   -6.7812,   -8.7500,\n",
      "           -5.8125]]), tensor([[-169.0000,   -8.4375,    9.3125,  ...,   -7.5312,   -8.3125,\n",
      "           -6.7500]]), tensor([[-116.0000,  -10.1250,    7.1562,  ...,   -6.9375,   -8.8125,\n",
      "           -6.1250]]), tensor([[-192.0000,   -9.3750,    8.7500,  ...,   -9.3125,   -9.3750,\n",
      "           -8.2500]]), tensor([[-205.0000,   -7.9688,    8.3750,  ...,   -7.7500,   -7.0312,\n",
      "           -6.9375]]), tensor([[-74.0000,  -8.5000,   5.7188,  ...,  -6.1250,  -9.0625,  -5.0938]]), tensor([[-90.5000,  -4.4062,   3.9219,  ...,  -2.1250,  -3.6094,  -3.3906]]), tensor([[-79.5000,  -8.4375,   7.1875,  ...,  -5.6250,  -7.7812,  -6.0000]]), tensor([[-212.0000,   -7.3750,    7.1562,  ...,   -7.5625,   -6.9062,\n",
      "           -7.3750]]), tensor([[-161.0000,   -7.3750,    4.8438,  ...,   -7.1250,   -7.2812,\n",
      "           -6.3750]]), tensor([[-131.0000,   -6.9688,    5.1875,  ...,   -4.7812,   -5.9688,\n",
      "           -4.9375]]), tensor([[-153.0000,   -8.7500,    6.8125,  ...,   -9.2500,   -5.5938,\n",
      "           -5.2500]]), tensor([[-241.0000,   -7.8438,   10.8125,  ...,   -8.3125,   -7.4375,\n",
      "           -5.2188]]), tensor([[-502.0000,   -4.6250,    9.7500,  ...,   -6.0938,   -7.5938,\n",
      "           -5.5938]]), tensor([[-374.0000,   -4.5312,    4.8125,  ...,   -3.3125,   -3.9375,\n",
      "           -3.7188]]), tensor([[-330.0000,   -4.4062,    4.2188,  ...,   -3.4844,   -3.7812,\n",
      "           -2.0156]]), tensor([[-1.7300e+02,  1.0547e-01,  1.2734e+00,  ...,  2.1094e+00,\n",
      "         -2.7969e+00, -3.2344e+00]]), tensor([[-123.0000,   -1.2422,    3.8125,  ...,   -1.4609,   -1.1797,\n",
      "           -1.1875]]), tensor([[-85.5000,  -2.7812,   1.8906,  ...,  -2.7969,  -5.2500,  -3.7812]]), tensor([[-103.5000,   -2.5000,   -0.1787,  ...,   -4.5625,   -3.1719,\n",
      "           -2.4062]]), tensor([[-476.0000,   -5.9688,    6.1250,  ...,   -7.2188,   -5.7188,\n",
      "           -4.2812]]), tensor([[-220.0000,   -7.4688,    4.6875,  ...,   -5.1250,   -4.3750,\n",
      "           -5.0000]]), tensor([[-194.0000,   -8.4375,    7.2500,  ...,   -7.3125,   -8.1875,\n",
      "           -6.8438]]), tensor([[-161.0000,   -8.8750,    4.5625,  ...,   -7.8438,   -5.3125,\n",
      "           -5.7188]]), tensor([[-196.0000,   -8.3750,    8.5625,  ...,   -7.6875,   -8.5000,\n",
      "           -7.7812]]), tensor([[-200.0000,   -7.8125,    7.1562,  ...,   -7.1875,   -7.3750,\n",
      "           -6.6250]]), tensor([[-200.0000,   -7.9375,    7.0000,  ...,   -7.2188,   -7.1875,\n",
      "           -6.1875]]), tensor([[-171.0000,   -8.3125,    6.4375,  ...,   -6.8438,   -6.8750,\n",
      "           -6.4375]]), tensor([[-286.0000,   -6.3125,    6.0312,  ...,   -5.1875,   -3.9531,\n",
      "           -5.5938]]), tensor([[-162.0000,   -9.0625,    7.5938,  ...,   -8.5000,   -8.1875,\n",
      "           -7.1875]]), tensor([[-248.0000,   -7.5938,    9.5000,  ...,   -8.6250,   -8.6250,\n",
      "           -7.8438]]), tensor([[-230.0000,   -7.6562,    8.3750,  ...,   -6.3125,   -7.7500,\n",
      "           -7.4375]]), tensor([[-148.0000,   -3.5625,    8.0625,  ...,   -3.3125,   -3.6250,\n",
      "           -4.9062]]), tensor([[-131.0000,   -9.0000,    8.3750,  ...,   -6.9375,   -6.1562,\n",
      "           -6.4062]]), tensor([[-108.5000,  -10.2500,    8.3125,  ...,   -8.6875,   -7.4375,\n",
      "           -6.8125]]), tensor([[-229.0000,   -7.0625,    9.6250,  ...,   -8.6250,   -8.6875,\n",
      "           -7.3750]]), tensor([[-207.0000,   -7.8125,    7.8750,  ...,   -8.8750,   -7.2188,\n",
      "           -6.0938]]), tensor([[-203.0000,   -8.3125,    7.0312,  ...,   -7.0625,   -6.5312,\n",
      "           -6.6875]]), tensor([[-208.0000,   -8.5000,    9.1250,  ...,   -8.5000,   -6.3125,\n",
      "           -8.3125]]), tensor([[-195.0000,  -10.1875,   10.5625,  ...,  -10.8125,   -9.8125,\n",
      "           -7.7500]]), tensor([[-167.0000,   -7.6562,    9.5000,  ...,   -8.3750,   -8.5625,\n",
      "           -6.5312]]), tensor([[-194.0000,   -9.5000,    6.9688,  ...,   -8.1250,   -7.7500,\n",
      "           -7.4375]]), tensor([[-211.0000,   -8.3125,   11.7500,  ...,   -7.1875,   -6.6250,\n",
      "           -6.1562]]), tensor([[-232.0000,  -10.4375,    7.6875,  ...,   -7.7188,   -5.4688,\n",
      "           -6.6250]]), tensor([[-169.0000,  -10.5625,    6.7812,  ...,   -7.2500,   -6.4375,\n",
      "           -6.0625]]), tensor([[-209.0000,   -9.2500,   10.2500,  ...,   -7.4062,   -7.3750,\n",
      "           -7.3750]]), tensor([[-322.0000,   -8.8125,   11.0000,  ...,   -8.8125,   -6.8438,\n",
      "           -7.0938]]), tensor([[-191.0000,   -7.4688,    8.9375,  ...,   -5.7500,   -5.3438,\n",
      "           -4.3438]]), tensor([[-226.0000,   -7.8438,    9.6875,  ...,   -7.7188,   -5.8750,\n",
      "           -6.0000]]), tensor([[-362.0000,   -6.9062,   10.0625,  ...,   -6.9375,   -7.3125,\n",
      "           -7.5938]]), tensor([[-183.0000,   -7.7500,   10.2500,  ...,   -7.3125,   -8.6875,\n",
      "           -5.2188]]), tensor([[-191.0000,   -8.7500,    6.8750,  ...,   -7.6250,   -8.4375,\n",
      "           -7.0312]]), tensor([[-168.0000,   -8.3750,    5.6250,  ...,   -8.3750,   -7.3125,\n",
      "           -6.6562]]), tensor([[-192.0000,   -9.5625,    9.5000,  ...,   -9.7500,   -8.3750,\n",
      "           -7.2188]]), tensor([[-240.0000,   -9.7500,   10.3125,  ...,   -8.8125,   -9.0000,\n",
      "           -8.1250]]), tensor([[-163.0000,   -8.5000,    9.1875,  ...,  -10.0625,   -7.8438,\n",
      "           -5.9375]]), tensor([[-168.0000,   -8.1875,    5.0625,  ...,   -6.5000,   -7.1875,\n",
      "           -5.3125]]), tensor([[-192.0000,   -9.4375,    8.0625,  ...,   -6.8750,   -7.5625,\n",
      "           -5.1875]]), tensor([[-223.0000,   -9.0625,   11.0000,  ...,   -9.2500,   -8.3125,\n",
      "           -5.4688]]), tensor([[-219.0000,  -10.1250,    8.5000,  ...,   -8.1875,   -8.3750,\n",
      "           -6.1250]]), tensor([[-178.0000,   -9.7500,   11.6875,  ...,   -8.5625,   -9.5625,\n",
      "           -9.0000]]), tensor([[-167.0000,   -7.2500,   10.3750,  ...,   -6.4375,   -6.8438,\n",
      "           -7.0312]]), tensor([[-222.0000,  -10.5000,   11.0000,  ...,   -8.0000,   -8.5000,\n",
      "           -8.6250]]), tensor([[-196.0000,   -7.5625,   10.8125,  ...,   -8.1875,   -8.3750,\n",
      "           -7.2188]]), tensor([[-157.0000,  -10.5625,   11.0000,  ...,   -8.1875,   -9.3750,\n",
      "           -9.9375]]), tensor([[-181.0000,   -8.8750,   11.3750,  ...,   -9.9375,   -9.4375,\n",
      "           -9.5625]]), tensor([[-158.0000,   -7.5625,   10.0000,  ...,   -6.5000,   -6.9062,\n",
      "           -6.6875]]), tensor([[-179.0000,  -10.2500,   10.1875,  ...,   -8.1875,   -9.1250,\n",
      "           -8.0625]]), tensor([[-120.0000,   -7.0312,    9.8750,  ...,   -5.2188,   -6.3125,\n",
      "           -6.7500]]), tensor([[-139.0000,   -8.5625,   11.0000,  ...,   -8.0000,   -9.1875,\n",
      "           -7.1875]]), tensor([[-186.0000,   -7.2188,   10.0625,  ...,   -6.9375,   -7.4375,\n",
      "           -7.0938]]), tensor([[-169.0000,   -8.6250,    7.8750,  ...,   -6.9375,   -7.7188,\n",
      "           -7.4375]]), tensor([[-195.0000,   -9.0000,    9.9375,  ...,   -7.0000,   -7.7812,\n",
      "           -6.7188]]), tensor([[-193.0000,   -9.8125,   11.5625,  ...,   -8.8750,   -7.6250,\n",
      "           -6.6250]]), tensor([[-249.0000,   -6.5625,   14.6250,  ...,   -8.8125,   -7.8750,\n",
      "           -5.0000]]), tensor([[-498.0000,   -3.0469,   19.5000,  ...,   -5.4375,   -5.8438,\n",
      "           -5.8750]])), 'sequences': tensor([[    3,  2744,  1228,  ...,  2602, 29491,     2]]), 'input_ids': tensor([[    3,  2744,  1228,  ...,  1617, 29572,     4]]), 'scores': (tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]), tensor([[   -inf,    -inf, 195000.,  ...,    -inf,    -inf,    -inf]]))}]\n",
      "Load time: 6517.69 ms\n",
      "Prompt eval time: 6601.82 ms / 3153 tokens (2.09 ms per token, 477.60 tokens per second)\n",
      "Eval time: 28473.13 ms / 312 tokens (91.26 ms per token, 10.96 tokens per second)\n",
      "Total time: 35074.95 ms / 3465 tokens\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline \n",
    "import os \n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from typing import Dict\n",
    "from class_extender import ClassExtender\n",
    "import time\n",
    "from transformers import TextClassificationPipeline\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.outputs import Generation, LLMResult\n",
    "\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]='your_huggingface_API_key'\n",
    "\n",
    "\n",
    "BASE_MODEL_ID =  \"/home/tpllmws23/llms/raftv2\" # \"mistralai/Mistral-7B-v0.3\" # path to model to test\n",
    "\n",
    "#\"../../../llms/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, use_fast=True)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "#tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "# Initialize language model\n",
    "start_time = time.time()\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_ID, torch_dtype=torch.bfloat16,\n",
    "trust_remote_code=True, device_map=\"auto\",\n",
    "quantization_config=bnb_config)\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(BASE_MODEL_ID)\n",
    "generation_config.max_new_tokens = 1024 # maximum number of new tokens that can be generated by the model\n",
    "generation_config.temperature = 0.0001 # randomness of the generated tex\n",
    "generation_config.top_p = 0 # diversity of the generated text\n",
    "generation_config.do_sample = True \n",
    "generation_config.repetition_penalty = 1.2\n",
    "\n",
    "#generation_config.use_cache=True,\n",
    "#generation_config.num_return_sequences=1,\n",
    "\n",
    "generation_config.output_logits=True,\n",
    "generation_config.output_scores=True,\n",
    "generation_config.output_hidden_states=True,\n",
    "generation_config.return_dict_in_generate=True,\n",
    "print(generation_config)\n",
    "\n",
    "\n",
    "# we want to pass forward the input_ids and model_outputs (scores, logits, etc.) to evaluate them later\n",
    "def postprocess(self, model_outputs, **postprocess_parameters: Dict):\n",
    "    clean_up_tokenization_spaces=True\n",
    "    input_ids = model_outputs[\"input_ids\"]\n",
    "    prompt_text = model_outputs[\"prompt_text\"]\n",
    "    generated_sequence = model_outputs[\"generated_sequence\"][0]\n",
    "    records = []\n",
    "    for sequence in generated_sequence:\n",
    "        # Decode text\n",
    "        text = self.tokenizer.decode(\n",
    "            sequence,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n",
    "        )\n",
    "\n",
    "        # Remove PADDING prompt of the sequence if XLNet or Transfo-XL model is used\n",
    "        if input_ids is None:\n",
    "            prompt_length = 0\n",
    "        else:\n",
    "            prompt_length = len(\n",
    "                self.tokenizer.decode(\n",
    "                    input_ids[0],\n",
    "                    skip_special_tokens=True,\n",
    "                    clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        all_text = text[prompt_length:]\n",
    "        if isinstance(prompt_text, str):\n",
    "            all_text = prompt_text + all_text\n",
    "            \n",
    "\n",
    "        record = {\"generated_text\": all_text, \"model_outputs\": model_outputs[\"output\"], \"input_ids\": input_ids}\n",
    "    records.append(record)\n",
    "    return records\n",
    "\n",
    "# for decoderonlyoutput and setting return_dict=True and returning logits / scores the regular _forward method will fail (probably a bug in Huggingface transformers), as it returns a dict of outputs instead of the single generated sequence\n",
    "def _forward(self, model_inputs, **generate_kwargs):\n",
    "        input_ids = model_inputs[\"input_ids\"]\n",
    "        attention_mask = model_inputs.get(\"attention_mask\", None)\n",
    "        # Allow empty prompts\n",
    "        if input_ids.shape[1] == 0:\n",
    "            input_ids = None\n",
    "            attention_mask = None\n",
    "            in_b = 1\n",
    "        else:\n",
    "            in_b = input_ids.shape[0]\n",
    "        prompt_text = model_inputs.pop(\"prompt_text\")\n",
    "\n",
    "        # If there is a prefix, we may need to adjust the generation length. Do so without permanently modifying\n",
    "        # generate_kwargs, as some of the parameterization may come from the initialization of the pipeline.\n",
    "        prefix_length = generate_kwargs.pop(\"prefix_length\", 0)\n",
    "        if prefix_length > 0:\n",
    "            has_max_new_tokens = \"max_new_tokens\" in generate_kwargs or (\n",
    "                \"generation_config\" in generate_kwargs\n",
    "                and generate_kwargs[\"generation_config\"].max_new_tokens is not None\n",
    "            )\n",
    "            if not has_max_new_tokens:\n",
    "                generate_kwargs[\"max_length\"] = generate_kwargs.get(\"max_length\") or self.model.config.max_length\n",
    "                generate_kwargs[\"max_length\"] += prefix_length\n",
    "            has_min_new_tokens = \"min_new_tokens\" in generate_kwargs or (\n",
    "                \"generation_config\" in generate_kwargs\n",
    "                and generate_kwargs[\"generation_config\"].min_new_tokens is not None\n",
    "            )\n",
    "            if not has_min_new_tokens and \"min_length\" in generate_kwargs:\n",
    "                generate_kwargs[\"min_length\"] += prefix_length\n",
    "\n",
    "        # BS x SL\n",
    "        output = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)\n",
    "        #print(generated_sequence)\n",
    "        #warnings.warn(\n",
    "        #            str(generated_sequence)\n",
    "        #)\n",
    "       \n",
    "        generated_sequence = output.sequences[0]\n",
    "\n",
    "        out_b = generated_sequence.shape[0]\n",
    "        if self.framework == \"pt\":\n",
    "            generated_sequence = generated_sequence.reshape(in_b, out_b // in_b, *generated_sequence.shape[1:])\n",
    "        elif self.framework == \"tf\":\n",
    "            generated_sequence = tf.reshape(generated_sequence, (in_b, out_b // in_b, *generated_sequence.shape[1:]))\n",
    "        return {\"generated_sequence\": generated_sequence, \"input_ids\": input_ids, \"prompt_text\": prompt_text, \"output\": output}\n",
    "        \n",
    "\n",
    "pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=True,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with ClassExtender(type(pipe), postprocess), ClassExtender(TextClassificationPipeline, postprocess), ClassExtender(TextClassificationPipeline, _forward):\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "    def create_eval_prompt(query: str, context: str):\n",
    "        system_prompt = \"You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\\n\\n\"\n",
    "        return f\"[INST]{system_prompt}Context: {context}\\n\\nQuestion: {query}[/INST]\"\n",
    "    \n",
    "    data = [{\"page_content\": \"\\n\\u00a7 4 Sprachkenntnisse\\n(1) 1Neben den allgemeinen Zugangsvoraussetzungen (\\u00a7 59 LHG) sind f\\u00fcr die in \\u00a7 1 Abs. 1\\nS. 1 genannten Studieng\\u00e4nge deutsche Sprach kenntnisse nachzuweisen. 2Diese k\\u00f6nnen\\ndurch eine deutsche Hochschulzugangsberechtigung (u. a. erfolgreich abgeschlossenes\\ngrundst\\u00e4ndiges Hochschulstudium) nachgewiesen werden. 3Ferner kann der\\nSprachnachweis durch die Vorlage eines der folgenden Dokumente erbracht werden:\\n1. Feststellungspr\\u00fcfung f\\u00fcr ein Bachelorstudium durch Vorlage der Zugangsberechtigung\\ndes Studienkollegs an der Hochschule Konstanz,\\n2. Test Deutsch als Fremdsprache (TestDaF), sofern im Durchschnitt mindestens die\\nStufe TDN 4 erreicht wurde,   Seite 5 von 43 3. Deutsche Sprachpr\\u00fcfung f\\u00fcr den Hochschulzugang (DSH), sofern die DSH mit\\nmindestens der Stufe DSH -2 abgeschlossen wurde,\\n4. \\u201eTelc Deutsch C1 Hochschule\\u201c\\noder eine \\u00e4quivalente Sprachpr\\u00fcfung gem\\u00e4\\u00df der Rahmenordnung \\u00fcber Deutsche\\nSprachpr\\u00fcfungen f\\u00fcr das Studium an deutschen Hochschulen (RO -DT). 4Auf den Nachweis\\neiner deutschen Sprachpr\\u00fcfung kann bei Bewerber innen und Bewerbern im besonders\\nbegr\\u00fcndeten Einzelfall verzichtet werden, insbesondere wenn sie die deutsche\\nStaatsangeh\\u00f6rigkeit besitzen.\\n(2) 1Sprachnachweise f\\u00fcr den gew\\u00e4hl ten Studiengang, die durch die Bewerberin oder den\\nBewerber bis zum Bewerbungsschluss nicht vorgelegt werden k\\u00f6nnen, k\\u00f6nnen bis zum\\nVorlesungsbeginn des Semesters gem\\u00e4\\u00df Terminplan der Hochschule Konstanz, f\\u00fcr das  der\\nAntrag auf Zulassung gestellt wurde, nachgereicht werden. 2Die Zulassung erfolgt in diesem\\nFall gem \\u00e4\\u00df \\u00a7 6  Abs. 5  unter Vorbehalt .\\n(3) 1F\\u00fcr Zeitstudierende gelten die Regelungen in \\u00a7 10 Zulassungs - und\\nImmatrikulationsordnung (ZIO) der Hochschule Konstanz.\", \"metadata\": {\"file_path\": \"/home/tpllmws23/Chatbot-LLama-Pruefungsamt/main_data_filtered/119_ZuSMa_Senat_18012022.pdf\"}, \"type\": \"Document\"}, {\"page_content\": \"\\n\\u00a7 21b Mechatronik (MME) Berufsbegleitendes Studium\\n(1) Studiengangspezifische Zugangsvoraussetzungen gem\\u00e4\\u00df \\u00a7 5  Abs. 1\\nZugangsvoraussetzungen f\\u00fcr den Masterstudiengang Mechatronik sind:\\n1. Ein mit der Note 2,9 oder besser abgeschlossenes grundst\\u00e4ndiges Hochschulstudium\\ngem\\u00e4\\u00df \\u00a7 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtungen Systemtechnik,\\nMaschinenbau, Elektrotechnik, Fahrzeugtechnik, Mechatronik, Feinwerktechnik oder einer\\nverwandten Fachrichtung.\\n2. Englischkenntnisse, \\u00e4quivalent z u Niveau- Stufe B1 des Europ\\u00e4ischen Referenzrahmens\\nf\\u00fcr das Lernen und Lehren von Fremdsprachen. Als \\u00e4quivalent zu einem Zertifikat \\u00fcber die\\nNiveau -Stufe B1 gelten insbesondere folgende Nachweise:\\nI. das Schulabschlusszeugnis, aus dem der Besuch des Englischunterrichts bis zum\\nErreichen des mittleren Bildungsabschlusses (10. Klasse) bzw. bis zum Erreichen\\nder Fachhochschulreife hervorgeht oder\\nII. ein Notenspiegel, aus dem die bestandene Pr\\u00fcfungsleistung \\u00fcber eine\\nLehrveranstaltung im Rahmen des grundst\\u00e4ndigen Studiums hervorgeht, die die\\nenglische Sprache zum Inhalt hatte oder\\nIII. eine Bescheinigung \\u00fcber den mindestens sechsmonatigen Aufenthalt an einer Schule, Hochschule oder anderen Bildungsinstitution mit Englisch als\\nUnterrichtssprache oder\\nIV. eine Bescheinigung \\u00fcber den Aufenthalt im englischsprachigen Ausland, der einen Zeitraum von mindestens sechs Monaten bzw. einem Studiensemester umfasst.\\nDie Vorlage anderer geeigneter Nachweise ist m\\u00f6glich.\\n(2) Auswahlkriterien nach \\u00a7 9 Abs. 2\\n1. Ergebnis eines Auswahlgespr\\u00e4chs\\nNicht zutreffend.\\n2. Leistungen, die mit der Abschlusspr\\u00fcfung des grundst\\u00e4ndigen Studiums nach Abs. 1\\ni. V. m. \\u00a7 5 Abs. 1 Nr. 1 nachgewiesen sind\\nDie Durchschnittsnote der Abschlusspr\\u00fcfung des grundst\\u00e4ndigen Hochschulstudiums nach\\nAbs. 1 bildet die Teilnote 1 als Basis zur Bestimmung der Auswahlnote.  Abweichend von Satz\\n1 bildet in den F\\u00e4llen des \\u00a7 3 Abs. 2 Nr. 1 Satz 2 die Durchschnittsnote nach \\u00a7 3 Abs. 2 Nr. 1 Satz 3 die Teilnote 1. Bei ausl\\u00e4ndischen Bildungsnachweisen ist die Durchschnittsnote nach\\ndeutsc her Deutung als Teilnote 1 zu ber\\u00fccksichtigen.\\nZus\\u00e4tzlich werden die Einzelnoten folgender F\\u00e4cher der Abschlusspr\\u00fcfung des grundst\\u00e4ndigen Hochschulstudiums, die \\u00fcber die Eignung f\\u00fcr den gew\\u00e4hlten Studiengang\\nbesonderen Aufschluss geben, f\\u00fcr die Auswahl herangezogen:\\n- Technische Mechanik (Dynamik),\\n- Elektrotechnik,\\n- Messtechnik,\\n- Regelungstechnik,\\n- Elektrische Antriebe.\\nDabei wird eine Note zwischen 1,0 und 1,7 in einem der o. g. F\\u00e4cher jeweils mit dem Wert 0,1\\nbewertet. Die kumulierte Gesamtzahl bildet die Teil note 2.\", \"metadata\": {\"file_path\": \"/home/tpllmws23/Chatbot-LLama-Pruefungsamt/main_data_filtered/119_ZuSMa_Senat_18012022.pdf\"}, \"type\": \"Document\"}, {\"page_content\": \"\\n\\u00a7 21a Mechatronik (MME) Vollzeitstudium\\n(1) Studiengangspezifische Zugangsvoraussetzungen gem\\u00e4\\u00df \\u00a7 5  Abs. 1\\nZugangsvoraussetzungen f\\u00fcr den Masterstudiengang Mechatronik sind:\\n1. Ein mit der Note 2,9 oder besser abgeschlossenes grundst\\u00e4ndiges Hochschulstudium\\ngem\\u00e4\\u00df \\u00a7 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtungen Maschinenbau,\\nElektrotechnik, Fahrzeugtechnik, Mechatronik, Feinwerktechnik oder einer verwandten\\nFachrichtung.\\n2. Englischkenntnisse, \\u00e4quivalent zu Niveau- Stufe B1 des Europ\\u00e4ischen Referenzrahmens\\nf\\u00fcr das Lernen und Lehren von Fremdsprachen. Als \\u00e4quivalent zu einem Zertifikat \\u00fcber die\\nNiveau -Stufe B1 gelten insbesondere folgende Nachweise:\\nI. das Schulabschlusszeugnis, aus dem der Besuch des Englischunterrichts bis zum\\nErreichen des mittleren Bildungsabschlusses (10. Klass e) bzw. bis zum Erreichen\\nder Fachhochschulreife hervorgeht oder\\nII. ein Notenspiegel, aus dem die bestandene Pr\\u00fcfungsleistung \\u00fcber eine\\nLehrveranstaltung im Rahmen des grundst\\u00e4ndigen Studiums hervorgeht, die die\\nenglische Sprache zum Inhalt hatte oder\\nIII. eine Bescheinigung \\u00fcber den mindestens sechsmonatigen Aufenthalt an einer Schule, Hochschule oder anderen Bildungsinstitution mit Englisch als\\nUnterrichtssprache oder\\nIV. eine Bescheinigung \\u00fcber den Aufenthalt im englischsprachigen Ausland, der einen Zeitraum von mindestens sechs Monaten bzw. einem Studiensemester umfasst.\\nDie Vorlage anderer geeigneter Nachweise ist m\\u00f6glich.\\n(2) Auswahlkriterien nach \\u00a7 9 Abs. 2\\n1. Ergebnis eines Auswahlgespr\\u00e4chs\\nNicht zutreffend.\\n2. Leistungen, die mit der Abschlusspr\\u00fcfung des grundst\\u00e4ndigen Studiums nach Abs. 1\\ni. V. m. \\u00a7 5 Abs. 1 Nr. 1 nachgewiesen sind\\nDie Durchschnittsnote der Abschlusspr\\u00fcfung des grundst\\u00e4ndigen Hochschulstudiums nach\\nAbs. 1 bildet die Teilnote 1 als Basis zur Bestimmung der Auswahlnote. Abweichend von Satz\\n1 bildet in den F\\u00e4llen des \\u00a7 3 Abs. 2 Nr. 1 Satz 2 die Durchschnittsnote nach \\u00a7 3 Abs. 2 Nr. 1\\nSatz 3 die Teilnote 1. Bei ausl\\u00e4ndischen Bildungsnachweisen ist die Durchschnittsnote nach\\ndeutscher Deutung als Teilnote 1 zu ber\\u00fccksichtigen.\\nZus\\u00e4tzlich werden die Einzelnoten folgender F\\u00e4cher der Abschlusspr\\u00fcfung des grundst\\u00e4ndigen Hochschulstudiums, die \\u00fcber die Eignung f\\u00fcr den gew\\u00e4hlten Studiengang\\nbesonderen Aufschluss geben, f\\u00fcr die Auswahl herangezogen:\\n- Technische Mechanik (Dynamik),\\n- Elektrotechnik,\\n- Messt echnik,\\n- Regelungstechnik,\\n- Elektrische Antriebe.\\nDabei wird eine Note zwischen 1,0 und 1,7 in einem der o. g. F\\u00e4cher jeweils mit dem Wert 0,1\\nbewertet. Die kumulierte Gesamtzahl bildet die Teilnote 2.\", \"metadata\": {\"file_path\": \"/home/tpllmws23/Chatbot-LLama-Pruefungsamt/main_data_filtered/119_ZuSMa_Senat_18012022.pdf\"}, \"type\": \"Document\"}, {\"page_content\": \"\\n\\u00a7 9 Zugangs - und Auswahlkriterien in den Masterstudieng\\u00e4ngen\\n(1)  1Im Besonderen Teil (\\u00a7\\u00a7 12 -26) dieser Satzung k\\u00f6nnen ein oder mehrere der in Absatz 2\\ngenannten Auswahlkriterien als weitere Zugangskriterien festgelegt werden. 2N\\u00e4heres\\nregelt der B esondere Teil f\\u00fcr den jeweiligen Studiengang (\\u00a7\\u00a7 12 -26).\\n(2)  1F\\u00fcr die Bildung der Ranglisten f\\u00fcr das erste Fachsemester in den Masterstudieng\\u00e4ngen\\nwird, neben dem Ergebnis des fachlich einschl\\u00e4gigen Hochschulabschlusses oder des\\ngleichwertigen Abschlusses,  mindestens eines der folgenden  Auswahlkriterien\\nber\\u00fccksichtigt:\\n1. Leistungen, die in dem Studium erbracht wurden, das Voraussetzung f\\u00fcr den Zugang\\nzu dem Masterstudiengang ist ,   Seite 8 von 43 2. Englischkenntnisse , n\\u00e4heres regelt der Besondere Teil f\\u00fcr den jeweiligen Studiengang\\n(\\u00a7\\u00a7 12 -26),\\n3. Berufst\\u00e4tigkeit und Qualifikationen:\\na) Art einer abgeschlossenen Berufsausbildung oder einer Berufst\\u00e4tigkeit in einem\\nanerkannten Ausbildungsberuf  oder eine andere einschl\\u00e4gige Berufst\\u00e4tigkeit , die \\u00fcber\\ndie fachspezifische Eignung Auskunft gibt, jeweils  einzeln und in Kombination, und\\nb) Qualifikation en, die \\u00fcber die fachspezifische Leistung Auskunft geben, jeweils einzeln\\noder in Kombination,\\n4. das Ergebnis eines fachspezifischen Studieneignungstests ,\\n5. das Ergebnis des Auswahlgespr\\u00e4chs/anderen m\\u00fcndlichen Verfahrens  gem\\u00e4\\u00df \\u00a7 9a ,\\n6. ein Motivationsschreiben,\\n7. eine schriftliche Abhandlung (Essay).\\n2N\\u00e4heres sowie die Gewichtung regelt der B esondere Teil f\\u00fcr den jeweiligen Studiengang (\\u00a7\\u00a7\\n12-26).\\n(2) 1Die Auswahl f\\u00fcr h\\u00f6here Fachsemester erfolgt gem\\u00e4\\u00df \\u00a7 7 HZG i. V. m. \\u00a7 32 HZVO.\", \"metadata\": {\"file_path\": \"/home/tpllmws23/Chatbot-LLama-Pruefungsamt/main_data_filtered/119_ZuSMa_Senat_18012022.pdf\"}, \"type\": \"Document\"}]\n",
    "    context = [entry['page_content'] for entry in data]\n",
    "    #eval_prompt = create_eval_prompt(\"\"\"Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse akzeptiert werden?#\"\"\", str(context))\n",
    "    eval_prompt = create_eval_prompt(\"\"\"Was sind Zugangsvoraussetzungen f\\u00fcr den Masterstudiengang Mechatronik?\"\"\", str(context))\n",
    "    \n",
    "    # overwrite langchains _generate method to pass forward the model outputs etc.\n",
    "    def _generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        # List to hold all results\n",
    "        text_generations: List[str] = []\n",
    "        model_outputs: List[Any] = []\n",
    "        pipeline_kwargs = kwargs.get(\"pipeline_kwargs\", {})\n",
    "\n",
    "        for i in range(0, len(prompts), self.batch_size):\n",
    "            batch_prompts = prompts[i : i + self.batch_size]\n",
    "\n",
    "            # Process batch of prompts\n",
    "            responses = self.pipeline(\n",
    "                batch_prompts,\n",
    "                **pipeline_kwargs,\n",
    "            )\n",
    "\n",
    "            # Process each response in the batch\n",
    "            for j, response in enumerate(responses):\n",
    "                if isinstance(response, list):\n",
    "                    # if model returns multiple generations, pick the top one\n",
    "                    response = response[0]\n",
    "\n",
    "                if self.pipeline.task == \"text-generation\":\n",
    "                    # pass forward model outputs\n",
    "                    text = response[\"generated_text\"]\n",
    "                    model_output = {\n",
    "                        \"logits\": response[\"model_outputs\"][\"logits\"],\n",
    "                        \"sequences\": response[\"model_outputs\"][\"sequences\"],\n",
    "                        \"input_ids\": response[\"input_ids\"],\n",
    "                        \"scores\": response[\"model_outputs\"][\"scores\"],\n",
    "                    }\n",
    "                elif self.pipeline.task == \"text2text-generation\":\n",
    "                    text = response[\"generated_text\"]\n",
    "                elif self.pipeline.task == \"summarization\":\n",
    "                    text = response[\"summary_text\"]\n",
    "                elif self.pipeline.task in \"translation\":\n",
    "                    text = response[\"translation_text\"]\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        f\"Got invalid task {self.pipeline.task}, \"\n",
    "                        f\"currently only {VALID_TASKS} are supported\"\n",
    "                    )\n",
    "\n",
    "                # Append the processed text to results\n",
    "                text_generations.append(text)\n",
    "                if model_output is not None: model_outputs.append(model_output)\n",
    "\n",
    "        return LLMResult(\n",
    "            generations=[[Generation(text=text)] for text in text_generations],\n",
    "            llm_output={\n",
    "                \"model_outputs\": model_outputs\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def invoke(self, input: str) -> LLMResult:\n",
    "        return (\n",
    "            self.generate_prompt(\n",
    "                [self._convert_input(input)],\n",
    "            )\n",
    "        )\n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "    input_ids = tokenizer(eval_prompt, return_tensors=\"pt\").input_ids\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "    prompt_eval_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    output: LLMResult = LLMResult(generations=[], llm_output={})\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with ClassExtender(type(llm), invoke), ClassExtender(type(llm), _generate):\n",
    "        output = llm.invoke(eval_prompt) # type: ignore\n",
    "    eval_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if output.llm_output is None:\n",
    "        print(\"MISSING LLM Outpout\") \n",
    "        #return\n",
    "    print(output.llm_output[\"model_outputs\"])\n",
    "    logits = output.llm_output[\"model_outputs\"][0][\"logits\"]\n",
    "    sequences = output.llm_output[\"model_outputs\"][0][\"sequences\"]\n",
    "    input_ids = output.llm_output[\"model_outputs\"][0][\"input_ids\"]\n",
    "    scores = output.llm_output[\"model_outputs\"][0][\"scores\"]\n",
    "\n",
    "    num_prompt_tokens = len(input_ids[0])\n",
    "    num_generated_tokens = len(sequences[-1]) - num_prompt_tokens\n",
    "    total_tokens = num_prompt_tokens + num_generated_tokens\n",
    "    tokens_per_second = total_tokens / (prompt_eval_time + eval_time)\n",
    "\n",
    "    # simulate llama.cpp timings (without sample time)\n",
    "    print(f\"Load time: {load_time * 1000:.2f} ms\")\n",
    "    print(f\"Prompt eval time: {prompt_eval_time * 1000:.2f} ms / {num_prompt_tokens} tokens \"\n",
    "        f\"({prompt_eval_time / num_prompt_tokens * 1000:.2f} ms per token, \"\n",
    "        f\"{num_prompt_tokens / prompt_eval_time:.2f} tokens per second)\")\n",
    "    print(f\"Eval time: {eval_time * 1000:.2f} ms / {num_generated_tokens} tokens \"\n",
    "        f\"({eval_time / num_generated_tokens * 1000:.2f} ms per token, \"\n",
    "        f\"{num_generated_tokens / eval_time:.2f} tokens per second)\")\n",
    "    print(f\"Total time: {(prompt_eval_time + eval_time) * 1000:.2f} ms / {total_tokens} tokens\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST]You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\\n\\nContext: ['\\\\n§ 4 Sprachkenntnisse\\\\n(1) 1Neben den allgemeinen Zugangsvoraussetzungen (§ 59 LHG) sind für die in § 1 Abs. 1\\\\nS. 1 genannten Studiengänge deutsche Sprach kenntnisse nachzuweisen. 2Diese können\\\\ndurch eine deutsche Hochschulzugangsberechtigung (u. a. erfolgreich abgeschlossenes\\\\ngrundständiges Hochschulstudium) nachgewiesen werden. 3Ferner kann der\\\\nSprachnachweis durch die Vorlage eines der folgenden Dokumente erbracht werden:\\\\n1. Feststellungsprüfung für ein Bachelorstudium durch Vorlage der Zugangsberechtigung\\\\ndes Studienkollegs an der Hochschule Konstanz,\\\\n2. Test Deutsch als Fremdsprache (TestDaF), sofern im Durchschnitt mindestens die\\\\nStufe TDN 4 erreicht wurde,   Seite 5 von 43 3. Deutsche Sprachprüfung für den Hochschulzugang (DSH), sofern die DSH mit\\\\nmindestens der Stufe DSH -2 abgeschlossen wurde,\\\\n4. „Telc Deutsch C1 Hochschule“\\\\noder eine äquivalente Sprachprüfung gemäß der Rahmenordnung über Deutsche\\\\nSprachprüfungen für das Studium an deutschen Hochschulen (RO -DT). 4Auf den Nachweis\\\\neiner deutschen Sprachprüfung kann bei Bewerber innen und Bewerbern im besonders\\\\nbegründeten Einzelfall verzichtet werden, insbesondere wenn sie die deutsche\\\\nStaatsangehörigkeit besitzen.\\\\n(2) 1Sprachnachweise für den gewähl ten Studiengang, die durch die Bewerberin oder den\\\\nBewerber bis zum Bewerbungsschluss nicht vorgelegt werden können, können bis zum\\\\nVorlesungsbeginn des Semesters gemäß Terminplan der Hochschule Konstanz, für das  der\\\\nAntrag auf Zulassung gestellt wurde, nachgereicht werden. 2Die Zulassung erfolgt in diesem\\\\nFall gem äß § 6  Abs. 5  unter Vorbehalt .\\\\n(3) 1Für Zeitstudierende gelten die Regelungen in § 10 Zulassungs - und\\\\nImmatrikulationsordnung (ZIO) der Hochschule Konstanz.', '\\\\n§ 21b Mechatronik (MME) Berufsbegleitendes Studium\\\\n(1) Studiengangspezifische Zugangsvoraussetzungen gemäß § 5  Abs. 1\\\\nZugangsvoraussetzungen für den Masterstudiengang Mechatronik sind:\\\\n1. Ein mit der Note 2,9 oder besser abgeschlossenes grundständiges Hochschulstudium\\\\ngemäß § 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtungen Systemtechnik,\\\\nMaschinenbau, Elektrotechnik, Fahrzeugtechnik, Mechatronik, Feinwerktechnik oder einer\\\\nverwandten Fachrichtung.\\\\n2. Englischkenntnisse, äquivalent z u Niveau- Stufe B1 des Europäischen Referenzrahmens\\\\nfür das Lernen und Lehren von Fremdsprachen. Als äquivalent zu einem Zertifikat über die\\\\nNiveau -Stufe B1 gelten insbesondere folgende Nachweise:\\\\nI. das Schulabschlusszeugnis, aus dem der Besuch des Englischunterrichts bis zum\\\\nErreichen des mittleren Bildungsabschlusses (10. Klasse) bzw. bis zum Erreichen\\\\nder Fachhochschulreife hervorgeht oder\\\\nII. ein Notenspiegel, aus dem die bestandene Prüfungsleistung über eine\\\\nLehrveranstaltung im Rahmen des grundständigen Studiums hervorgeht, die die\\\\nenglische Sprache zum Inhalt hatte oder\\\\nIII. eine Bescheinigung über den mindestens sechsmonatigen Aufenthalt an einer Schule, Hochschule oder anderen Bildungsinstitution mit Englisch als\\\\nUnterrichtssprache oder\\\\nIV. eine Bescheinigung über den Aufenthalt im englischsprachigen Ausland, der einen Zeitraum von mindestens sechs Monaten bzw. einem Studiensemester umfasst.\\\\nDie Vorlage anderer geeigneter Nachweise ist möglich.\\\\n(2) Auswahlkriterien nach § 9 Abs. 2\\\\n1. Ergebnis eines Auswahlgesprächs\\\\nNicht zutreffend.\\\\n2. Leistungen, die mit der Abschlussprüfung des grundständigen Studiums nach Abs. 1\\\\ni. V. m. § 5 Abs. 1 Nr. 1 nachgewiesen sind\\\\nDie Durchschnittsnote der Abschlussprüfung des grundständigen Hochschulstudiums nach\\\\nAbs. 1 bildet die Teilnote 1 als Basis zur Bestimmung der Auswahlnote.  Abweichend von Satz\\\\n1 bildet in den Fällen des § 3 Abs. 2 Nr. 1 Satz 2 die Durchschnittsnote nach § 3 Abs. 2 Nr. 1 Satz 3 die Teilnote 1. Bei ausländischen Bildungsnachweisen ist die Durchschnittsnote nach\\\\ndeutsc her Deutung als Teilnote 1 zu berücksichtigen.\\\\nZusätzlich werden die Einzelnoten folgender Fächer der Abschlussprüfung des grundständigen Hochschulstudiums, die über die Eignung für den gewählten Studiengang\\\\nbesonderen Aufschluss geben, für die Auswahl herangezogen:\\\\n- Technische Mechanik (Dynamik),\\\\n- Elektrotechnik,\\\\n- Messtechnik,\\\\n- Regelungstechnik,\\\\n- Elektrische Antriebe.\\\\nDabei wird eine Note zwischen 1,0 und 1,7 in einem der o. g. Fächer jeweils mit dem Wert 0,1\\\\nbewertet. Die kumulierte Gesamtzahl bildet die Teil note 2.', '\\\\n§ 21a Mechatronik (MME) Vollzeitstudium\\\\n(1) Studiengangspezifische Zugangsvoraussetzungen gemäß § 5  Abs. 1\\\\nZugangsvoraussetzungen für den Masterstudiengang Mechatronik sind:\\\\n1. Ein mit der Note 2,9 oder besser abgeschlossenes grundständiges Hochschulstudium\\\\ngemäß § 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtungen Maschinenbau,\\\\nElektrotechnik, Fahrzeugtechnik, Mechatronik, Feinwerktechnik oder einer verwandten\\\\nFachrichtung.\\\\n2. Englischkenntnisse, äquivalent zu Niveau- Stufe B1 des Europäischen Referenzrahmens\\\\nfür das Lernen und Lehren von Fremdsprachen. Als äquivalent zu einem Zertifikat über die\\\\nNiveau -Stufe B1 gelten insbesondere folgende Nachweise:\\\\nI. das Schulabschlusszeugnis, aus dem der Besuch des Englischunterrichts bis zum\\\\nErreichen des mittleren Bildungsabschlusses (10. Klass e) bzw. bis zum Erreichen\\\\nder Fachhochschulreife hervorgeht oder\\\\nII. ein Notenspiegel, aus dem die bestandene Prüfungsleistung über eine\\\\nLehrveranstaltung im Rahmen des grundständigen Studiums hervorgeht, die die\\\\nenglische Sprache zum Inhalt hatte oder\\\\nIII. eine Bescheinigung über den mindestens sechsmonatigen Aufenthalt an einer Schule, Hochschule oder anderen Bildungsinstitution mit Englisch als\\\\nUnterrichtssprache oder\\\\nIV. eine Bescheinigung über den Aufenthalt im englischsprachigen Ausland, der einen Zeitraum von mindestens sechs Monaten bzw. einem Studiensemester umfasst.\\\\nDie Vorlage anderer geeigneter Nachweise ist möglich.\\\\n(2) Auswahlkriterien nach § 9 Abs. 2\\\\n1. Ergebnis eines Auswahlgesprächs\\\\nNicht zutreffend.\\\\n2. Leistungen, die mit der Abschlussprüfung des grundständigen Studiums nach Abs. 1\\\\ni. V. m. § 5 Abs. 1 Nr. 1 nachgewiesen sind\\\\nDie Durchschnittsnote der Abschlussprüfung des grundständigen Hochschulstudiums nach\\\\nAbs. 1 bildet die Teilnote 1 als Basis zur Bestimmung der Auswahlnote. Abweichend von Satz\\\\n1 bildet in den Fällen des § 3 Abs. 2 Nr. 1 Satz 2 die Durchschnittsnote nach § 3 Abs. 2 Nr. 1\\\\nSatz 3 die Teilnote 1. Bei ausländischen Bildungsnachweisen ist die Durchschnittsnote nach\\\\ndeutscher Deutung als Teilnote 1 zu berücksichtigen.\\\\nZusätzlich werden die Einzelnoten folgender Fächer der Abschlussprüfung des grundständigen Hochschulstudiums, die über die Eignung für den gewählten Studiengang\\\\nbesonderen Aufschluss geben, für die Auswahl herangezogen:\\\\n- Technische Mechanik (Dynamik),\\\\n- Elektrotechnik,\\\\n- Messt echnik,\\\\n- Regelungstechnik,\\\\n- Elektrische Antriebe.\\\\nDabei wird eine Note zwischen 1,0 und 1,7 in einem der o. g. Fächer jeweils mit dem Wert 0,1\\\\nbewertet. Die kumulierte Gesamtzahl bildet die Teilnote 2.', '\\\\n§ 9 Zugangs - und Auswahlkriterien in den Masterstudiengängen\\\\n(1)  1Im Besonderen Teil (§§ 12 -26) dieser Satzung können ein oder mehrere der in Absatz 2\\\\ngenannten Auswahlkriterien als weitere Zugangskriterien festgelegt werden. 2Näheres\\\\nregelt der B esondere Teil für den jeweiligen Studiengang (§§ 12 -26).\\\\n(2)  1Für die Bildung der Ranglisten für das erste Fachsemester in den Masterstudiengängen\\\\nwird, neben dem Ergebnis des fachlich einschlägigen Hochschulabschlusses oder des\\\\ngleichwertigen Abschlusses,  mindestens eines der folgenden  Auswahlkriterien\\\\nberücksichtigt:\\\\n1. Leistungen, die in dem Studium erbracht wurden, das Voraussetzung für den Zugang\\\\nzu dem Masterstudiengang ist ,   Seite 8 von 43 2. Englischkenntnisse , näheres regelt der Besondere Teil für den jeweiligen Studiengang\\\\n(§§ 12 -26),\\\\n3. Berufstätigkeit und Qualifikationen:\\\\na) Art einer abgeschlossenen Berufsausbildung oder einer Berufstätigkeit in einem\\\\nanerkannten Ausbildungsberuf  oder eine andere einschlägige Berufstätigkeit , die über\\\\ndie fachspezifische Eignung Auskunft gibt, jeweils  einzeln und in Kombination, und\\\\nb) Qualifikation en, die über die fachspezifische Leistung Auskunft geben, jeweils einzeln\\\\noder in Kombination,\\\\n4. das Ergebnis eines fachspezifischen Studieneignungstests ,\\\\n5. das Ergebnis des Auswahlgesprächs/anderen mündlichen Verfahrens  gemäß § 9a ,\\\\n6. ein Motivationsschreiben,\\\\n7. eine schriftliche Abhandlung (Essay).\\\\n2Näheres sowie die Gewichtung regelt der B esondere Teil für den jeweiligen Studiengang (§§\\\\n12-26).\\\\n(2) 1Die Auswahl für höhere Fachsemester erfolgt gemäß § 7 HZG i. V. m. § 32 HZVO.']\\n\\nQuestion: Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse akzeptiert werden?[/INST]\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.generations[0][0].text # this will only return the prompt, the true generation lies inside sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERPLEXITY:  tensor(0.7297)\n",
      "\n",
      "\n",
      "LOGPROBS:  tensor([[-4.3830e+02, -1.5816e+01, -1.3738e+01,  ..., -2.1800e+01,\n",
      "         -2.0300e+01, -1.9863e+01],\n",
      "        [-3.2001e+02, -2.4421e+01, -1.8329e+01,  ..., -2.3983e+01,\n",
      "         -2.2733e+01, -2.4546e+01],\n",
      "        [-2.6047e+02, -2.9974e+01, -1.8020e+01,  ..., -2.8755e+01,\n",
      "         -2.9786e+01, -2.7880e+01],\n",
      "        ...,\n",
      "        [-2.1625e+02, -3.3063e+01, -1.1688e+01,  ..., -3.2126e+01,\n",
      "         -3.0876e+01, -2.9876e+01],\n",
      "        [-2.7100e+02, -2.8563e+01, -7.3759e+00,  ..., -3.0813e+01,\n",
      "         -2.9876e+01, -2.7001e+01],\n",
      "        [-5.1752e+02, -2.2567e+01, -1.9638e-02,  ..., -2.4957e+01,\n",
      "         -2.5363e+01, -2.5395e+01]])\n",
      "SCORE:  (['To', 'answer', 'this', 'question', ',', 'we', 'need', 'to', 'identify', 'the', 'requirements', 'or', 'pr', 'ere', 'quis', 'ites', 'mentioned', 'in', 'the', 'context', 'for', 'admission', 'into', 'the', 'Master', \"'\", 's', 'program', 'in', 'Me', 'chat', 'ron', 'ics', '.', 'The', 'relevant', 'information', 'can', 'be', 'found', 'under', 'the', 'sub', 'section', '\"', 'Stud', 'ien', 'f', 'äh', 'igkeit', '\"', 'and', 'it', 'ment', 'ions', 'specific', 'criteria', 'that', 'must', 'be', 'met', 'by', 'applic', 'ants', '.', '\\n', '\\n', 'The', 'context', 'states', ':', '##', 'begin', '_', 'quote', '##', '\"(', '1', ')', 'Für', 'die', 'Z', 'ul', 'ass', 'ung', 'in', 'einen', 'Master', 'st', 'udi', 'eng', 'ang', 'der', 'F', 'ach', 'richt', 'ung', '\\\\', 'n', 'M', 'ech', 'at', 'ron', 'ik', 'm', 'uss', 'ein', 'mit', 'der', 'Mind', 'est', 'note', '', '2', ',', '5', 'ab', 'gesch', 'loss', 'enes', 'gru', 'nd', 'ständ', 'iges', 'Hoch', 'sch', 'ul', 'stud', 'ium', 'in', 'einem', 'Stud', 'i', 'eng', 'ang', 'der', 'F', 'ach', 'richt', 'ungen', 'Mas', 'ch', 'inen', 'bau', ',', '\\\\', 'n', 'E', 'le', 'kt', 'ro', '-', 'und', 'Information', 'ste', 'chn', 'ik', ',', 'F', 'ahr', 'zeug', 'techn', 'ik', 'oder', 'einer', 'verw', 'and', 'ten', '\\\\', 'n', 'F', 'ach', 'richt', 'ung', 'vor', 'lie', 'gen', '.\"', '##', 'end', '_', 'quote', '##', 'This', 'transl', 'ates', 'to', ':', '\"', 'For', 'admission', 'into', 'a', 'Master', \"'\", 's', 'program', 'in', 'the', 'field', 'of', 'Me', 'chat', 'ron', 'ics', ',', 'a', 'basic', 'university', 'degree', 'with', 'at', 'least', 'a', 'grade', 'of', '', '2', '.', '5', 'must', 'have', 'been', 'completed', 'in', 'a', 'course', 'of', 'study', 'in', 'the', 'fields', 'of', 'mechanical', 'engineering', ',', 'electrical', 'and', 'information', 'technology', ',', 'autom', 'otive', 'engineering', 'or', 'a', 'related', 'field', '.\"', '\\n', '\\n', '<', 'AN', 'SW', 'ER', '>:', 'The', 'requirement', 'for', 'admission', 'into', 'the', 'Master', \"'\", 's', 'program', 'in', 'Me', 'chat', 'ron', 'ics', 'is', 'a', 'basic', 'university', 'degree', 'with', 'at', 'least', 'a', 'grade', 'of', '', '2', '.', '5', 'from', 'a', 'course', 'of', 'study', 'in', 'the', 'fields', 'of', 'mechanical', 'engineering', ',', 'electrical', 'and', 'information', 'technology', ',', 'autom', 'otive', 'engineering', 'or', 'a', 'related', 'field', '.', '</s>'], [tensor(-11.0188), tensor(-13.7022), tensor(-10.5986), tensor(-11.0001), tensor(-7.4405), tensor(-15.5334), tensor(-15.4178), tensor(-13.0628), tensor(-12.8707), tensor(-7.7879), tensor(-13.4919), tensor(-10.4073), tensor(-18.2563), tensor(-21.0625), tensor(-23.7814), tensor(-27.5626), tensor(-9.4290), tensor(-12.9378), tensor(-11.1254), tensor(-13.0166), tensor(-21.1747), tensor(-15.3337), tensor(-12.8599), tensor(-7.4446), tensor(-12.4853), tensor(-16.0120), tensor(-16.3125), tensor(-7.6942), tensor(-10.6390), tensor(-23.2498), tensor(-28.8751), tensor(-19.5627), tensor(-12.8177), tensor(-13.7858), tensor(-14.4513), tensor(-5.4444), tensor(-19.1534), tensor(-16.1195), tensor(-9.2502), tensor(-18.5942), tensor(-12.8361), tensor(-4.6719), tensor(-11.4862), tensor(-17.3485), tensor(-17.4358), tensor(-16.6320), tensor(-11.1914), tensor(-11.3179), tensor(-20.0601), tensor(-14.1533), tensor(-7.4611), tensor(-11.0698), tensor(-4.4488), tensor(-17.9575), tensor(-19.4844), tensor(-6.3332), tensor(-13.5083), tensor(-11.5113), tensor(-11.2529), tensor(-9.8754), tensor(-18.2254), tensor(-13.7517), tensor(-22.0879), tensor(-14.2814), tensor(-8.8534), tensor(-0.2334), tensor(-9.1888), tensor(-9.2810), tensor(-15.7581), tensor(-9.1497), tensor(-7.9411), tensor(-10.7252), tensor(-19.3128), tensor(-16.1250), tensor(-26.8751), tensor(-18.5814), tensor(-7.3405), tensor(-13.3156), tensor(-15.2203), tensor(-9.9162), tensor(-5.3614), tensor(-16.2005), tensor(-21.9377), tensor(-21.5938), tensor(-17.6904), tensor(-13.2213), tensor(-11.3694), tensor(-15.7184), tensor(-20.3989), tensor(-20.8829), tensor(-15.7189), tensor(-20.0008), tensor(-13.9777), tensor(-14.2937), tensor(-16.0150), tensor(-21.6020), tensor(-16.3028), tensor(-10.6039), tensor(-10.8204), tensor(-19.4951), tensor(-12.5931), tensor(-18.7970), tensor(-15.9064), tensor(-19.5313), tensor(-13.5757), tensor(-23.1007), tensor(-9.8862), tensor(-10.6509), tensor(-5.1976), tensor(-20.8767), tensor(-17.7563), tensor(-17.1601), tensor(-13.4730), tensor(-18.2821), tensor(-14.9080), tensor(-20.3459), tensor(-15.6739), tensor(-19.6620), tensor(-21.8921), tensor(-22.5406), tensor(-17.2231), tensor(-27.2656), tensor(-15.5635), tensor(-22.6967), tensor(-21.2318), tensor(-15.4106), tensor(-17.1103), tensor(-19.3919), tensor(-13.2508), tensor(-11.0283), tensor(-9.9931), tensor(-18.1241), tensor(-12.9073), tensor(-17.5942), tensor(-18.0953), tensor(-18.5362), tensor(-15.7217), tensor(-21.0275), tensor(-16.9063), tensor(-18.5933), tensor(-17.3128), tensor(-15.9375), tensor(-21.6252), tensor(-12.3753), tensor(-8.5134), tensor(-18.2202), tensor(-13.3752), tensor(-19.3457), tensor(-19.6877), tensor(-23.4506), tensor(-14.1997), tensor(-7.0174), tensor(-16.9322), tensor(-25.0278), tensor(-24.4141), tensor(-27.1074), tensor(-19.5000), tensor(-18.2228), tensor(-15.8199), tensor(-18.4065), tensor(-18.3770), tensor(-20.9845), tensor(-25.2578), tensor(-15.8219), tensor(-8.0200), tensor(-19.2415), tensor(-17.5314), tensor(-15.6878), tensor(-16.7714), tensor(-16.2815), tensor(-19.9376), tensor(-21.7188), tensor(-22.9688), tensor(-21.0939), tensor(-18.0048), tensor(-19.9071), tensor(-22.0000), tensor(-15.5183), tensor(-18.1901), tensor(-19.2502), tensor(-16.1875), tensor(-17.9063), tensor(-20.5625), tensor(-9.5120), tensor(-18.1632), tensor(-14.4375), tensor(-11.8138), tensor(-1.2375), tensor(-10.8743), tensor(-14.9281), tensor(-20.5973), tensor(-15.2618), tensor(-8.9497), tensor(-18.7648), tensor(-19.5630), tensor(-15.3125), tensor(-12.6309), tensor(-15.4379), tensor(-15.7473), tensor(-17.2484), tensor(-10.6250), tensor(-24.9169), tensor(-31.1875), tensor(-20.9375), tensor(-17.7813), tensor(-10.3751), tensor(-13.6086), tensor(-5.6076), tensor(-2.4353), tensor(-16.0187), tensor(-8.7346), tensor(-13.8360), tensor(-10.6251), tensor(-5.1383), tensor(-15.3111), tensor(-6.1321), tensor(-15.2500), tensor(-22.4219), tensor(-14.3753), tensor(-18.2972), tensor(-14.2979), tensor(-11.2727), tensor(-10.7503), tensor(-17.0343), tensor(-13.8126), tensor(-8.3454), tensor(-15.9641), tensor(-13.5743), tensor(-16.1063), tensor(-14.1357), tensor(-7.8150), tensor(-16.3117), tensor(-17.0000), tensor(-9.5727), tensor(-9.0022), tensor(-17.9689), tensor(-16.2537), tensor(-17.9069), tensor(-14.4455), tensor(-15.1876), tensor(-19.3619), tensor(-20.3343), tensor(-22.7240), tensor(-11.1262), tensor(-17.0850), tensor(-5.1582), tensor(-15.0019), tensor(-14.3657), tensor(-13.0012), tensor(-0.0051), tensor(-7.5631), tensor(-12.5017), tensor(-25.2813), tensor(-16.8862), tensor(-27.5625), tensor(-24.9611), tensor(-9.1238), tensor(-14.7594), tensor(-13.8305), tensor(-16.8293), tensor(-12.7044), tensor(-7.1995), tensor(-17.1948), tensor(-18.0909), tensor(-12.0625), tensor(-6.6907), tensor(-9.7543), tensor(-23.4301), tensor(-29.8438), tensor(-18.1253), tensor(-16.4376), tensor(-14.1630), tensor(-14.7703), tensor(-4.4710), tensor(-3.8982), tensor(-14.8751), tensor(-8.3018), tensor(-13.2146), tensor(-10.2502), tensor(-5.5134), tensor(-16.2535), tensor(-8.5008), tensor(-15.3125), tensor(-20.6250), tensor(-13.2500), tensor(-20.2657), tensor(-13.7254), tensor(-9.5758), tensor(-16.8064), tensor(-8.9423), tensor(-15.1875), tensor(-14.4397), tensor(-4.6727), tensor(-16.2980), tensor(-10.8756), tensor(-10.4380), tensor(-9.6880), tensor(-16.3126), tensor(-16.0626), tensor(-15.6251), tensor(-16.6563), tensor(-12.4375), tensor(-13.8751), tensor(-23.9452), tensor(-25.5548), tensor(-9.9385), tensor(-15.5433), tensor(-6.0030), tensor(-10.3131), tensor(-11.9384), tensor(-7.3759)])\n",
      "NLL:  tensor([1.7503e-01, 1.4725e-02, 1.2236e+00, 1.3160e-04, 2.9594e-03, 2.1085e-03,\n",
      "        1.1538e-02, 2.8547e-04, 4.6444e-01, 3.7909e-02, 1.0388e+00, 2.4698e+00,\n",
      "        6.2052e-01, 3.5763e-07, 1.2421e-04, 1.1062e-04, 2.0540e+00, 6.2784e-02,\n",
      "        4.0583e-04, 7.9109e-02, 1.4344e-01, 1.0994e+00, 7.0362e-01, 7.0865e-03,\n",
      "        4.5403e-01, 1.2008e-02, 3.3855e-05, 1.3168e-01, 1.3951e-02, 7.6582e-03,\n",
      "        5.3404e-05, 1.5865e-04, 5.2495e-03, 4.5744e-03, 4.6693e-01, 1.0069e+00,\n",
      "        4.9671e-03, 3.2914e+00, 1.7916e-04, 4.8661e-04, 3.0549e+00, 1.7193e-01,\n",
      "        7.6747e-01, 6.6100e-01, 8.8109e-01, 2.3312e+00, 3.5149e-02, 7.2416e-01,\n",
      "        1.3245e-02, 1.2640e-02, 1.6799e+00, 3.0073e+00, 2.5738e+00, 1.9966e+00,\n",
      "        1.2636e-05, 1.9582e+00, 1.8833e+00, 1.4801e+00, 1.0342e+00, 3.5733e-04,\n",
      "        3.7874e-02, 3.5955e+00, 1.5044e-01, 1.1682e-04, 1.0339e-01, 2.3341e-01,\n",
      "        1.2933e-03, 1.1560e+00, 1.6828e-01, 2.1216e-01, 3.6250e-03, 1.7565e+00,\n",
      "        3.2336e-04, 5.0068e-06, 5.9960e-05, 3.2367e-03, 2.6843e+00, 4.4064e-01,\n",
      "        1.4998e-03, 2.2600e+00, 2.3645e-01, 5.2867e-01, 1.9250e-04, 9.7747e-05,\n",
      "        2.8730e-03, 8.0688e-02, 1.0569e+00, 9.3364e-02, 4.7363e-04, 1.0669e-04,\n",
      "        1.3124e-04, 7.8957e-04, 4.8163e-01, 7.4972e-02, 1.5048e-02, 4.1726e-04,\n",
      "        4.7464e-01, 2.7602e+00, 3.9186e-02, 2.6076e-01, 2.6497e-01, 1.2659e-04,\n",
      "        1.0633e-04, 9.4175e-06, 3.4128e-01, 4.2886e-01, 4.2409e-02, 1.8216e-01,\n",
      "        2.6009e-01, 2.5955e+00, 6.3480e-03, 3.8994e-03, 4.2580e-03, 8.3626e-04,\n",
      "        1.7754e-03, 4.5532e-01, 2.0168e-03, 1.8083e-03, 1.4309e-03, 1.4958e-03,\n",
      "        6.1370e-01, 1.1921e-05, 9.8014e-04, 1.4215e-03, 3.8807e-01, 4.3127e-03,\n",
      "        9.1547e-04, 1.2456e-03, 7.5907e-04, 7.7833e-01, 1.8061e-01, 1.4704e-02,\n",
      "        1.0130e-03, 4.4002e-04, 1.5935e-03, 1.0575e-03, 2.9195e-03, 2.1375e-03,\n",
      "        6.3775e-05, 6.9414e-01, 1.0706e+00, 4.8876e-06, 2.2290e-04, 3.2753e-04,\n",
      "        1.3407e-02, 5.2491e-01, 1.9203e-04, 1.9875e-03, 1.6271e-04, 5.2379e-03,\n",
      "        3.1684e+00, 2.0487e-01, 1.3143e-01, 4.8637e-04, 2.9921e-05, 2.7179e-05,\n",
      "        3.8147e-06, 5.0969e-02, 1.1676e-01, 2.2969e-04, 2.0307e-03, 1.4209e-04,\n",
      "        1.0729e-06, 6.3436e-01, 2.0037e-02, 2.2733e-02, 1.6318e-04, 3.4350e-04,\n",
      "        3.4950e-01, 2.0991e-04, 1.1229e-04, 7.6294e-06, 1.8000e-05, 1.6009e-04,\n",
      "        2.8604e-01, 8.8617e-04, 4.8875e-05, 3.1121e+00, 2.5518e-03, 2.1646e-04,\n",
      "        1.5497e-06, 1.7166e-05, 4.7921e-05, 1.6995e+00, 6.2509e-01, 1.7166e-05,\n",
      "        1.2639e-03, 3.6245e-01, 6.1818e-02, 2.1863e-02, 1.9152e-02, 1.1759e-02,\n",
      "        3.8718e-01, 1.4837e-02, 4.9543e-04, 2.0861e-05, 5.8970e-03, 4.3264e-04,\n",
      "        4.3483e-01, 2.9631e-02, 3.4093e-05, 2.8314e-03, 2.1457e-05, 2.4557e-05,\n",
      "        4.7684e-06, 5.0424e-05, 1.4889e-02, 4.8257e-01, 1.8532e-01, 8.1158e-02,\n",
      "        2.4846e+00, 2.2423e+00, 1.0573e-04, 1.3312e-02, 6.1079e-02, 7.1383e-03,\n",
      "        3.8146e-05, 3.2901e-05, 3.0060e-04, 2.9726e-04, 7.9126e-02, 8.3520e-01,\n",
      "        3.4779e-04, 3.0734e-03, 1.3982e-04, 9.5388e-02, 8.9136e-02, 1.1759e-02,\n",
      "        1.2561e-02, 1.0678e-02, 2.5049e-03, 9.2934e-02, 6.9141e-06, 1.5102e+00,\n",
      "        2.2018e-03, 1.6628e-04, 3.7203e-03, 6.1100e-04, 8.0261e-03, 1.4697e-04,\n",
      "        1.8190e-02, 1.6937e+00, 5.2359e-03, 3.1369e-01, 4.2876e-01, 3.3245e-02,\n",
      "        1.8788e-03, 2.1903e-02, 1.2306e-03, 5.1096e-03, 5.5917e-04, 5.6425e-01,\n",
      "        1.5497e-05, 1.1161e-02, 8.3446e-07, 1.1515e-04, 1.5501e-01, 3.5719e+00,\n",
      "        1.1175e-01, 1.6831e-02, 1.6945e-02, 1.1954e-02, 7.3006e-03, 4.9278e-03,\n",
      "        1.3590e-05, 3.1858e-03, 4.2641e-03, 4.4598e-04, 4.9351e-05, 2.6866e-04,\n",
      "        5.2928e-05, 6.7473e-03, 1.4529e-01, 2.8350e-01, 2.3191e-02, 8.6304e-05,\n",
      "        1.7678e-01, 8.9561e-02, 1.8416e-04, 1.3353e-02, 3.5472e-03, 8.1041e-04,\n",
      "        4.0292e-05, 2.5749e-05, 3.2901e-05, 6.1033e-05, 2.1004e+00, 1.3286e-02,\n",
      "        2.5101e-02, 4.7923e-03, 2.9563e-05, 2.1847e-03, 1.7268e-01, 1.6768e-02,\n",
      "        6.0850e-04, 4.8125e-04, 5.1831e-04, 1.2540e-04, 8.4993e-05, 1.0514e-04,\n",
      "        3.1113e-05, 4.0888e-05, 1.4697e-04, 9.0058e-04, 6.8781e-05, 9.8454e-04,\n",
      "        3.8700e-01, 2.9778e-03, 6.3757e-04, 8.7164e-04, 9.0058e-04, 1.9638e-02])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Assuming `logits` is a tensor of shape (sequence_length, vocab_size)\n",
    "log_probs = F.log_softmax(torch.stack(list(logits), dim=0).squeeze(), dim=-1)\n",
    "\n",
    "nll = F.nll_loss(log_probs, sequences[-1][input_ids.shape[1]:], reduction='none') # mask away prompt\n",
    "average_nll = nll.mean()\n",
    "# Perplexity is the exponentiation of the average NLL\n",
    "perplexity = torch.exp(average_nll)\n",
    "print(\"PERPLEXITY: \", perplexity)\n",
    "\n",
    "print(\"\\n\\nLOGPROBS: \", log_probs)\n",
    "\n",
    "def score_probs(log_probs, sequence_ids):\n",
    "    sequence_tokens = [tokenizer.decode(id) for id in sequence_ids]\n",
    "    token_logprobs = []\n",
    "    for k in range(1, sequence_ids.shape[0]):\n",
    "        token_logprobs.append(log_probs[k-1, sequence_ids[k]])\n",
    "    return sequence_tokens, token_logprobs\n",
    "\n",
    "# combine log_probs with tokens\n",
    "result = score_probs(log_probs, sequences[-1][input_ids.shape[1]:] )\n",
    "\n",
    "sequence_ids = sequences[-1][input_ids.shape[1]:]\n",
    "\n",
    "sequence_tokens = [tokenizer.decode(id) for id in sequence_ids]\n",
    "\n",
    "print(\"SCORE: \", result)\n",
    "\n",
    "print(\"NLL: \", nll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 32768\n",
    "# scores and logits need to be stacked as they are returned as a tuple\n",
    "torch.stack(list(scores), dim=0).shape # returns [<generation_length>, <batch_size>, <vocab_size>], is the same for logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- proccesses logits to compute correct scores, as this does not happen when generation_config.do_sample=True (-> leads to faster and potentially better generations)\n",
    "- all off the scores are -inf in that case and can't really be used\n",
    "- alas the following code will only approximate them and not get them correct completely (but close enough for valid results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([312, 32768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2200e+02,  4.8438e-01,  2.5625e+00,  ..., -5.5000e+00,\n",
       "         -4.0000e+00, -3.5625e+00],\n",
       "        [-3.0200e+02, -6.4062e+00, -3.1445e-01,  ..., -5.9688e+00,\n",
       "         -4.7188e+00, -6.5312e+00],\n",
       "        [-2.3900e+02, -8.5000e+00,  3.4531e+00,  ..., -7.2812e+00,\n",
       "         -8.3125e+00, -6.4062e+00],\n",
       "        ...,\n",
       "        [-1.9300e+02, -9.8125e+00,  1.1562e+01,  ..., -8.8750e+00,\n",
       "         -7.6250e+00, -6.6250e+00],\n",
       "        [-2.4900e+02, -6.5625e+00,  1.4625e+01,  ..., -8.8125e+00,\n",
       "         -7.8750e+00, -5.0000e+00],\n",
       "        [-4.9800e+02, -3.0469e+00,  1.9500e+01,  ..., -5.4375e+00,\n",
       "         -5.8438e+00, -5.8750e+00]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers.generation.logits_process import RepetitionPenaltyLogitsProcessor, TemperatureLogitsWarper\n",
    "\n",
    "processor = RepetitionPenaltyLogitsProcessor(1.2)\n",
    "warper = TemperatureLogitsWarper(generation_config.temperature)\n",
    "\n",
    "logits_shifted = torch.stack(list(logits), dim=0)[:-1, :, :].squeeze()\n",
    "sequence_ids_shifted = sequence_ids.unsqueeze(0)[:, 1:]\n",
    "\n",
    "logits_unshifted = torch.stack(list(logits), dim=0).squeeze()\n",
    "sequence_ids_unshifted = sequence_ids.unsqueeze(0)[:, :]\n",
    "\n",
    "\n",
    "scores_self = processor(input_ids, logits_unshifted)\n",
    "print(scores_self.shape)\n",
    "scores_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "res = []\n",
    "for row in logits_unshifted:\n",
    "    # apply processor on each logit row instead of the whole logits at once -> leads to less rounding errors\n",
    "    tmp = row.unsqueeze(0).clone().type(torch.FloatTensor)\n",
    "\n",
    "    res.append(processor(input_ids, tmp))\n",
    "    scores_self[i] = processor(input_ids, tmp) / generation_config.temperature\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5480000.0000,    16953.1250,    43125.0000,  ...,\n",
       "           -44375.0000,   -43750.0000,   -45937.5000],\n",
       "        [-3180000.0000,   -62187.5000,    11640.6250,  ...,\n",
       "           -63125.0000,   -45312.5000,   -70937.5000],\n",
       "        [-2560000.0000,   -80625.0000,    45000.0000,  ...,\n",
       "           -71562.5000,   -84375.0000,   -67187.5000],\n",
       "        ...,\n",
       "        [-2860000.0000,   -73750.0000,    51875.0000,  ...,\n",
       "           -47812.5000,   -57500.0000,   -60937.5000],\n",
       "        [-2840000.0000,   -74062.5000,   105000.0000,  ...,\n",
       "           -77500.0000,   -69062.5000,   -61875.0000],\n",
       "        [-4820000.0000,   -23125.0000,   168750.0000,  ...,\n",
       "           -64062.5000,   -61562.5000,   -51250.0000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32768, 249])\n",
      "torch.Size([249, 32768])\n",
      "torch.Size([1, 32768, 249])\n",
      "torch.Size([1, 32768, 249])\n",
      "torch.Size([1, 248])\n",
      "torch.Size([1, 249])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.5944, -12.4211, -10.8303, -10.2502,  -6.7545, -14.4436, -14.8937,\n",
       "         -11.8751, -12.7679,  -8.3280, -12.4921, -14.8516, -12.2119, -14.9990,\n",
       "         -14.1860, -12.9380, -17.8222, -12.1459,  -8.0014,  -8.8141, -22.2299,\n",
       "          -4.8453, -12.5011, -10.9393, -14.9311, -14.2549, -15.1632,  -6.6746,\n",
       "         -16.2790, -14.2631,  -4.3065, -13.6988,  -7.8448, -14.6946,  -7.8094,\n",
       "         -10.1293, -16.7325, -15.6250, -27.8126, -20.9063,  -2.1949, -13.1855,\n",
       "         -13.1616, -27.1836, -17.9704, -22.1720, -19.1727, -16.1875, -11.1255,\n",
       "         -22.7657, -21.9532, -17.9376, -16.0168, -12.3128, -18.8283, -22.4396,\n",
       "         -15.1592, -14.7189, -22.0314, -22.5156, -18.6406, -23.1250, -22.5247,\n",
       "         -10.5006, -21.2423, -17.4688, -21.7188, -16.2507, -13.3658, -15.9087,\n",
       "         -18.0314, -14.7500, -24.8750, -20.2813, -14.8928,  -5.4550, -12.6192,\n",
       "         -10.7569, -14.1770, -15.8129,  -7.1367, -15.5044, -11.3808, -11.5004,\n",
       "         -14.5989, -17.1250, -18.5330, -14.5287,  -5.2580,  -8.2505, -20.2135,\n",
       "         -20.1876, -11.9421, -14.0775, -11.9161, -14.0648,  -2.1575, -14.6880,\n",
       "         -13.3307,  -8.2968, -12.4669,  -5.6376,  -6.4482, -13.6544, -10.5654,\n",
       "          -0.8048,  -7.3137, -11.4553, -25.1563, -17.0737, -28.3125, -24.7075,\n",
       "         -10.4570, -15.0181, -13.4502, -13.1888, -10.3613, -15.9419, -11.5627,\n",
       "         -17.8807, -12.4395, -11.5626, -11.1251, -10.5123, -10.4906,  -5.1931,\n",
       "          -7.5322, -14.5488, -14.1638,  -7.9043, -12.6832, -12.6427,  -1.3789,\n",
       "         -14.9928, -13.9386,  -9.1777, -13.1601, -10.2431, -11.4065, -11.4575,\n",
       "          -6.7081, -14.2693,  -2.0069, -12.2804, -19.2393, -15.0314,  -1.8791,\n",
       "          -8.3335, -15.5116, -17.6598, -20.9376, -22.4688, -22.4691, -17.6563,\n",
       "         -17.9064, -14.8964,  -7.8196, -12.6272, -12.1250, -19.1317, -10.2595,\n",
       "          -7.3074,  -6.2460,  -5.6710,  -6.0520, -12.4101, -10.0002,  -1.2170,\n",
       "         -21.1721,  -8.6277,  -5.3801, -21.8439,  -7.5650, -11.3162, -21.2503,\n",
       "         -12.0001,  -6.7579, -10.3418, -10.8711, -15.8231, -15.5939,  -8.3810,\n",
       "         -16.4464,  -2.9402, -23.3886, -18.5000, -17.3756, -20.9462, -17.5002,\n",
       "         -15.7546, -16.0063, -11.5310, -14.3166, -13.2404,  -2.6992, -13.0046,\n",
       "         -12.5001,  -1.2554,  -1.1657, -22.3332, -12.3126, -10.5337, -16.4091,\n",
       "          -7.3176,  -0.5553, -11.8550, -21.2579, -12.4422, -11.1568, -19.7822,\n",
       "         -16.1879, -14.8753, -15.5318, -16.3438, -19.4222, -22.4026, -13.5062,\n",
       "         -18.8441, -11.7505, -16.8757,  -4.3479, -23.7950,  -7.3199, -18.5962,\n",
       "         -10.2077, -13.0000,  -7.5635, -19.0606, -12.2501, -14.1893, -20.0001,\n",
       "         -15.0314, -10.3058,  -4.2084, -12.6358, -20.9296, -18.3815, -16.3125,\n",
       "         -20.5336, -20.7993, -25.5625, -11.5633,  -0.8283, -14.6804, -15.5726,\n",
       "          -6.0145, -12.6464, -10.5024]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 32768\n",
    "scores_transition = scores_self.transpose(0, 1)\n",
    "print(scores_transition.shape)\n",
    "print(torch.stack(list(logits), dim=0).squeeze().shape)\n",
    "scores_transition = scores_transition.reshape(-1, vocab_size, scores_transition.shape[-1])\n",
    "print(scores_transition.shape)\n",
    "scores_transition = torch.nn.functional.log_softmax(scores_transition, dim=1)\n",
    "\n",
    "print(scores_transition.shape)\n",
    "print(sequence_ids_shifted.shape)\n",
    "print(sequences[:,input_ids.shape[1]:].shape)\n",
    "indices = sequence_ids_shifted\n",
    "\n",
    "# 8. Compute scores\n",
    "transition_scores_self = scores_transition.squeeze().gather(0, indices)\n",
    "transition_scores_self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_perplexity(log_probs):\n",
    "    total_log_prob = 0\n",
    "    for log_prob in log_probs:\n",
    "        total_log_prob += log_prob\n",
    "    perplexity = math.exp(-total_log_prob / len(log_probs))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERPLEXITY:  1.371638369396272\n",
      "|  5140 | answer   | -0.168 | 84.49%\n",
      "|  1224 | this     | -0.015 | 98.54%\n",
      "|  3764 | question | -1.224 | 29.42%\n",
      "| 29493 | ,        | -0.000 | 99.99%\n",
      "|  1246 | we       | -0.003 | 99.70%\n",
      "|  1695 | need     | -0.002 | 99.79%\n",
      "|  1066 | to       | -0.012 | 98.85%\n",
      "|  9819 | identify | -0.000 | 99.97%\n",
      "|  1040 | the      | -0.464 | 62.85%\n",
      "|  9064 | requirements | -0.038 | 96.28%\n",
      "|  1210 | or       | -1.039 | 35.39%\n",
      "|  1492 | pr       | -2.470 | 8.46%\n",
      "|  1165 | ere      | -0.620 | 53.77%\n",
      "| 11993 | quis     | -0.000 | 100.00%\n",
      "|  4155 | ites     | -0.000 | 99.99%\n",
      "|  7851 | mentioned | -0.000 | 99.99%\n",
      "|  1065 | in       | -2.054 | 12.82%\n",
      "|  1040 | the      | -0.063 | 93.91%\n",
      "|  3526 | context  | -0.000 | 99.96%\n",
      "|  1122 | for      | -0.079 | 92.40%\n",
      "| 24256 | admission | -0.143 | 86.64%\n",
      "|  1546 | into     | -1.099 | 33.31%\n",
      "|  1040 | the      | -0.704 | 49.48%\n",
      "| 10129 | Master   | -0.007 | 99.29%\n",
      "| 29510 | '        | -0.454 | 63.51%\n",
      "| 29481 | s        | -0.012 | 98.81%\n",
      "|  2775 | program  | -0.000 | 100.00%\n",
      "|  1065 | in       | -0.132 | 87.66%\n",
      "|  3365 | Me       | -0.014 | 98.62%\n",
      "| 13700 | chat     | -0.008 | 99.24%\n",
      "|  2457 | ron      | -0.000 | 99.99%\n",
      "|  1831 | ics      | -0.000 | 99.98%\n",
      "| 29491 | .        | -0.005 | 99.48%\n",
      "|  1183 | The      | -0.005 | 99.54%\n",
      "|  9366 | relevant | -0.467 | 62.70%\n",
      "|  2639 | information | -1.007 | 36.54%\n",
      "|  1309 | can      | -0.005 | 99.51%\n",
      "|  1115 | be       | -3.291 | 3.72%\n",
      "|  2187 | found    | -0.000 | 99.98%\n",
      "|  1684 | under    | -0.000 | 99.95%\n",
      "|  1040 | the      | -3.055 | 4.71%\n",
      "|  1851 | sub      | -0.172 | 84.21%\n",
      "|  3775 | section  | -0.767 | 46.42%\n",
      "|  1113 | \"        | -0.661 | 51.63%\n",
      "| 19030 | Stud     | -0.881 | 41.43%\n",
      "|  2143 | ien      | -2.331 | 9.72%\n",
      "| 29490 | f        | -0.035 | 96.55%\n",
      "|  7301 | äh       | -0.724 | 48.48%\n",
      "| 17902 | igkeit   | -0.013 | 98.69%\n",
      "| 29507 | \"        | -0.013 | 98.74%\n",
      "|  1072 | and      | -1.680 | 18.64%\n",
      "|  1146 | it       | -3.007 | 4.94%\n",
      "|  5266 | ment     | -2.574 | 7.63%\n",
      "|  1362 | ions     | -1.997 | 13.58%\n",
      "|  3716 | specific | -0.000 | 100.00%\n",
      "| 15885 | criteria | -1.958 | 14.11%\n",
      "|  1137 | that     | -1.883 | 15.21%\n",
      "|  2348 | must     | -1.480 | 22.76%\n",
      "|  1115 | be       | -1.034 | 35.55%\n",
      "|  2192 | met      | -0.000 | 99.97%\n",
      "|  1254 | by       | -0.038 | 96.28%\n",
      "|  5366 | applic   | -3.595 | 2.74%\n",
      "|  2317 | ants     | -0.150 | 86.03%\n",
      "| 29491 | .        | -0.000 | 99.99%\n",
      "|   781 | \n",
      "        | -0.103 | 90.18%\n",
      "|   781 | \n",
      "        | -0.233 | 79.19%\n",
      "|  1782 | The      | -0.001 | 99.87%\n",
      "|  3526 | context  | -1.156 | 31.48%\n",
      "|  5373 | states   | -0.168 | 84.51%\n",
      "| 29515 | :        | -0.212 | 80.89%\n",
      "|  1299 | ##       | -0.004 | 99.64%\n",
      "|  2125 | begin    | -1.756 | 17.27%\n",
      "| 29498 | _        | -0.000 | 99.97%\n",
      "| 15075 | quote    | -0.000 | 100.00%\n",
      "|  1832 | ##       | -0.000 | 99.99%\n",
      "| 22584 | \"(       | -0.003 | 99.68%\n",
      "| 29508 | 1        | -2.684 | 6.83%\n",
      "| 29499 | )        | -0.441 | 64.36%\n",
      "| 18802 | Für      | -0.001 | 99.85%\n",
      "|  1970 | die      | -2.260 | 10.44%\n",
      "|  1822 | Z        | -0.236 | 78.95%\n",
      "|  1121 | ul       | -0.529 | 58.94%\n",
      "|  1257 | ass      | -0.000 | 99.98%\n",
      "|  1737 | ung      | -0.000 | 99.99%\n",
      "|  1065 | in       | -0.003 | 99.71%\n",
      "|  8665 | einen    | -0.081 | 92.26%\n",
      "| 10129 | Master   | -1.057 | 34.75%\n",
      "|  1071 | st       | -0.093 | 91.09%\n",
      "| 11859 | udi      | -0.000 | 99.95%\n",
      "|  1748 | eng      | -0.000 | 99.99%\n",
      "|  1370 | ang      | -0.000 | 99.99%\n",
      "|  1659 | der      | -0.001 | 99.92%\n",
      "|  1169 | F        | -0.482 | 61.79%\n",
      "|  1363 | ach      | -0.075 | 92.78%\n",
      "| 17366 | richt    | -0.015 | 98.51%\n",
      "|  1737 | ung      | -0.000 | 99.96%\n",
      "|  1182 | \\        | -0.475 | 62.21%\n",
      "| 29479 | n        | -2.760 | 6.33%\n",
      "| 29523 | M        | -0.039 | 96.16%\n",
      "|  6063 | ech      | -0.261 | 77.05%\n",
      "|  1038 | at       | -0.265 | 76.73%\n",
      "|  2457 | ron      | -0.000 | 99.99%\n",
      "|  1617 | ik       | -0.000 | 99.99%\n",
      "|  1058 | m        | -0.000 | 100.00%\n",
      "|  2117 | uss      | -0.341 | 71.10%\n",
      "|  2564 | ein      | -0.429 | 65.13%\n",
      "|  3135 | mit      | -0.042 | 95.85%\n",
      "|  1659 | der      | -0.182 | 83.35%\n",
      "| 15451 | Mind     | -0.260 | 77.10%\n",
      "|  1142 | est      | -2.595 | 7.46%\n",
      "|  9606 | note     | -0.006 | 99.37%\n",
      "| 29473 |          | -0.004 | 99.61%\n",
      "| 29518 | 2        | -0.004 | 99.58%\n",
      "| 29493 | ,        | -0.001 | 99.92%\n",
      "| 29550 | 5        | -0.002 | 99.82%\n",
      "|  1302 | ab       | -0.455 | 63.42%\n",
      "| 13154 | gesch    | -0.002 | 99.80%\n",
      "|  9963 | loss     | -0.002 | 99.82%\n",
      "| 26632 | enes     | -0.001 | 99.86%\n",
      "|  6848 | gru      | -0.001 | 99.85%\n",
      "|  1060 | nd       | -0.614 | 54.14%\n",
      "| 22359 | ständ    | -0.000 | 100.00%\n",
      "| 22366 | iges     | -0.001 | 99.90%\n",
      "| 19970 | Hoch     | -0.001 | 99.86%\n",
      "|  3220 | sch      | -0.388 | 67.84%\n",
      "|  1121 | ul       | -0.004 | 99.57%\n",
      "| 13850 | stud     | -0.001 | 99.91%\n",
      "|  2730 | ium      | -0.001 | 99.88%\n",
      "|  1065 | in       | -0.001 | 99.92%\n",
      "|  7794 | einem    | -0.778 | 45.92%\n",
      "|  5674 | Stud     | -0.181 | 83.48%\n",
      "| 29478 | i        | -0.015 | 98.54%\n",
      "|  1748 | eng      | -0.001 | 99.90%\n",
      "|  1370 | ang      | -0.000 | 99.96%\n",
      "|  1659 | der      | -0.002 | 99.84%\n",
      "|  1169 | F        | -0.001 | 99.90%\n",
      "|  1363 | ach      | -0.003 | 99.71%\n",
      "| 17366 | richt    | -0.002 | 99.79%\n",
      "|  5308 | ungen    | -0.000 | 99.99%\n",
      "|  9951 | Mas      | -0.694 | 49.95%\n",
      "|  1106 | ch       | -1.071 | 34.28%\n",
      "| 10052 | inen     | -0.000 | 100.00%\n",
      "| 17623 | bau      | -0.000 | 99.98%\n",
      "| 29493 | ,        | -0.000 | 99.97%\n",
      "|  1182 | \\        | -0.013 | 98.67%\n",
      "| 29479 | n        | -0.525 | 59.16%\n",
      "| 29517 | E        | -0.000 | 99.98%\n",
      "|  1059 | le       | -0.002 | 99.80%\n",
      "|  3022 | kt       | -0.000 | 99.98%\n",
      "|  1079 | ro       | -0.005 | 99.48%\n",
      "| 29501 | -        | -3.168 | 4.21%\n",
      "|  1408 | und      | -0.205 | 81.48%\n",
      "|  9916 | Information | -0.131 | 87.69%\n",
      "|  3221 | ste      | -0.000 | 99.95%\n",
      "|  2586 | chn      | -0.000 | 100.00%\n",
      "|  1617 | ik       | -0.000 | 100.00%\n",
      "| 29493 | ,        | -0.000 | 100.00%\n",
      "|  1169 | F        | -0.051 | 95.03%\n",
      "|  9543 | ahr      | -0.117 | 88.98%\n",
      "| 19920 | zeug     | -0.000 | 99.98%\n",
      "| 23975 | techn    | -0.002 | 99.80%\n",
      "|  1617 | ik       | -0.000 | 99.99%\n",
      "|  8533 | oder     | -0.000 | 100.00%\n",
      "|  6752 | einer    | -0.634 | 53.03%\n",
      "| 14893 | verw     | -0.020 | 98.02%\n",
      "|  1159 | and      | -0.023 | 97.75%\n",
      "|  1978 | ten      | -0.000 | 99.98%\n",
      "|  1182 | \\        | -0.000 | 99.97%\n",
      "| 29479 | n        | -0.349 | 70.51%\n",
      "| 29533 | F        | -0.000 | 99.98%\n",
      "|  1363 | ach      | -0.000 | 99.99%\n",
      "| 17366 | richt    | -0.000 | 100.00%\n",
      "|  1737 | ung      | -0.000 | 100.00%\n",
      "|  7644 | vor      | -0.000 | 99.98%\n",
      "|  6483 | lie      | -0.286 | 75.13%\n",
      "|  3151 | gen      | -0.001 | 99.91%\n",
      "|  1379 | .\"       | -0.000 | 100.00%\n",
      "|  1299 | ##       | -3.112 | 4.45%\n",
      "|  1184 | end      | -0.003 | 99.75%\n",
      "| 29498 | _        | -0.000 | 99.98%\n",
      "| 15075 | quote    | -0.000 | 100.00%\n",
      "|  1832 | ##       | -0.000 | 100.00%\n",
      "|  1619 | This     | -0.000 | 100.00%\n",
      "|  8022 | transl   | -1.699 | 18.28%\n",
      "|  1770 | ates     | -0.625 | 53.52%\n",
      "|  1066 | to       | -0.000 | 100.00%\n",
      "| 29515 | :        | -0.001 | 99.87%\n",
      "|  1113 | \"        | -0.362 | 69.60%\n",
      "|  3333 | For      | -0.062 | 94.01%\n",
      "| 24256 | admission | -0.022 | 97.84%\n",
      "|  1546 | into     | -0.019 | 98.10%\n",
      "|  1032 | a        | -0.012 | 98.83%\n",
      "| 10129 | Master   | -0.387 | 67.90%\n",
      "| 29510 | '        | -0.015 | 98.53%\n",
      "| 29481 | s        | -0.000 | 99.95%\n",
      "|  2775 | program  | -0.000 | 100.00%\n",
      "|  1065 | in       | -0.006 | 99.41%\n",
      "|  1040 | the      | -0.000 | 99.96%\n",
      "|  2602 | field    | -0.435 | 64.74%\n",
      "|  1070 | of       | -0.030 | 97.08%\n",
      "|  3365 | Me       | -0.000 | 100.00%\n",
      "| 13700 | chat     | -0.003 | 99.72%\n",
      "|  2457 | ron      | -0.000 | 100.00%\n",
      "|  1831 | ics      | -0.000 | 100.00%\n",
      "| 29493 | ,        | -0.000 | 100.00%\n",
      "|  1032 | a        | -0.000 | 99.99%\n",
      "|  7239 | basic    | -0.015 | 98.52%\n",
      "| 11307 | university | -0.483 | 61.72%\n",
      "|  6921 | degree   | -0.185 | 83.08%\n",
      "|  1163 | with     | -0.081 | 92.20%\n",
      "|  1206 | at       | -2.485 | 8.34%\n",
      "|  3197 | least    | -2.242 | 10.62%\n",
      "|  1032 | a        | -0.000 | 99.99%\n",
      "| 12914 | grade    | -0.013 | 98.68%\n",
      "|  1070 | of       | -0.061 | 94.08%\n",
      "| 29473 |          | -0.007 | 99.29%\n",
      "| 29518 | 2        | -0.000 | 100.00%\n",
      "| 29491 | .        | -0.000 | 100.00%\n",
      "| 29550 | 5        | -0.000 | 99.97%\n",
      "|  2348 | must     | -0.000 | 99.97%\n",
      "|  1274 | have     | -0.079 | 92.39%\n",
      "|  1518 | been     | -0.835 | 43.38%\n",
      "|  8136 | completed | -0.000 | 99.97%\n",
      "|  1065 | in       | -0.003 | 99.69%\n",
      "|  1032 | a        | -0.000 | 99.99%\n",
      "|  3131 | course   | -0.095 | 90.90%\n",
      "|  1070 | of       | -0.089 | 91.47%\n",
      "|  4649 | study    | -0.012 | 98.83%\n",
      "|  1065 | in       | -0.013 | 98.75%\n",
      "|  1040 | the      | -0.011 | 98.94%\n",
      "|  5848 | fields   | -0.002 | 99.75%\n",
      "|  1070 | of       | -0.093 | 91.13%\n",
      "| 19600 | mechanical | -0.000 | 100.00%\n",
      "| 14088 | engineering | -1.510 | 22.09%\n",
      "| 29493 | ,        | -0.002 | 99.78%\n",
      "| 18596 | electrical | -0.000 | 99.98%\n",
      "|  1072 | and      | -0.004 | 99.63%\n",
      "|  2639 | information | -0.001 | 99.94%\n",
      "|  6282 | technology | -0.008 | 99.20%\n",
      "| 29493 | ,        | -0.000 | 99.99%\n",
      "|  5375 | autom    | -0.018 | 98.20%\n",
      "| 29306 | otive    | -1.694 | 18.38%\n",
      "| 14088 | engineering | -0.005 | 99.48%\n",
      "|  1210 | or       | -0.314 | 73.07%\n",
      "|  1032 | a        | -0.429 | 65.13%\n",
      "|  5970 | related  | -0.033 | 96.73%\n",
      "|  2602 | field    | -0.002 | 99.81%\n",
      "|  1379 | .\"       | -0.022 | 97.83%\n",
      "|   781 | \n",
      "        | -0.001 | 99.88%\n",
      "|   781 | \n",
      "        | -0.005 | 99.49%\n",
      "| 29557 | <        | -0.001 | 99.94%\n",
      "|  2019 | AN       | -0.564 | 56.88%\n",
      "| 10622 | SW       | -0.000 | 100.00%\n",
      "|  1493 | ER       | -0.011 | 98.89%\n",
      "| 10438 | >:       | -0.000 | 100.00%\n",
      "|  1183 | The      | -0.000 | 99.99%\n",
      "| 16937 | requirement | -0.155 | 85.65%\n",
      "|  1122 | for      | -3.572 | 2.81%\n",
      "| 24256 | admission | -0.112 | 89.43%\n",
      "|  1546 | into     | -0.017 | 98.33%\n",
      "|  1040 | the      | -0.017 | 98.32%\n",
      "| 10129 | Master   | -0.012 | 98.81%\n",
      "| 29510 | '        | -0.007 | 99.27%\n",
      "| 29481 | s        | -0.005 | 99.51%\n",
      "|  2775 | program  | -0.000 | 100.00%\n",
      "|  1065 | in       | -0.003 | 99.68%\n",
      "|  3365 | Me       | -0.004 | 99.57%\n",
      "| 13700 | chat     | -0.000 | 99.96%\n",
      "|  2457 | ron      | -0.000 | 100.00%\n",
      "|  1831 | ics      | -0.000 | 99.97%\n",
      "|  1117 | is       | -0.000 | 99.99%\n",
      "|  1032 | a        | -0.007 | 99.33%\n",
      "|  7239 | basic    | -0.145 | 86.48%\n",
      "| 11307 | university | -0.283 | 75.32%\n",
      "|  6921 | degree   | -0.023 | 97.71%\n",
      "|  1163 | with     | -0.000 | 99.99%\n",
      "|  1206 | at       | -0.177 | 83.80%\n",
      "|  3197 | least    | -0.090 | 91.43%\n",
      "|  1032 | a        | -0.000 | 99.98%\n",
      "| 12914 | grade    | -0.013 | 98.67%\n",
      "|  1070 | of       | -0.004 | 99.65%\n",
      "| 29473 |          | -0.001 | 99.92%\n",
      "| 29518 | 2        | -0.000 | 100.00%\n",
      "| 29491 | .        | -0.000 | 100.00%\n",
      "| 29550 | 5        | -0.000 | 100.00%\n",
      "|  1245 | from     | -0.000 | 99.99%\n",
      "|  1032 | a        | -2.100 | 12.24%\n",
      "|  3131 | course   | -0.013 | 98.68%\n",
      "|  1070 | of       | -0.025 | 97.52%\n",
      "|  4649 | study    | -0.005 | 99.52%\n",
      "|  1065 | in       | -0.000 | 100.00%\n",
      "|  1040 | the      | -0.002 | 99.78%\n",
      "|  5848 | fields   | -0.173 | 84.14%\n",
      "|  1070 | of       | -0.017 | 98.34%\n",
      "| 19600 | mechanical | -0.001 | 99.94%\n",
      "| 14088 | engineering | -0.000 | 99.95%\n",
      "| 29493 | ,        | -0.001 | 99.95%\n",
      "| 18596 | electrical | -0.000 | 99.99%\n",
      "|  1072 | and      | -0.000 | 99.99%\n",
      "|  2639 | information | -0.000 | 99.99%\n",
      "|  6282 | technology | -0.000 | 100.00%\n",
      "| 29493 | ,        | -0.000 | 100.00%\n",
      "|  5375 | autom    | -0.000 | 99.99%\n",
      "| 29306 | otive    | -0.001 | 99.91%\n",
      "| 14088 | engineering | -0.000 | 99.99%\n",
      "|  1210 | or       | -0.001 | 99.90%\n",
      "|  1032 | a        | -0.387 | 67.91%\n",
      "|  5970 | related  | -0.003 | 99.70%\n",
      "|  2602 | field    | -0.001 | 99.94%\n",
      "| 29491 | .        | -0.001 | 99.91%\n",
      "|     2 | </s>     | -0.001 | 99.91%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "transition_scores = model.compute_transition_scores(sequences, torch.unbind(scores_self.unsqueeze(1), dim=0), normalize_logits=True)\n",
    "\n",
    "generated_tokens = sequences[-1][input_ids.shape[1]:][1:]\n",
    "\n",
    "\n",
    "log_probs = transition_scores[0][:-1]\n",
    "\n",
    "\n",
    "print(\"PERPLEXITY: \", compute_perplexity(log_probs))\n",
    " \n",
    "for tok, score in zip(generated_tokens, log_probs):\n",
    "\n",
    "    # | token | token string | logits | probability\n",
    "\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## when do_sample=False it will work directly with the scores output without the preprocessing by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERPLEXITY:  1.9461695291850882\n",
      "|  1183 | The      | -3.542 | 2.89%\n",
      "|  3526 | context  | -1.157 | 31.44%\n",
      "|  6080 | provides | -0.329 | 71.98%\n",
      "|  3624 | several  | -2.505 | 8.17%\n",
      "|  3645 | options  | -0.345 | 70.85%\n",
      "|  1137 | that     | -1.684 | 18.56%\n",
      "|  1309 | can      | -0.010 | 98.98%\n",
      "|  7799 | serve    | -1.920 | 14.66%\n",
      "|  1158 | as       | -0.000 | 100.00%\n",
      "|  7935 | proof    | -0.255 | 77.52%\n",
      "|  1070 | of       | -0.013 | 98.75%\n",
      "|  6335 | German   | -0.004 | 99.58%\n",
      "|  4610 | language | -0.001 | 99.89%\n",
      "|  7034 | skills   | -0.186 | 83.02%\n",
      "| 29491 | .        | -0.338 | 71.34%\n",
      "|  3725 | These    | -0.599 | 54.92%\n",
      "|  3792 | include  | -0.038 | 96.32%\n",
      "| 29515 | :        | -0.182 | 83.35%\n",
      "|  1027 |          | -3.716 | 2.43%\n",
      "|   781 | \n",
      "        | -0.212 | 80.88%\n",
      "| 29508 | 1        | -1.278 | 27.85%\n",
      "| 29491 | .        | -0.010 | 99.01%\n",
      "|  1098 | A        | -0.080 | 92.27%\n",
      "| 16511 | certificate | -0.474 | 62.23%\n",
      "|  8870 | showing  | -2.526 | 8.00%\n",
      "|  6821 | successful | -1.172 | 30.99%\n",
      "| 15919 | completion | -0.004 | 99.55%\n",
      "|  1070 | of       | -0.016 | 98.39%\n",
      "|  1032 | a        | -1.794 | 16.62%\n",
      "|  3131 | course   | -1.981 | 13.79%\n",
      "|  1206 | at       | -1.264 | 28.25%\n",
      "|  2377 | Sch      | -7.905 | 0.04%\n",
      "|  2158 | ule      | -1.020 | 36.06%\n",
      "|  1210 | or       | -1.012 | 36.34%\n",
      "| 19970 | Hoch     | -0.694 | 49.96%\n",
      "|  3220 | sch      | -0.037 | 96.35%\n",
      "|  2158 | ule      | -0.006 | 99.36%\n",
      "|  2952 | level    | -1.376 | 25.26%\n",
      "|  1163 | with     | -1.477 | 22.84%\n",
      "|  5068 | English  | -0.030 | 97.09%\n",
      "| 10389 | taught   | -2.574 | 7.62%\n",
      "|  1158 | as       | -0.664 | 51.47%\n",
      "|  1040 | the      | -0.169 | 84.45%\n",
      "| 11080 | medium   | -1.760 | 17.20%\n",
      "|  1070 | of       | -0.010 | 99.00%\n",
      "| 13894 | instruction | -0.001 | 99.95%\n",
      "| 29493 | ,        | -1.636 | 19.48%\n",
      "|  1210 | or       | -2.457 | 8.57%\n",
      "|   781 | \n",
      "        | -2.755 | 6.36%\n",
      "| 29518 | 2        | -0.016 | 98.38%\n",
      "| 29491 | .        | -0.001 | 99.94%\n",
      "|  1098 | A        | -1.188 | 30.47%\n",
      "|  4016 | document | -0.958 | 38.38%\n",
      "| 24398 | stating  | -3.914 | 2.00%\n",
      "|  1137 | that     | -1.869 | 15.42%\n",
      "|  1040 | the      | -0.737 | 47.84%\n",
      "|  5366 | applic   | -0.279 | 75.63%\n",
      "|  1208 | ant      | -0.000 | 100.00%\n",
      "|  5991 | spent    | -1.019 | 36.09%\n",
      "|  1206 | at       | -0.156 | 85.54%\n",
      "|  3197 | least    | -0.000 | 100.00%\n",
      "|  4290 | six      | -0.002 | 99.77%\n",
      "|  4138 | months   | -0.000 | 99.99%\n",
      "|  1206 | at       | -1.991 | 13.65%\n",
      "|  2820 | school   | -0.998 | 36.87%\n",
      "| 29493 | ,        | -0.065 | 93.69%\n",
      "|  7070 | college  | -3.057 | 4.70%\n",
      "| 29493 | ,        | -0.214 | 80.72%\n",
      "|  1210 | or       | -0.255 | 77.46%\n",
      "|  2466 | another  | -0.365 | 69.42%\n",
      "| 14933 | educational | -0.021 | 97.96%\n",
      "| 17622 | institution | -0.001 | 99.93%\n",
      "|  1738 | where    | -0.074 | 92.84%\n",
      "|  5068 | English  | -0.008 | 99.23%\n",
      "|  1171 | was      | -0.004 | 99.61%\n",
      "|  2075 | used     | -0.968 | 37.98%\n",
      "|  1158 | as       | -0.003 | 99.69%\n",
      "|  1040 | the      | -0.009 | 99.14%\n",
      "|  4610 | language | -0.644 | 52.53%\n",
      "|  1070 | of       | -0.001 | 99.95%\n",
      "| 13894 | instruction | -0.041 | 95.97%\n",
      "| 29493 | ,        | -0.129 | 87.86%\n",
      "|  1210 | or       | -0.235 | 79.04%\n",
      "| 29473 |          | -3.131 | 4.37%\n",
      "|   781 | \n",
      "        | -0.003 | 99.73%\n",
      "| 29538 | 3        | -0.006 | 99.42%\n",
      "| 29491 | .        | -0.001 | 99.94%\n",
      "|  1098 | A        | -0.200 | 81.86%\n",
      "|  4016 | document | -0.301 | 74.01%\n",
      "| 18656 | indicating | -1.317 | 26.79%\n",
      "|  1137 | that     | -0.221 | 80.15%\n",
      "|  1040 | the      | -0.033 | 96.71%\n",
      "|  5366 | applic   | -0.070 | 93.26%\n",
      "|  1208 | ant      | -0.001 | 99.94%\n",
      "|  1427 | has      | -0.628 | 53.39%\n",
      "|  1518 | been     | -3.444 | 3.19%\n",
      "| 19604 | abroad   | -2.460 | 8.54%\n",
      "|  1065 | in       | -0.636 | 52.95%\n",
      "|  1164 | an       | -0.052 | 94.96%\n",
      "|  5068 | English  | -0.008 | 99.23%\n",
      "|  9479 | speaking | -0.747 | 47.37%\n",
      "|  3707 | country  | -0.001 | 99.93%\n",
      "|  1122 | for      | -0.008 | 99.21%\n",
      "|  1206 | at       | -0.234 | 79.13%\n",
      "|  3197 | least    | -0.002 | 99.82%\n",
      "|  4290 | six      | -0.027 | 97.36%\n",
      "|  4138 | months   | -0.004 | 99.63%\n",
      "|  1210 | or       | -0.429 | 65.14%\n",
      "|  1392 | one      | -0.016 | 98.39%\n",
      "|  4314 | sem      | -0.062 | 93.99%\n",
      "|  8701 | ester    | -0.000 | 100.00%\n",
      "| 29491 | .        | -0.042 | 95.84%\n",
      "|   781 | \n",
      "        | -0.883 | 41.35%\n",
      "|   781 | \n",
      "        | -0.300 | 74.07%\n",
      "| 29557 | <        | -0.942 | 38.99%\n",
      "|  2019 | AN       | -0.000 | 100.00%\n",
      "| 10622 | SW       | -0.001 | 99.88%\n",
      "|  1493 | ER       | -0.000 | 99.99%\n",
      "| 10438 | >:       | -0.000 | 99.99%\n",
      "|  1232 | '        | -3.309 | 3.65%\n",
      "| 29476 | a        | -5.027 | 0.66%\n",
      "| 29499 | )        | -2.205 | 11.02%\n",
      "|  1098 | A        | -1.599 | 20.21%\n",
      "|  3163 | record   | -4.872 | 0.77%\n",
      "|  8870 | showing  | -1.195 | 30.29%\n",
      "| 15919 | completion | -1.595 | 20.30%\n",
      "|  1070 | of       | -0.003 | 99.67%\n",
      "|  1032 | a        | -0.244 | 78.33%\n",
      "|  3131 | course   | -0.142 | 86.77%\n",
      "|  1206 | at       | -0.056 | 94.53%\n",
      "|  4996 | School   | -3.330 | 3.58%\n",
      "|  1210 | or       | -0.067 | 93.52%\n",
      "|  3668 | University | -0.092 | 91.25%\n",
      "|  2952 | level    | -0.291 | 74.72%\n",
      "|  1163 | with     | -0.337 | 71.36%\n",
      "|  5068 | English  | -0.004 | 99.58%\n",
      "| 10389 | taught   | -0.169 | 84.48%\n",
      "|  1158 | as       | -0.003 | 99.70%\n",
      "|  1040 | the      | -0.050 | 95.17%\n",
      "| 11080 | medium   | -0.172 | 84.23%\n",
      "|  1070 | of       | -0.005 | 99.53%\n",
      "| 13894 | instruction | -0.051 | 95.00%\n",
      "| 29493 | ,        | -0.491 | 61.19%\n",
      "|  1055 | b        | -0.388 | 67.83%\n",
      "| 29499 | )        | -0.006 | 99.37%\n",
      "|  1098 | A        | -0.150 | 86.10%\n",
      "|  7019 | statement | -0.736 | 47.90%\n",
      "|  8985 | regarding | -3.054 | 4.71%\n",
      "| 10749 | spending | -0.736 | 47.88%\n",
      "|  1206 | at       | -0.093 | 91.12%\n",
      "|  3197 | least    | -0.003 | 99.68%\n",
      "|  4290 | six      | -0.041 | 95.98%\n",
      "|  4138 | months   | -0.007 | 99.33%\n",
      "|  1206 | at       | -0.028 | 97.25%\n",
      "|  1032 | a        | -1.356 | 25.76%\n",
      "|  2820 | school   | -0.131 | 87.73%\n",
      "| 29493 | ,        | -0.017 | 98.28%\n",
      "|  7070 | college  | -0.258 | 77.28%\n",
      "| 29493 | ,        | -0.088 | 91.57%\n",
      "|  1210 | or       | -0.003 | 99.68%\n",
      "|  1567 | other    | -0.046 | 95.53%\n",
      "| 14933 | educational | -0.171 | 84.28%\n",
      "| 17622 | institution | -0.101 | 90.37%\n",
      "|  1738 | where    | -0.391 | 67.61%\n",
      "|  5068 | English  | -0.002 | 99.84%\n",
      "|  1171 | was      | -0.023 | 97.77%\n",
      "|  2075 | used     | -0.271 | 76.28%\n",
      "|  1158 | as       | -0.001 | 99.88%\n",
      "|  1040 | the      | -0.006 | 99.45%\n",
      "|  4610 | language | -0.043 | 95.84%\n",
      "|  1070 | of       | -0.001 | 99.87%\n",
      "| 13894 | instruction | -0.010 | 99.04%\n",
      "| 29493 | ,        | -0.046 | 95.48%\n",
      "|  1045 | c        | -0.831 | 43.56%\n",
      "| 29499 | )        | -0.002 | 99.80%\n",
      "|  1098 | A        | -0.042 | 95.91%\n",
      "| 20595 | declaration | -3.618 | 2.68%\n",
      "|  9503 | confirm  | -3.085 | 4.58%\n",
      "|  1056 | ing      | -0.000 | 100.00%\n",
      "|  2018 | being    | -0.810 | 44.48%\n",
      "| 19604 | abroad   | -0.084 | 91.91%\n",
      "|  1065 | in       | -0.020 | 98.01%\n",
      "|  1164 | an       | -0.017 | 98.36%\n",
      "|  5068 | English  | -0.003 | 99.66%\n",
      "|  9479 | speaking | -0.369 | 69.14%\n",
      "|  3707 | country  | -0.009 | 99.08%\n",
      "|  1122 | for      | -0.003 | 99.69%\n",
      "|  1206 | at       | -0.006 | 99.38%\n",
      "|  3197 | least    | -0.004 | 99.60%\n",
      "|  4290 | six      | -0.007 | 99.32%\n",
      "|  4138 | months   | -0.009 | 99.13%\n",
      "|  1210 | or       | -0.031 | 96.95%\n",
      "|  1392 | one      | -0.010 | 98.98%\n",
      "|  4314 | sem      | -0.014 | 98.60%\n",
      "|  8701 | ester    | -0.001 | 99.86%\n",
      "|  2583 | .'       | -0.024 | 97.59%\n",
      "|     2 | </s>     | -0.006 | 99.37%\n"
     ]
    }
   ],
   "source": [
    "transition_scores = model.compute_transition_scores(sequences, scores, normalize_logits=True)\n",
    "import numpy as np\n",
    "\n",
    "generated_tokens = sequences[-1][input_ids.shape[1]:]\n",
    "\n",
    "print(\"PERPLEXITY: \", compute_perplexity(transition_scores[0]))\n",
    "\n",
    "for tok, score in zip(generated_tokens, transition_scores[0]):\n",
    "\n",
    "    # | token | token string | logits | probability\n",
    "\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-548.0000,    1.6953,    3.5937,  ...,   -4.4375,   -4.3750,\n",
       "            -4.5938]]),\n",
       " tensor([[-318.0000,   -6.2188,    1.1641,  ...,   -6.3125,   -4.5312,\n",
       "            -7.0938]]),\n",
       " tensor([[-256.0000,   -8.0625,    4.5000,  ...,   -7.1562,   -8.4375,\n",
       "            -6.7188]]),\n",
       " tensor([[-274.0000,   -7.8125,    5.8125,  ...,   -6.8750,   -7.9062,\n",
       "            -7.7500]]),\n",
       " tensor([[-310.0000,   -7.1875,    3.8750,  ...,   -7.7812,   -7.6875,\n",
       "            -7.4062]]),\n",
       " tensor([[-304.0000,   -7.7500,    3.7969,  ...,   -6.7812,   -8.4375,\n",
       "            -7.5312]]),\n",
       " tensor([[-228.0000,   -9.2500,    4.1250,  ...,   -6.5000,   -8.8125,\n",
       "            -7.9688]]),\n",
       " tensor([[-280.0000,   -9.0625,    5.5000,  ...,   -7.4062,   -9.1250,\n",
       "            -9.6875]]),\n",
       " tensor([[-193.0000,   -8.1875,    3.1406,  ...,   -4.9062,   -6.5625,\n",
       "            -7.3750]]),\n",
       " tensor([[-310.0000,   -6.9688,    4.4062,  ...,   -6.6875,   -6.7812,\n",
       "            -6.2812]]),\n",
       " tensor([[-302.0000,   -6.7500,    2.2031,  ...,   -5.8750,   -5.9375,\n",
       "            -6.1875]]),\n",
       " tensor([[-234.0000,   -7.0938,    3.1719,  ...,   -8.9375,   -8.2500,\n",
       "            -6.5625]]),\n",
       " tensor([[-314.0000,   -7.1875,    3.7969,  ...,   -6.0938,   -7.1250,\n",
       "            -6.5938]]),\n",
       " tensor([[-294.0000,   -8.3750,    5.9062,  ...,   -6.4062,   -9.0000,\n",
       "            -8.0625]]),\n",
       " tensor([[-221.0000,   -8.5000,    5.8750,  ...,   -7.9375,   -8.2500,\n",
       "            -7.4688]]),\n",
       " tensor([[-376.0000,   -8.9375,    8.3750,  ...,   -9.1875,  -10.4375,\n",
       "            -9.5000]]),\n",
       " tensor([[-286.0000,   -8.8125,    6.8125,  ...,   -7.1562,   -7.9688,\n",
       "            -7.3125]]),\n",
       " tensor([[-332.0000,   -8.5000,    8.3750,  ...,   -9.1250,  -10.0625,\n",
       "            -9.2500]]),\n",
       " tensor([[-250.0000,  -10.3125,    7.0000,  ...,   -8.1250,   -6.7812,\n",
       "            -8.0000]]),\n",
       " tensor([[-191.0000,   -9.3750,    7.5312,  ...,   -7.2500,   -7.9375,\n",
       "            -8.1875]]),\n",
       " tensor([[-220.0000,   -9.7500,    7.6562,  ...,   -8.3750,   -8.8125,\n",
       "            -8.5625]]),\n",
       " tensor([[-366.0000,   -7.0312,    6.1250,  ...,   -9.6250,   -9.0000,\n",
       "            -6.8125]]),\n",
       " tensor([[-328.0000,   -8.1250,    7.0000,  ...,   -9.8125,   -9.6875,\n",
       "            -8.1875]]),\n",
       " tensor([[-512.0000,   -5.4688,    4.7500,  ...,   -7.5000,   -6.9062,\n",
       "            -7.4688]]),\n",
       " tensor([[-430.0000,   -5.6875,    3.6094,  ...,   -6.7500,   -6.5000,\n",
       "            -6.5625]]),\n",
       " tensor([[-446.0000,   -6.2812,    6.4375,  ...,   -7.8750,   -8.7500,\n",
       "            -7.2188]]),\n",
       " tensor([[-532.0000,   -4.5000,    6.3750,  ...,   -5.7188,   -7.0312,\n",
       "            -6.3438]]),\n",
       " tensor([[-408.0000,   -6.8750,    4.3750,  ...,   -5.3125,   -7.3125,\n",
       "            -5.9062]]),\n",
       " tensor([[-298.0000,   -8.4375,    6.4375,  ...,   -7.8125,   -8.0625,\n",
       "            -7.9688]]),\n",
       " tensor([[-246.0000,   -8.0000,    7.0312,  ...,   -8.0625,   -7.7812,\n",
       "            -7.8125]]),\n",
       " tensor([[-300.0000,   -7.3438,    4.5625,  ...,   -6.2500,   -9.4375,\n",
       "            -7.0625]]),\n",
       " tensor([[-290.0000,   -8.0625,    7.4062,  ...,   -9.5625,   -8.1875,\n",
       "            -6.4062]]),\n",
       " tensor([[-438.0000,   -5.5938,    5.9375,  ...,   -7.0000,   -6.9375,\n",
       "            -6.9062]]),\n",
       " tensor([[-366.0000,   -6.7188,    4.7188,  ...,   -7.0000,   -8.1875,\n",
       "            -6.3750]]),\n",
       " tensor([[-420.0000,   -6.1562,    4.5625,  ...,   -5.3750,   -6.5312,\n",
       "            -6.1250]]),\n",
       " tensor([[-664.0000,   -1.5938,    6.5938,  ...,   -6.3125,   -5.5938,\n",
       "            -6.0000]]),\n",
       " tensor([[-221.0000,   -3.1250,    3.0000,  ...,   -1.0469,   -4.6875,\n",
       "            -4.7812]]),\n",
       " tensor([[-197.0000,   -8.0000,    5.1562,  ...,   -6.1250,   -7.3125,\n",
       "            -7.2500]]),\n",
       " tensor([[-137.0000,    2.1719,    2.9844,  ...,    1.0938,   -1.3984,\n",
       "             1.4922]]),\n",
       " tensor([[-344.0000,   -2.2812,    4.9688,  ...,   -2.1094,   -5.4375,\n",
       "            -3.6250]]),\n",
       " tensor([[-540.0000,   -5.7500,    3.4219,  ...,   -6.2812,   -5.3750,\n",
       "            -5.5625]]),\n",
       " tensor([[-406.0000,   -3.8750,    3.1875,  ...,   -3.8750,   -2.4062,\n",
       "            -2.3750]]),\n",
       " tensor([[-220.0000,   -3.9062,    3.1406,  ...,   -5.4375,   -3.5156,\n",
       "            -1.7109]]),\n",
       " tensor([[-215.0000,   -5.4375,    3.3750,  ...,   -6.1250,   -5.5625,\n",
       "            -2.3281]]),\n",
       " tensor([[-382.0000,   -1.6875,    2.2812,  ...,   -4.1875,   -2.0625,\n",
       "            -4.1250]]),\n",
       " tensor([[-392.0000,   -9.0625,    3.8438,  ...,   -8.4375,   -7.0625,\n",
       "            -5.2188]]),\n",
       " tensor([[-508.0000,   -6.6250,    4.0312,  ...,   -6.0312,   -9.4375,\n",
       "            -7.3438]]),\n",
       " tensor([[-207.0000,   -7.6250,    4.5938,  ...,   -6.6875,   -6.9062,\n",
       "            -6.4375]]),\n",
       " tensor([[-284.0000,   -3.0625,    4.3750,  ...,   -4.1562,   -4.6250,\n",
       "            -4.5625]]),\n",
       " tensor([[-274.0000,   -7.1875,    2.6875,  ...,   -4.5312,   -5.0000,\n",
       "            -7.0000]]),\n",
       " tensor([[-191.0000,   -5.8125,    3.7812,  ...,   -6.5625,   -6.4375,\n",
       "            -5.2188]]),\n",
       " tensor([[-272.0000,   -9.5625,    3.5156,  ...,   -7.6875,   -8.5000,\n",
       "            -6.5938]]),\n",
       " tensor([[-386.0000,   -6.5312,    2.5781,  ...,   -7.7188,   -7.3125,\n",
       "            -4.4688]]),\n",
       " tensor([[-494.0000,   -7.0312,    3.9375,  ...,   -7.0625,   -8.1250,\n",
       "            -5.2500]]),\n",
       " tensor([[-472.0000,   -7.3750,    3.8281,  ...,   -6.8438,   -7.7500,\n",
       "            -6.4688]]),\n",
       " tensor([[-215.0000,   -2.6719,    3.1406,  ...,   -6.2188,   -3.3281,\n",
       "            -3.6406]]),\n",
       " tensor([[-396.0000,   -3.6875,    3.8594,  ...,   -4.3750,   -2.7656,\n",
       "            -4.9688]]),\n",
       " tensor([[-370.0000,   -6.7500,    3.1094,  ...,   -5.3438,   -5.3750,\n",
       "            -4.2500]]),\n",
       " tensor([[-464.0000,   -2.1562,    2.9375,  ...,   -3.3906,   -4.0000,\n",
       "            -2.2656]]),\n",
       " tensor([[-324.0000,   -6.3438,    4.0625,  ...,   -8.4375,   -5.0312,\n",
       "            -6.0000]]),\n",
       " tensor([[-484.0000,   -6.9375,    4.7812,  ...,   -8.0625,   -6.7812,\n",
       "            -5.4688]]),\n",
       " tensor([[-253.0000,   -6.3438,    5.2188,  ...,   -5.9375,   -3.1406,\n",
       "            -5.6562]]),\n",
       " tensor([[-213.0000,   -5.8438,    3.3750,  ...,   -8.1875,   -3.2031,\n",
       "            -3.7969]]),\n",
       " tensor([[-400.0000,   -7.6250,    5.1562,  ...,   -9.1875,   -4.4688,\n",
       "            -6.7188]]),\n",
       " tensor([[-442.0000,   -8.0000,    4.9375,  ...,   -6.9375,   -8.0625,\n",
       "            -7.2188]]),\n",
       " tensor([[-235.0000,   -5.9062,    4.1875,  ...,   -5.9375,   -5.5938,\n",
       "            -3.9688]]),\n",
       " tensor([[-185.0000,   -2.5312,    3.4688,  ...,   -4.1562,   -1.9688,\n",
       "            -3.4062]]),\n",
       " tensor([[-404.0000,   -5.8750,    4.0938,  ...,   -5.9688,   -4.9375,\n",
       "            -6.2812]]),\n",
       " tensor([[-442.0000,   -5.8438,    3.9375,  ...,   -7.1250,   -6.4062,\n",
       "            -4.8125]]),\n",
       " tensor([[-502.0000,   -3.5000,    8.2500,  ...,   -6.8750,   -6.7188,\n",
       "            -6.5000]]),\n",
       " tensor([[-171.0000,   -7.3750,    6.5625,  ...,   -8.1875,   -6.8750,\n",
       "            -4.5625]]),\n",
       " tensor([[-143.0000,   -7.9062,    5.4688,  ...,   -6.2812,   -4.8438,\n",
       "            -5.8438]]),\n",
       " tensor([[-208.0000,    2.7812,    3.5000,  ...,   -0.7500,   -1.1875,\n",
       "             0.2969]]),\n",
       " tensor([[-228.0000,   -4.3750,    6.3125,  ...,   -6.3125,   -6.5000,\n",
       "            -4.5625]]),\n",
       " tensor([[-512.0000,   -5.2500,    7.0000,  ...,   -9.0000,   -6.8438,\n",
       "            -6.5938]]),\n",
       " tensor([[-302.0000,   -6.9375,    4.9688,  ...,   -8.9375,   -7.6875,\n",
       "            -6.6250]]),\n",
       " tensor([[-276.0000,   -8.3125,    4.6562,  ...,   -7.6875,   -8.6875,\n",
       "            -7.6250]]),\n",
       " tensor([[-290.0000,   -7.6562,    7.8438,  ...,   -8.5625,   -8.6875,\n",
       "            -6.3750]]),\n",
       " tensor([[-189.0000,   -7.5000,    2.9375,  ...,   -6.2500,   -7.2500,\n",
       "            -5.1562]]),\n",
       " tensor([[-219.0000,   -8.6250,    9.0000,  ...,   -7.5000,   -6.6875,\n",
       "            -7.2812]]),\n",
       " tensor([[-234.0000,   -7.5938,    5.0000,  ...,   -6.5312,   -7.9062,\n",
       "            -6.8125]]),\n",
       " tensor([[-231.0000,   -8.1250,    6.3750,  ...,   -6.8750,   -8.5625,\n",
       "            -5.8438]]),\n",
       " tensor([[-244.0000,   -7.0625,    7.3125,  ...,   -9.9375,   -8.5000,\n",
       "            -7.1562]]),\n",
       " tensor([[-253.0000,   -7.5000,    6.2500,  ...,   -6.5312,   -7.2812,\n",
       "            -7.0938]]),\n",
       " tensor([[-268.0000,   -7.6875,    7.1875,  ...,   -6.1562,   -9.3125,\n",
       "            -8.0625]]),\n",
       " tensor([[-290.0000,   -9.5625,    9.7500,  ...,   -7.7812,  -10.6875,\n",
       "            -8.3750]]),\n",
       " tensor([[-239.0000,   -9.1250,    6.0938,  ...,   -7.1875,   -8.1875,\n",
       "            -7.8438]]),\n",
       " tensor([[-292.0000,   -7.4062,    8.5000,  ...,   -8.2500,   -9.1875,\n",
       "            -8.5000]]),\n",
       " tensor([[-221.0000,   -9.8750,    6.6875,  ...,   -8.3125,   -7.2188,\n",
       "            -7.8750]]),\n",
       " tensor([[-209.0000,  -10.1250,    9.5000,  ...,   -8.8750,   -8.8125,\n",
       "            -9.5000]]),\n",
       " tensor([[-211.0000,   -9.5000,    9.3750,  ...,   -7.8125,   -8.8125,\n",
       "            -8.2500]]),\n",
       " tensor([[-157.0000,   -7.5625,    7.9688,  ...,   -7.2812,   -6.9062,\n",
       "            -5.5000]]),\n",
       " tensor([[-328.0000,   -6.1562,    7.4062,  ...,   -7.8125,   -6.7500,\n",
       "            -7.0000]]),\n",
       " tensor([[-460.0000,   -4.5000,    7.8750,  ...,   -7.5312,   -5.0938,\n",
       "            -5.3438]]),\n",
       " tensor([[-322.0000,   -6.1562,    2.8906,  ...,   -5.8438,   -6.0312,\n",
       "            -4.0000]]),\n",
       " tensor([[-262.0000,   -7.7500,    7.1250,  ...,   -7.5938,   -7.4688,\n",
       "            -7.0625]]),\n",
       " tensor([[-258.0000,   -7.4062,    6.7812,  ...,   -6.5000,   -7.5000,\n",
       "            -4.6562]]),\n",
       " tensor([[-278.0000,   -8.5000,    9.6875,  ...,   -7.1250,   -9.0000,\n",
       "            -5.8125]]),\n",
       " tensor([[-270.0000,   -7.3750,    6.5625,  ...,   -8.3750,   -7.2500,\n",
       "            -7.5312]]),\n",
       " tensor([[-264.0000,   -7.4688,    4.6875,  ...,   -6.1875,   -8.5000,\n",
       "            -7.1875]]),\n",
       " tensor([[-215.0000,   -8.2500,    5.9375,  ...,   -7.5938,   -7.9375,\n",
       "            -6.7812]]),\n",
       " tensor([[-318.0000,   -6.7500,    4.8125,  ...,   -5.9375,   -6.3438,\n",
       "            -6.6562]]),\n",
       " tensor([[-304.0000,   -5.8750,    4.4062,  ...,   -5.8125,   -6.0625,\n",
       "            -5.0312]]),\n",
       " tensor([[-282.0000,   -6.9375,    3.7656,  ...,   -5.8125,   -6.1562,\n",
       "            -6.2812]]),\n",
       " tensor([[-348.0000,   -7.7188,    5.3750,  ...,   -7.6250,   -6.4375,\n",
       "            -6.2500]]),\n",
       " tensor([[-516.0000,   -4.3125,    8.0000,  ...,   -5.6250,   -5.9062,\n",
       "            -5.7500]]),\n",
       " tensor([[-360.0000,   -4.1250,    3.8281,  ...,   -3.5156,   -3.1406,\n",
       "            -3.6094]]),\n",
       " tensor([[-414.0000,   -4.5312,    3.5469,  ...,   -3.1406,   -3.2344,\n",
       "            -2.0156]]),\n",
       " tensor([[-322.0000,   -6.5000,    1.5000,  ...,   -5.4062,   -6.2812,\n",
       "            -4.1562]]),\n",
       " tensor([[-220.0000,   -6.9688,    2.5938,  ...,   -7.0312,   -5.6250,\n",
       "            -5.6562]]),\n",
       " tensor([[-208.0000,   -7.3125,    1.9141,  ...,   -8.6875,   -7.8125,\n",
       "            -5.9688]]),\n",
       " tensor([[-298.0000,   -8.6250,    6.8750,  ...,   -7.7812,   -8.1250,\n",
       "            -6.9375]]),\n",
       " tensor([[-448.0000,   -5.4062,    3.0469,  ...,   -6.2812,   -5.9375,\n",
       "            -6.3750]]),\n",
       " tensor([[-516.0000,   -5.1562,    5.9688,  ...,   -6.4688,   -7.2188,\n",
       "            -6.5625]]),\n",
       " tensor([[-187.0000,   -3.4844,    2.9062,  ...,   -1.0859,   -5.8438,\n",
       "            -4.3125]]),\n",
       " tensor([[-162.0000,   -7.3125,    6.2812,  ...,   -5.6562,   -5.7500,\n",
       "            -6.5938]]),\n",
       " tensor([[-147.0000,   -0.7070,    4.1875,  ...,   -1.1562,   -3.0312,\n",
       "            -0.4668]]),\n",
       " tensor([[-207.0000,   -6.5312,    6.0625,  ...,   -5.7500,   -5.8125,\n",
       "            -5.9062]]),\n",
       " tensor([[-544.0000,   -5.7500,    3.2344,  ...,   -5.3750,   -6.2188,\n",
       "            -6.6250]]),\n",
       " tensor([[-382.0000,   -3.9062,    3.2969,  ...,   -4.2500,   -3.1094,\n",
       "            -2.3594]]),\n",
       " tensor([[-416.0000,   -5.9375,    3.2500,  ...,   -5.1250,   -4.2812,\n",
       "            -5.1875]]),\n",
       " tensor([[-172.0000,   -4.4375,    2.5625,  ...,   -3.4844,   -4.7500,\n",
       "            -2.9219]]),\n",
       " tensor([[-258.0000,   -6.4688,    3.6094,  ...,   -6.2812,   -6.2188,\n",
       "            -6.2188]]),\n",
       " tensor([[-316.0000,   -4.5625,    4.5312,  ...,   -6.0312,   -4.5000,\n",
       "            -3.7344]]),\n",
       " tensor([[-245.0000,   -8.6250,    4.9375,  ...,   -6.6875,   -5.2812,\n",
       "            -5.0000]]),\n",
       " tensor([[-165.0000,   -8.5000,    3.2188,  ...,   -7.3750,   -7.4375,\n",
       "            -6.6250]]),\n",
       " tensor([[-334.0000,   -8.3125,    2.3281,  ...,   -7.3750,   -6.4062,\n",
       "            -6.1250]]),\n",
       " tensor([[-416.0000,   -7.0625,    2.8281,  ...,   -7.0000,   -6.5938,\n",
       "            -5.9062]]),\n",
       " tensor([[-414.0000,   -7.6562,    3.7812,  ...,   -7.5312,   -7.0312,\n",
       "            -7.4688]]),\n",
       " tensor([[-486.0000,   -7.1562,    4.2812,  ...,   -5.0625,   -7.8750,\n",
       "            -6.5312]]),\n",
       " tensor([[-374.0000,   -4.4375,    4.0625,  ...,   -6.7812,   -3.9219,\n",
       "            -4.1562]]),\n",
       " tensor([[-251.0000,  -10.2500,    4.5000,  ...,  -12.0625,   -7.5312,\n",
       "            -6.2500]]),\n",
       " tensor([[-384.0000,   -7.8750,    2.2500,  ...,   -9.3750,   -6.7500,\n",
       "            -4.5000]]),\n",
       " tensor([[-470.0000,   -7.9688,    4.6875,  ...,   -7.6250,   -7.6875,\n",
       "            -6.6562]]),\n",
       " tensor([[-211.0000,   -2.7656,    3.8906,  ...,   -6.3750,   -3.2656,\n",
       "            -3.9375]]),\n",
       " tensor([[-400.0000,   -8.1250,    6.3125,  ...,   -7.6875,   -5.6875,\n",
       "            -4.3125]]),\n",
       " tensor([[-524.0000,   -6.2188,    5.7188,  ...,   -7.1562,   -3.3750,\n",
       "            -6.7812]]),\n",
       " tensor([[-214.0000,   -7.1250,    4.8125,  ...,   -6.7188,   -4.0312,\n",
       "            -5.3438]]),\n",
       " tensor([[-200.0000,   -7.8438,    3.3438,  ...,   -6.9375,   -4.7188,\n",
       "            -5.7188]]),\n",
       " tensor([[-227.0000,   -6.8125,    4.7188,  ...,   -5.0312,   -5.2812,\n",
       "            -6.5000]]),\n",
       " tensor([[-262.0000,   -6.0625,    4.5938,  ...,   -9.3750,   -4.6250,\n",
       "            -3.6719]]),\n",
       " tensor([[-127.0000,   -5.7500,    5.2500,  ...,   -5.4062,   -3.7031,\n",
       "            -4.3750]]),\n",
       " tensor([[-250.0000,   -8.2500,    4.1875,  ...,   -9.6875,   -7.1250,\n",
       "            -6.6875]]),\n",
       " tensor([[-362.0000,   -6.9062,    2.0781,  ...,   -6.4688,   -5.3750,\n",
       "            -3.0156]]),\n",
       " tensor([[-472.0000,   -7.4375,    5.9688,  ...,   -5.7500,   -7.4375,\n",
       "            -7.0938]]),\n",
       " tensor([[-160.0000,   -8.0000,    4.4688,  ...,   -9.1875,   -5.7500,\n",
       "            -6.1562]]),\n",
       " tensor([[-264.0000,   -6.5000,    5.8125,  ...,   -5.4375,   -4.3125,\n",
       "            -5.3438]]),\n",
       " tensor([[-113.0000,   -5.7812,    5.1875,  ...,   -7.5000,   -6.2188,\n",
       "            -5.6875]]),\n",
       " tensor([[-326.0000,   -9.2500,    4.4062,  ...,   -5.8750,   -7.1875,\n",
       "            -8.0625]]),\n",
       " tensor([[-516.0000,   -7.3750,    4.3750,  ...,   -8.0625,   -8.3750,\n",
       "            -6.4375]]),\n",
       " tensor([[-350.0000,   -5.2812,    5.6250,  ...,   -6.9688,   -6.5938,\n",
       "            -3.9688]]),\n",
       " tensor([[-442.0000,   -8.6250,    6.1875,  ...,   -9.1875,   -9.3125,\n",
       "            -7.2188]]),\n",
       " tensor([[-241.0000,   -6.8750,    5.4375,  ...,   -6.6875,   -7.3125,\n",
       "            -6.2188]]),\n",
       " tensor([[-288.0000,   -7.9688,    6.2188,  ...,   -7.3438,   -7.3438,\n",
       "            -8.1875]]),\n",
       " tensor([[-460.0000,   -8.8125,    6.5312,  ...,   -8.8750,   -9.1250,\n",
       "            -6.9062]]),\n",
       " tensor([[-190.0000,   -7.3438,    6.8750,  ...,   -6.6562,   -4.4062,\n",
       "            -4.5938]]),\n",
       " tensor([[-248.0000,  -10.1250,    6.8438,  ...,   -9.0625,   -5.3438,\n",
       "            -7.0000]]),\n",
       " tensor([[-408.0000,   -5.7188,    4.3438,  ...,   -6.1562,   -6.3438,\n",
       "            -5.0312]]),\n",
       " tensor([[-422.0000,   -3.8750,   10.1250,  ...,   -7.8438,   -7.3750,\n",
       "            -5.4062]]),\n",
       " tensor([[-192.0000,   -8.1250,    6.2500,  ...,   -8.3750,   -8.5625,\n",
       "            -4.9688]]),\n",
       " tensor([[-141.0000,   -8.6250,    5.8125,  ...,   -6.0938,   -6.0000,\n",
       "            -6.2500]]),\n",
       " tensor([[-1.2600e+02, -9.5215e-02,  4.0312e+00,  ..., -2.2188e+00,\n",
       "          -1.9922e+00, -4.9219e-01]]),\n",
       " tensor([[-207.0000,   -5.0000,    7.7188,  ...,   -6.8125,   -6.4062,\n",
       "            -6.3125]]),\n",
       " tensor([[-396.0000,   -6.1562,    6.1875,  ...,   -8.6875,   -7.0000,\n",
       "            -6.2500]]),\n",
       " tensor([[-272.0000,   -6.0625,    2.9844,  ...,   -6.9062,   -7.9688,\n",
       "            -6.4062]]),\n",
       " tensor([[-175.0000,   -8.2500,    7.7812,  ...,   -6.9688,   -6.0938,\n",
       "            -5.7500]]),\n",
       " tensor([[-284.0000,   -8.0000,    7.7500,  ...,   -9.4375,   -7.9688,\n",
       "            -8.9375]]),\n",
       " tensor([[-270.0000,   -8.0625,    3.9062,  ...,   -5.4688,   -6.0625,\n",
       "            -6.4062]]),\n",
       " tensor([[-172.0000,   -5.0000,    4.0000,  ...,   -3.2344,   -0.6211,\n",
       "            -1.7344]]),\n",
       " tensor([[-144.0000,   -6.5312,    1.5625,  ...,   -4.4688,   -4.0312,\n",
       "            -4.5938]]),\n",
       " tensor([[-68.5000,  -8.5625,   4.5000,  ...,  -6.4375,  -5.9062,  -6.9375]]),\n",
       " tensor([[-153.0000,   -6.9062,    3.1250,  ...,   -8.3125,   -6.5000,\n",
       "            -8.5000]]),\n",
       " tensor([[-184.0000,   -8.2500,    5.2188,  ...,   -6.3750,   -4.8125,\n",
       "            -6.0625]]),\n",
       " tensor([[-149.0000,   -8.0000,    5.4375,  ...,   -6.3750,   -5.7188,\n",
       "            -5.5000]]),\n",
       " tensor([[-140.0000,   -6.5625,    7.0000,  ...,   -5.0625,   -4.1250,\n",
       "            -3.6094]]),\n",
       " tensor([[-149.0000,   -8.0625,    7.8750,  ...,   -7.7500,   -5.1250,\n",
       "            -4.6250]]),\n",
       " tensor([[-41.5000,  -5.2188,   5.0000,  ...,  -2.8281,  -2.2656,  -1.5469]]),\n",
       " tensor([[-152.0000,   -9.7500,   10.0625,  ...,   -9.8125,   -6.5625,\n",
       "            -5.9062]]),\n",
       " tensor([[-145.0000,   -6.9062,    2.4531,  ...,   -8.4375,   -5.8438,\n",
       "            -5.8750]]),\n",
       " tensor([[-122.5000,   -8.6875,    4.8125,  ...,   -6.3750,   -5.5938,\n",
       "            -5.5312]]),\n",
       " tensor([[-211.0000,   -8.3750,    6.9062,  ...,   -6.7812,   -4.6250,\n",
       "            -6.9375]]),\n",
       " tensor([[-125.5000,   -7.0000,    3.0938,  ...,   -6.4375,   -3.3438,\n",
       "            -5.2188]]),\n",
       " tensor([[-98.0000,  -8.6875,   6.2500,  ...,  -6.8750,  -6.3125,  -6.8125]]),\n",
       " tensor([[-243.0000,   -8.5625,    7.0000,  ...,   -9.4375,   -7.7812,\n",
       "            -7.3125]]),\n",
       " tensor([[-286.0000,   -6.7188,    5.8438,  ...,   -6.5312,   -6.8750,\n",
       "            -5.8438]]),\n",
       " tensor([[-217.0000,   -6.5312,    2.6719,  ...,   -6.6875,   -5.8750,\n",
       "            -5.1875]]),\n",
       " tensor([[-90.5000,  -4.9688,   3.9062,  ...,  -3.1250,  -2.9219,  -5.5000]]),\n",
       " tensor([[-106.5000,   -3.8125,    3.9688,  ...,   -3.8906,   -2.4375,\n",
       "            -3.0312]]),\n",
       " tensor([[-115.5000,   -7.1562,    5.4062,  ...,   -7.6250,   -5.4375,\n",
       "            -4.5625]]),\n",
       " tensor([[-88.0000,  -7.0000,   3.7500,  ...,  -8.9375,  -6.0625,  -5.7500]]),\n",
       " tensor([[-254.0000,   -7.7500,    4.8438,  ...,  -10.5000,   -7.8750,\n",
       "            -8.1250]]),\n",
       " tensor([[-258.0000,   -7.2188,    5.4375,  ...,   -9.4375,   -7.0000,\n",
       "            -5.9062]]),\n",
       " tensor([[-198.0000,   -7.2188,    5.9688,  ...,   -9.3125,   -6.3750,\n",
       "            -5.0000]]),\n",
       " tensor([[-224.0000,   -7.8125,    8.4375,  ...,   -9.7500,   -8.5000,\n",
       "            -5.9062]]),\n",
       " tensor([[-236.0000,   -7.5312,    9.2500,  ...,   -9.2500,   -8.1250,\n",
       "            -6.1250]]),\n",
       " tensor([[-145.0000,   -6.5312,    8.8750,  ...,   -5.6250,   -4.1562,\n",
       "            -3.8125]]),\n",
       " tensor([[-192.0000,   -8.6250,    8.1250,  ...,   -8.1250,   -4.9062,\n",
       "            -6.0625]]),\n",
       " tensor([[-184.0000,   -7.6875,    7.5625,  ...,   -7.5312,   -5.9688,\n",
       "            -6.3125]]),\n",
       " tensor([[-398.0000,   -5.8750,    8.6875,  ...,   -8.0000,   -7.2188,\n",
       "            -5.1875]]),\n",
       " tensor([[-378.0000,   -4.1250,    5.2812,  ...,   -3.9844,   -4.3438,\n",
       "            -3.9219]]),\n",
       " tensor([[-270.0000,   -4.9062,    5.8438,  ...,   -4.1250,   -3.2188,\n",
       "            -1.8516]]),\n",
       " tensor([[-296.0000,   -8.1875,    5.5312,  ...,   -8.2500,   -6.5625,\n",
       "            -5.9375]]),\n",
       " tensor([[-219.0000,   -8.0625,    3.6094,  ...,   -8.5625,   -6.0625,\n",
       "            -5.6562]]),\n",
       " tensor([[-196.0000,   -8.1250,    2.8750,  ...,   -8.4375,   -6.6875,\n",
       "            -6.5938]]),\n",
       " tensor([[-284.0000,   -8.9375,    5.5938,  ...,   -7.7500,   -7.8438,\n",
       "            -7.0000]]),\n",
       " tensor([[-356.0000,   -7.4688,    5.0000,  ...,   -7.5312,   -6.7188,\n",
       "            -7.0000]]),\n",
       " tensor([[-392.0000,   -5.9375,    7.9062,  ...,   -8.3750,   -6.7188,\n",
       "            -5.8125]]),\n",
       " tensor([[-166.0000,   -4.4688,    4.0312,  ...,   -2.2344,   -6.2188,\n",
       "            -5.2812]]),\n",
       " tensor([[-142.0000,   -7.9688,    6.5000,  ...,   -5.5938,   -5.7812,\n",
       "            -6.5312]]),\n",
       " tensor([[-1.4300e+02,  7.3828e-01,  3.2188e+00,  ..., -1.2969e+00,\n",
       "          -1.2578e+00, -8.3496e-02]]),\n",
       " tensor([[-205.0000,   -6.5312,    6.3125,  ...,   -5.8750,   -6.5938,\n",
       "            -6.5625]]),\n",
       " tensor([[-480.0000,   -7.1562,    5.0312,  ...,   -5.4375,   -5.5938,\n",
       "            -6.4375]]),\n",
       " tensor([[-2.9400e+02, -3.6406e+00,  3.7031e+00,  ..., -2.6406e+00,\n",
       "          -1.3184e-01, -4.6094e-01]]),\n",
       " tensor([[-450.0000,   -6.9062,    3.4688,  ...,   -4.8438,   -6.1250,\n",
       "            -6.0000]]),\n",
       " tensor([[-408.0000,   -6.6875,    3.2031,  ...,   -7.7812,   -4.9688,\n",
       "            -5.9375]]),\n",
       " tensor([[-452.0000,   -6.0312,    5.4688,  ...,   -5.4375,   -6.5000,\n",
       "            -5.9375]]),\n",
       " tensor([[-446.0000,   -5.0938,    4.4375,  ...,   -6.9375,   -5.3125,\n",
       "            -5.2188]]),\n",
       " tensor([[-188.0000,   -6.7188,    2.7188,  ...,   -6.2500,   -3.4531,\n",
       "            -3.6406]]),\n",
       " tensor([[-203.0000,   -5.6562,    2.5938,  ...,   -7.0000,   -4.9688,\n",
       "            -5.1875]]),\n",
       " tensor([[-266.0000,   -3.9531,    3.2500,  ...,   -4.2188,   -5.5312,\n",
       "            -5.5938]]),\n",
       " tensor([[-207.0000,   -7.1562,    4.0312,  ...,   -7.4688,   -4.1250,\n",
       "            -7.0938]]),\n",
       " tensor([[-462.0000,   -6.6562,    3.9844,  ...,   -7.1250,   -8.0625,\n",
       "            -7.9688]]),\n",
       " tensor([[-304.0000,   -5.1875,    5.0312,  ...,   -2.1094,   -0.3398,\n",
       "            -2.1719]]),\n",
       " tensor([[-298.0000,   -6.5625,    3.9062,  ...,   -4.9062,   -3.0156,\n",
       "            -6.1250]]),\n",
       " tensor([[-280.0000,   -6.1875,    6.6562,  ...,   -5.8125,   -5.2500,\n",
       "            -4.1250]]),\n",
       " tensor([[-229.0000,   -8.1250,    3.9062,  ...,   -6.0938,   -5.7188,\n",
       "            -6.1875]]),\n",
       " tensor([[-456.0000,   -7.3750,    4.2500,  ...,   -8.3125,   -8.5000,\n",
       "            -6.2812]]),\n",
       " tensor([[-352.0000,   -3.2344,    2.6719,  ...,   -4.7500,   -3.3438,\n",
       "            -2.3125]]),\n",
       " tensor([[-312.0000,   -7.8438,    6.0938,  ...,   -8.2500,   -8.8750,\n",
       "            -6.1250]]),\n",
       " tensor([[-428.0000,   -6.7188,    4.3125,  ...,   -8.3125,   -5.3125,\n",
       "            -3.2344]]),\n",
       " tensor([[-418.0000,   -6.0312,    4.0000,  ...,   -6.8750,   -7.8438,\n",
       "            -5.1250]]),\n",
       " tensor([[-229.0000,   -4.0312,    3.6719,  ...,   -5.6562,   -5.8750,\n",
       "            -6.2500]]),\n",
       " tensor([[-262.0000,   -1.7266,    2.5781,  ...,   -4.2812,   -4.3125,\n",
       "            -3.4062]]),\n",
       " tensor([[-438.0000,   -6.8750,    4.9062,  ...,   -7.5938,   -6.4688,\n",
       "            -2.5000]]),\n",
       " tensor([[-233.0000,   -8.0625,    5.2812,  ...,   -8.5625,   -5.8125,\n",
       "            -6.7812]]),\n",
       " tensor([[-318.0000,   -6.1250,    5.2812,  ...,   -7.8438,   -6.7812,\n",
       "            -6.2188]]),\n",
       " tensor([[-484.0000,   -6.9375,    4.5000,  ...,   -8.3125,   -6.0625,\n",
       "            -5.2500]]),\n",
       " tensor([[-512.0000,   -5.4375,    4.0938,  ...,   -5.5000,   -6.9375,\n",
       "            -7.4375]]),\n",
       " tensor([[-243.0000,   -8.5000,    4.4688,  ...,   -7.6875,   -5.7812,\n",
       "            -6.7188]]),\n",
       " tensor([[-352.0000,   -8.3750,    5.3125,  ...,   -6.5938,   -6.1562,\n",
       "            -6.1250]]),\n",
       " tensor([[-424.0000,   -8.1250,    5.3750,  ...,   -8.3750,   -7.5625,\n",
       "            -7.5938]]),\n",
       " tensor([[-370.0000,   -6.9062,    4.5938,  ...,   -4.7812,   -7.3438,\n",
       "            -7.1562]]),\n",
       " tensor([[-512.0000,   -5.5625,    5.4688,  ...,   -4.6250,   -6.5000,\n",
       "            -6.9375]]),\n",
       " tensor([[-368.0000,   -6.6562,    7.0000,  ...,   -4.5312,   -7.1250,\n",
       "            -7.0000]]),\n",
       " tensor([[-478.0000,   -4.0938,    3.0000,  ...,   -4.8750,   -4.8750,\n",
       "            -5.3438]]),\n",
       " tensor([[-191.0000,   -1.6250,    1.6797,  ...,   -4.3438,   -4.2812,\n",
       "            -2.0312]]),\n",
       " tensor([[-374.0000,   -4.8125,    3.3438,  ...,   -5.0000,   -5.7812,\n",
       "            -4.5000]]),\n",
       " tensor([[-408.0000,   -7.6875,    4.5000,  ...,   -6.5312,   -6.5000,\n",
       "            -5.9062]]),\n",
       " tensor([[-390.0000,   -4.6250,    8.0625,  ...,   -6.3438,   -7.1562,\n",
       "            -5.0625]]),\n",
       " tensor([[-204.0000,   -7.9375,    5.4062,  ...,   -7.3750,   -7.9375,\n",
       "            -5.3750]]),\n",
       " tensor([[-152.0000,   -8.5625,    5.8125,  ...,   -5.8125,   -6.1562,\n",
       "            -5.9375]]),\n",
       " tensor([[-195.0000,    1.1797,    2.7031,  ...,   -1.9375,   -1.2500,\n",
       "            -0.3359]]),\n",
       " tensor([[-201.0000,   -4.1562,    7.2500,  ...,   -5.5312,   -6.0938,\n",
       "            -5.7812]]),\n",
       " tensor([[-376.0000,   -7.2188,    5.7188,  ...,   -8.3125,   -7.5938,\n",
       "            -7.4062]]),\n",
       " tensor([[-246.0000,   -7.2500,    4.7812,  ...,   -7.0625,   -9.0625,\n",
       "            -7.9688]]),\n",
       " tensor([[-153.0000,   -7.7188,    5.3125,  ...,   -5.2188,   -3.7500,\n",
       "            -4.9062]]),\n",
       " tensor([[-280.0000,   -7.9688,    8.5000,  ...,   -8.1250,   -8.3125,\n",
       "            -8.3750]]),\n",
       " tensor([[-338.0000,   -8.2500,    6.2500,  ...,   -6.2188,   -6.1562,\n",
       "            -6.1875]]),\n",
       " tensor([[-193.0000,   -5.7812,    5.6562,  ...,   -3.2188,   -0.5352,\n",
       "            -2.5938]]),\n",
       " tensor([[-215.0000,   -8.8750,    3.9531,  ...,   -7.9375,   -5.4062,\n",
       "            -5.4375]]),\n",
       " tensor([[-175.0000,   -5.8125,    4.1250,  ...,   -3.1875,    0.7773,\n",
       "            -1.7188]]),\n",
       " tensor([[-308.0000,   -7.8750,    2.8125,  ...,   -8.2500,   -4.4062,\n",
       "            -6.6875]]),\n",
       " tensor([[-426.0000,   -6.4062,    5.4375,  ...,   -5.9062,   -6.4375,\n",
       "            -6.2500]]),\n",
       " tensor([[-448.0000,   -6.5312,    6.2500,  ...,   -8.0000,   -6.2188,\n",
       "            -5.8438]]),\n",
       " tensor([[-213.0000,   -8.1250,    4.1562,  ...,   -7.1250,   -3.3594,\n",
       "            -4.2188]]),\n",
       " tensor([[-195.0000,   -6.2812,    3.1406,  ...,   -7.0938,   -5.6562,\n",
       "            -5.5312]]),\n",
       " tensor([[-231.0000,   -4.8750,    3.5781,  ...,   -4.3125,   -5.6562,\n",
       "            -5.6562]]),\n",
       " tensor([[-212.0000,   -8.0000,    3.7812,  ...,   -7.4375,   -4.5938,\n",
       "            -7.6562]]),\n",
       " tensor([[-210.0000,   -7.6250,    4.7188,  ...,   -6.2188,   -5.6250,\n",
       "            -7.7812]]),\n",
       " tensor([[-268.0000,   -7.5312,    4.6250,  ...,   -9.0625,   -7.2500,\n",
       "            -7.2188]]),\n",
       " tensor([[-1.7400e+02, -4.1562e+00,  3.3906e+00,  ..., -1.4141e+00,\n",
       "           2.9297e-02, -2.3750e+00]]),\n",
       " tensor([[-183.0000,   -7.3438,    2.7812,  ...,   -5.1250,   -3.4688,\n",
       "            -5.3125]]),\n",
       " tensor([[-223.0000,   -6.9375,    8.5000,  ...,   -6.4375,   -5.4688,\n",
       "            -5.0000]]),\n",
       " tensor([[-135.0000,   -9.1875,    4.2188,  ...,   -7.8125,   -6.2812,\n",
       "            -7.5625]]),\n",
       " tensor([[-233.0000,   -8.4375,    5.3438,  ...,  -10.1875,   -7.4688,\n",
       "            -5.5312]]),\n",
       " tensor([[-193.0000,   -7.8750,    2.8750,  ...,   -8.0000,   -7.1875,\n",
       "            -4.9375]]),\n",
       " tensor([[-197.0000,   -9.3125,    7.7812,  ...,   -9.6875,   -8.5000,\n",
       "            -5.9062]]),\n",
       " tensor([[-187.0000,   -8.0000,    3.5625,  ...,   -8.1250,   -6.0938,\n",
       "            -4.6250]]),\n",
       " tensor([[-187.0000,   -8.6250,    9.6875,  ...,   -7.2812,   -6.8750,\n",
       "            -6.1562]]),\n",
       " tensor([[-201.0000,   -8.1875,    3.5000,  ...,   -5.4375,   -5.0312,\n",
       "            -5.5938]]),\n",
       " tensor([[-278.0000,   -9.2500,    7.4688,  ...,   -9.0000,   -7.8750,\n",
       "            -7.9062]]),\n",
       " tensor([[-294.0000,   -7.3750,    6.3438,  ...,   -5.2500,   -8.8750,\n",
       "            -7.5312]]),\n",
       " tensor([[-296.0000,   -8.8125,    7.4688,  ...,   -9.1250,   -8.5000,\n",
       "            -8.1875]]),\n",
       " tensor([[-268.0000,   -7.1250,    8.3125,  ...,   -5.7500,   -6.6562,\n",
       "            -6.8438]]),\n",
       " tensor([[-238.0000,   -9.1875,    7.0938,  ...,   -9.8750,   -9.5625,\n",
       "            -6.8125]]),\n",
       " tensor([[-218.0000,   -8.6875,    8.1875,  ...,   -8.8750,   -9.9375,\n",
       "            -6.1875]]),\n",
       " tensor([[-225.0000,   -8.0625,    8.9375,  ...,   -9.1250,   -6.4688,\n",
       "            -4.5000]]),\n",
       " tensor([[-380.0000,   -6.3125,    9.1875,  ...,   -6.0312,   -7.5938,\n",
       "            -6.7812]]),\n",
       " tensor([[-308.0000,   -3.2969,    4.4375,  ...,   -3.5000,   -2.7188,\n",
       "            -3.0469]]),\n",
       " tensor([[-294.0000,   -4.7500,    5.6562,  ...,   -3.9219,   -1.8906,\n",
       "            -1.9062]]),\n",
       " tensor([[-310.0000,   -7.5938,    4.9688,  ...,   -8.3125,   -6.6562,\n",
       "            -5.8750]]),\n",
       " tensor([[-216.0000,   -8.6250,    5.3750,  ...,   -8.6875,   -7.6875,\n",
       "            -6.6875]]),\n",
       " tensor([[-178.0000,   -8.3125,    3.9062,  ...,   -9.5000,   -7.9375,\n",
       "            -6.8750]]),\n",
       " tensor([[-288.0000,   -8.4375,    5.4375,  ...,   -7.5938,   -8.3125,\n",
       "            -7.1875]]),\n",
       " tensor([[-364.0000,   -6.7812,    4.7812,  ...,   -6.2812,   -6.6562,\n",
       "            -7.1562]]),\n",
       " tensor([[-392.0000,   -5.8750,    7.5938,  ...,   -7.3438,   -7.5000,\n",
       "            -5.8750]]),\n",
       " tensor([[-179.0000,   -5.0625,    4.6875,  ...,   -3.1250,   -7.1875,\n",
       "            -5.8438]]),\n",
       " tensor([[-137.0000,   -7.5625,    6.1250,  ...,   -5.3125,   -5.8125,\n",
       "            -6.2812]]),\n",
       " tensor([[-1.4800e+02,  2.5625e+00,  3.2812e+00,  ..., -6.1523e-02,\n",
       "          -1.1328e+00,  7.9688e-01]]),\n",
       " tensor([[-200.0000,   -6.3750,    5.9062,  ...,   -6.0000,   -6.4375,\n",
       "            -6.4688]]),\n",
       " tensor([[-512.0000,   -7.2188,    4.9062,  ...,   -4.4062,   -5.4062,\n",
       "            -5.7812]]),\n",
       " tensor([[-342.0000,   -4.3438,    4.3750,  ...,   -4.6562,   -3.0000,\n",
       "            -2.6250]]),\n",
       " tensor([[-472.0000,   -6.7188,    2.7031,  ...,   -6.6875,   -5.8750,\n",
       "            -4.9375]]),\n",
       " tensor([[-268.0000,   -4.8125,    3.3906,  ...,   -6.6562,   -3.2656,\n",
       "            -4.1562]]),\n",
       " tensor([[-466.0000,   -6.6875,    3.9375,  ...,   -6.5625,   -7.6250,\n",
       "            -5.1562]]),\n",
       " tensor([[-215.0000,   -5.6562,    3.1094,  ...,   -5.7812,   -4.7500,\n",
       "            -3.9219]]),\n",
       " tensor([[-290.0000,   -4.5312,    3.6406,  ...,   -5.3438,   -4.3125,\n",
       "            -3.9219]]),\n",
       " tensor([[-246.0000,   -6.8750,    4.2188,  ...,   -6.0625,   -4.5938,\n",
       "            -4.5625]]),\n",
       " tensor([[-195.0000,   -8.5000,    3.6406,  ...,   -7.1562,   -6.8125,\n",
       "            -6.3750]]),\n",
       " tensor([[-338.0000,   -7.5312,    2.6875,  ...,   -6.7500,   -6.2188,\n",
       "            -5.2812]]),\n",
       " tensor([[-434.0000,   -7.0625,    2.7031,  ...,   -5.7812,   -6.7812,\n",
       "            -5.6250]]),\n",
       " tensor([[-410.0000,   -7.4375,    3.4688,  ...,   -6.9688,   -5.6875,\n",
       "            -4.4688]]),\n",
       " tensor([[-424.0000,   -7.7500,    4.0625,  ...,   -7.4062,   -6.6562,\n",
       "            -7.3125]]),\n",
       " tensor([[-211.0000,   -5.3438,    4.1250,  ...,   -6.0312,   -6.5000,\n",
       "            -5.4375]]),\n",
       " tensor([[-156.0000,   -5.7812,    3.3594,  ...,   -5.5938,   -5.1250,\n",
       "            -6.0625]]),\n",
       " tensor([[-270.0000,   -3.9219,    4.5938,  ...,   -4.7812,   -0.8398,\n",
       "            -4.6562]]),\n",
       " tensor([[-149.0000,   -6.8125,    5.1250,  ...,   -6.2812,   -3.8281,\n",
       "            -4.3438]]),\n",
       " tensor([[-224.0000,   -8.1250,    4.7188,  ...,   -7.9688,   -5.5625,\n",
       "            -6.2188]]),\n",
       " tensor([[-406.0000,   -7.8750,    4.5000,  ...,   -6.6250,   -7.0000,\n",
       "            -7.2812]]),\n",
       " tensor([[-324.0000,   -5.9062,    6.3750,  ...,   -3.0781,   -2.6094,\n",
       "            -4.2188]]),\n",
       " tensor([[-228.0000,   -6.1250,    3.5469,  ...,   -6.9062,   -4.1875,\n",
       "            -4.7812]]),\n",
       " tensor([[-229.0000,   -8.9375,    3.1562,  ...,   -5.9688,   -6.9062,\n",
       "            -6.4375]]),\n",
       " tensor([[-426.0000,   -7.6250,    4.2812,  ...,   -8.2500,   -8.0625,\n",
       "            -6.5000]]),\n",
       " tensor([[-310.0000,   -5.3125,    2.6406,  ...,   -5.0000,   -3.6562,\n",
       "            -3.3750]]),\n",
       " tensor([[-316.0000,   -8.5625,    5.5625,  ...,   -8.4375,   -9.0625,\n",
       "            -6.6875]]),\n",
       " tensor([[-414.0000,   -7.0938,    3.1406,  ...,   -7.7188,   -5.5312,\n",
       "            -3.3125]]),\n",
       " tensor([[-490.0000,   -7.3125,    5.8125,  ...,   -6.1250,   -7.0312,\n",
       "            -6.2500]]),\n",
       " tensor([[-249.0000,   -7.7812,    5.5000,  ...,   -6.9062,   -6.4062,\n",
       "            -6.4688]]),\n",
       " tensor([[-454.0000,   -7.9062,    3.5000,  ...,   -8.3125,   -7.3750,\n",
       "            -4.2500]]),\n",
       " tensor([[-444.0000,   -5.1250,    3.1562,  ...,   -5.4688,   -6.1562,\n",
       "            -1.1953]]),\n",
       " tensor([[-231.0000,   -7.5312,    5.8438,  ...,   -8.1875,   -5.0625,\n",
       "            -6.1875]]),\n",
       " tensor([[-318.0000,   -5.7500,    4.6562,  ...,   -7.6875,   -6.1875,\n",
       "            -5.6875]]),\n",
       " tensor([[-396.0000,   -7.5625,    3.7031,  ...,   -6.9688,   -5.5938,\n",
       "            -2.6250]]),\n",
       " tensor([[-502.0000,   -6.7188,    6.2812,  ...,   -5.6875,   -7.2812,\n",
       "            -8.2500]]),\n",
       " tensor([[-226.0000,   -8.4375,    3.7188,  ...,   -8.2500,   -6.3125,\n",
       "            -6.6250]]),\n",
       " tensor([[-334.0000,   -8.2500,    5.7188,  ...,   -5.8125,   -5.9688,\n",
       "            -4.8438]]),\n",
       " tensor([[-474.0000,   -6.2812,    5.7812,  ...,   -5.7812,   -5.6875,\n",
       "            -6.3750]]),\n",
       " tensor([[-316.0000,   -7.9062,    4.8750,  ...,   -6.7500,   -7.0312,\n",
       "            -8.2500]]),\n",
       " tensor([[-470.0000,   -6.6875,    5.7188,  ...,   -6.3750,   -6.0312,\n",
       "            -5.8438]]),\n",
       " tensor([[-406.0000,   -7.5312,    5.4688,  ...,   -5.4375,   -5.5312,\n",
       "            -5.6250]]),\n",
       " tensor([[-464.0000,   -6.7812,    4.5938,  ...,   -5.2812,   -8.1250,\n",
       "            -6.0938]]),\n",
       " tensor([[-288.0000,   -3.4219,    4.0312,  ...,   -3.6719,   -5.6875,\n",
       "            -6.2812]]),\n",
       " tensor([[-130.0000,   -4.1875,    5.3750,  ...,   -8.5625,   -5.1875,\n",
       "            -4.8750]]),\n",
       " tensor([[-318.0000,   -8.1250,    5.6562,  ...,   -8.3750,   -5.7812,\n",
       "            -4.8125]]),\n",
       " tensor([[-356.0000,   -4.7188,    3.7969,  ...,   -3.8594,   -6.3125,\n",
       "            -4.8750]]),\n",
       " tensor([[-458.0000,   -6.9062,    6.2500,  ...,   -6.8750,   -7.1562,\n",
       "            -5.9375]]),\n",
       " tensor([[-374.0000,   -4.7188,    8.1875,  ...,   -6.2500,   -7.2812,\n",
       "            -5.1250]]),\n",
       " tensor([[-193.0000,   -8.2500,    5.0625,  ...,   -7.1250,   -8.1875,\n",
       "            -5.5312]]),\n",
       " tensor([[-141.0000,   -8.4375,    6.0625,  ...,   -5.7500,   -6.2500,\n",
       "            -5.9062]]),\n",
       " tensor([[-166.0000,    0.8164,    2.7500,  ...,   -1.9219,   -1.6172,\n",
       "            -0.7891]]),\n",
       " tensor([[-204.0000,   -4.3438,    7.5938,  ...,   -5.7188,   -5.9375,\n",
       "            -5.8438]]),\n",
       " tensor([[-370.0000,   -7.1562,    6.6562,  ...,   -7.9062,   -8.3125,\n",
       "            -8.0625]]),\n",
       " tensor([[-229.0000,   -7.9062,    6.3750,  ...,   -7.8125,  -10.0000,\n",
       "            -8.0625]]),\n",
       " tensor([[-125.5000,   -9.0000,    7.2188,  ...,   -6.7188,   -6.1875,\n",
       "            -5.1562]]),\n",
       " tensor([[-266.0000,   -8.3750,    8.6875,  ...,   -8.5000,   -8.5000,\n",
       "            -8.7500]]),\n",
       " tensor([[-338.0000,   -8.5000,    5.9688,  ...,   -6.8125,   -6.2812,\n",
       "            -6.2500]]),\n",
       " tensor([[-220.0000,   -6.3438,    6.4688,  ...,   -4.0312,   -1.9297,\n",
       "            -4.5000]]),\n",
       " tensor([[-230.0000,   -8.9375,    4.2188,  ...,   -8.3125,   -5.3438,\n",
       "            -5.8438]]),\n",
       " tensor([[-113.5000,   -7.4375,    3.2500,  ...,   -7.0625,   -6.3750,\n",
       "            -5.6875]]),\n",
       " tensor([[-85.0000,  -7.3438,   3.7188,  ...,  -7.5625,  -5.5000,  -5.7188]]),\n",
       " tensor([[-245.0000,   -8.5000,    6.2812,  ...,   -8.6250,   -7.5312,\n",
       "            -9.3750]]),\n",
       " tensor([[-110.0000,   -7.2500,    3.8750,  ...,   -7.3438,   -4.1562,\n",
       "            -4.8750]]),\n",
       " tensor([[-119.5000,   -7.9375,    6.4375,  ...,   -8.6875,   -6.7500,\n",
       "            -5.9688]]),\n",
       " tensor([[-179.0000,   -8.0625,    6.6562,  ...,   -7.0000,   -6.8438,\n",
       "            -6.7812]]),\n",
       " tensor([[-284.0000,   -4.2188,    7.8750,  ...,   -1.3516,   -1.3516,\n",
       "            -1.9375]]),\n",
       " tensor([[-197.0000,   -6.0000,    4.7500,  ...,   -6.1562,   -3.5000,\n",
       "            -3.8750]]),\n",
       " tensor([[-141.0000,   -9.4375,    4.6250,  ...,   -7.0312,   -7.0625,\n",
       "            -6.3125]]),\n",
       " tensor([[-209.0000,   -8.8750,    5.7812,  ...,   -9.7500,   -6.8438,\n",
       "            -5.2812]]),\n",
       " tensor([[-205.0000,   -7.5000,    4.8750,  ...,   -8.8125,   -6.0312,\n",
       "            -5.5312]]),\n",
       " tensor([[-161.0000,   -8.1875,    6.8125,  ...,   -8.8125,   -8.3125,\n",
       "            -6.6250]]),\n",
       " tensor([[-172.0000,   -6.6250,    5.8125,  ...,   -8.3125,   -7.5938,\n",
       "            -6.4688]]),\n",
       " tensor([[-147.0000,   -7.7812,    5.6250,  ...,   -9.0625,   -5.2812,\n",
       "            -5.6875]]),\n",
       " tensor([[-180.0000,   -8.3125,    5.4062,  ...,   -6.6250,   -6.5625,\n",
       "            -5.7188]]),\n",
       " tensor([[-209.0000,   -8.6250,   10.0625,  ...,   -7.6875,   -6.7500,\n",
       "            -6.3438]]),\n",
       " tensor([[-204.0000,   -8.6875,    6.0938,  ...,   -5.7500,   -5.3438,\n",
       "            -5.8750]]),\n",
       " tensor([[-340.0000,   -8.3125,    8.6250,  ...,   -7.6875,   -6.7812,\n",
       "            -7.1250]]),\n",
       " tensor([[-280.0000,   -8.7500,    6.2812,  ...,   -7.3125,   -7.5312,\n",
       "            -8.2500]]),\n",
       " tensor([[-322.0000,   -8.2500,    8.8750,  ...,   -6.9688,   -6.3750,\n",
       "            -6.1250]]),\n",
       " tensor([[-284.0000,   -8.6250,    8.5625,  ...,   -6.1875,   -6.2188,\n",
       "            -6.3125]]),\n",
       " tensor([[-247.0000,   -6.1250,    8.7500,  ...,   -8.3125,   -8.1875,\n",
       "            -5.8750]]),\n",
       " tensor([[-444.0000,   -4.6875,    9.3750,  ...,   -6.0312,   -7.0938,\n",
       "            -6.2500]]),\n",
       " tensor([[-233.0000,   -4.1875,    4.3750,  ...,   -2.5469,   -2.4531,\n",
       "            -2.9375]]),\n",
       " tensor([[-308.0000,   -4.6250,    5.5312,  ...,   -4.1875,   -3.3438,\n",
       "            -2.8281]]),\n",
       " tensor([[-300.0000,   -7.0312,    4.6250,  ...,   -7.1875,   -7.4688,\n",
       "            -6.2812]]),\n",
       " tensor([[-242.0000,   -7.8438,    5.9375,  ...,   -7.6875,   -8.1250,\n",
       "            -6.9688]]),\n",
       " tensor([[-204.0000,   -7.4688,    5.0312,  ...,   -6.1562,   -6.6875,\n",
       "            -7.3125]]),\n",
       " tensor([[-250.0000,   -9.0625,    7.8438,  ...,   -8.8750,   -8.4375,\n",
       "            -7.1562]]),\n",
       " tensor([[-209.0000,   -8.0000,    4.9688,  ...,   -9.8750,   -8.9375,\n",
       "            -6.9688]]),\n",
       " tensor([[-302.0000,   -8.3125,    6.2188,  ...,   -8.3125,   -8.6250,\n",
       "            -6.9688]]),\n",
       " tensor([[-360.0000,   -6.0625,    5.3750,  ...,   -5.6250,   -7.3750,\n",
       "            -7.3438]]),\n",
       " tensor([[-400.0000,   -5.0938,    8.0000,  ...,   -7.0000,   -7.7812,\n",
       "            -6.0625]]),\n",
       " tensor([[-180.0000,   -5.3125,    4.8438,  ...,   -3.1562,   -7.5312,\n",
       "            -5.9375]]),\n",
       " tensor([[-130.0000,   -7.2500,    6.4375,  ...,   -5.4375,   -5.9062,\n",
       "            -6.4688]]),\n",
       " tensor([[-2.3200e+02,  3.1406e+00,  1.9688e+00,  ..., -5.8203e-01,\n",
       "          -1.9434e-01,  5.8203e-01]]),\n",
       " tensor([[-192.0000,   -6.4688,    5.7500,  ...,   -6.4375,   -6.0625,\n",
       "            -6.4062]]),\n",
       " tensor([[-500.0000,   -5.7188,    3.9531,  ...,   -3.1094,   -6.3438,\n",
       "            -7.2812]]),\n",
       " tensor([[-318.0000,   -4.0312,    4.4375,  ...,   -2.4531,   -3.0781,\n",
       "            -2.5469]]),\n",
       " tensor([[-310.0000,   -4.2812,    5.9688,  ...,   -0.3535,   -1.9375,\n",
       "            -4.0000]]),\n",
       " tensor([[-142.0000,   -4.0938,    3.2031,  ...,    0.2988,   -2.5938,\n",
       "            -5.5000]]),\n",
       " tensor([[-284.0000,   -6.5312,    4.2812,  ...,   -4.2500,   -6.8438,\n",
       "            -4.3125]]),\n",
       " tensor([[-430.0000,   -7.0312,    3.7500,  ...,   -6.2500,   -6.8750,\n",
       "            -6.4688]]),\n",
       " tensor([[-434.0000,   -5.8750,    6.0000,  ...,   -6.1875,   -7.5312,\n",
       "            -7.2188]]),\n",
       " tensor([[-326.0000,   -8.3750,    4.0625,  ...,   -6.3750,   -9.1875,\n",
       "            -7.4062]]),\n",
       " tensor([[-486.0000,   -7.6250,    4.6875,  ...,   -8.2500,   -8.5000,\n",
       "            -8.8125]]),\n",
       " tensor([[-244.0000,   -6.2188,    4.6250,  ...,   -7.6562,   -6.1875,\n",
       "            -6.5938]]),\n",
       " tensor([[-260.0000,   -7.1250,    3.7969,  ...,   -7.3125,   -6.4688,\n",
       "            -7.8125]]),\n",
       " tensor([[-278.0000,   -6.5000,    3.6562,  ...,   -4.5000,   -4.4062,\n",
       "            -5.4375]]),\n",
       " tensor([[-436.0000,   -5.9688,    3.8750,  ...,   -4.6875,   -5.2812,\n",
       "            -5.6250]]),\n",
       " tensor([[-428.0000,   -4.1250,    2.5625,  ...,   -4.8125,   -5.6875,\n",
       "            -5.7500]]),\n",
       " tensor([[-390.0000,   -4.5312,    2.3281,  ...,   -2.0312,   -5.4062,\n",
       "            -6.0625]]),\n",
       " tensor([[-185.0000,   -6.2188,    3.8438,  ...,   -4.3750,   -5.1875,\n",
       "            -6.7188]]),\n",
       " tensor([[-129.0000,   -2.8594,    2.6562,  ...,   -0.7227,   -1.0625,\n",
       "            -3.0625]]),\n",
       " tensor([[-232.0000,   -7.8125,    5.2812,  ...,   -8.1250,   -3.3750,\n",
       "            -6.6250]]),\n",
       " tensor([[-516.0000,   -7.0312,    5.1875,  ...,   -6.9062,   -8.5625,\n",
       "            -7.8125]]),\n",
       " tensor([[-222.0000,   -7.6875,    4.1562,  ...,   -7.0000,   -7.0312,\n",
       "            -6.6250]]),\n",
       " tensor([[-314.0000,   -4.2812,    5.3438,  ...,   -4.7188,   -4.7500,\n",
       "            -4.0312]]),\n",
       " tensor([[-256.0000,   -5.7812,    4.6562,  ...,   -5.9375,   -4.7500,\n",
       "            -5.3438]]),\n",
       " tensor([[-190.0000,   -7.3438,    3.6875,  ...,   -6.6562,   -6.4688,\n",
       "            -6.1875]]),\n",
       " tensor([[-380.0000,   -8.1875,    3.5469,  ...,   -8.2500,   -7.0938,\n",
       "            -6.2812]]),\n",
       " tensor([[-446.0000,   -7.9062,    3.0469,  ...,   -5.9688,   -5.9688,\n",
       "            -5.5625]]),\n",
       " tensor([[-268.0000,   -1.7578,    3.7500,  ...,   -2.4688,   -3.3281,\n",
       "            -2.6250]]),\n",
       " tensor([[-422.0000,   -7.1250,    4.1562,  ...,   -6.4062,   -7.1250,\n",
       "            -4.1875]]),\n",
       " tensor([[-492.0000,   -8.1875,    5.4062,  ...,   -6.2188,   -9.9375,\n",
       "            -8.4375]]),\n",
       " tensor([[-221.0000,   -7.6875,    3.7656,  ...,   -6.8125,   -5.6875,\n",
       "            -5.0000]]),\n",
       " tensor([[-324.0000,   -5.8438,    4.5000,  ...,   -3.9219,   -4.4062,\n",
       "            -4.7812]]),\n",
       " tensor([[-278.0000,   -7.6250,    3.7031,  ...,   -6.7500,   -6.6250,\n",
       "            -7.2812]]),\n",
       " tensor([[-468.0000,   -6.2812,    4.2812,  ...,   -4.1875,   -6.5000,\n",
       "            -6.7188]]),\n",
       " tensor([[-474.0000,   -6.2188,    5.5312,  ...,   -6.9688,   -8.0625,\n",
       "            -7.7188]]),\n",
       " tensor([[-324.0000,   -5.0938,    3.9062,  ...,   -8.4375,   -4.8750,\n",
       "            -5.6562]]),\n",
       " tensor([[-500.0000,   -7.4375,    3.9062,  ...,   -6.2188,   -8.5000,\n",
       "            -6.2188]]),\n",
       " tensor([[-231.0000,   -6.9688,    4.0938,  ...,   -5.6875,   -6.0938,\n",
       "            -6.4062]]),\n",
       " tensor([[-316.0000,   -3.6250,    4.5312,  ...,   -3.0938,   -4.1875,\n",
       "            -3.8750]]),\n",
       " tensor([[-296.0000,   -5.8438,    4.3125,  ...,   -5.8750,   -5.2500,\n",
       "            -5.3750]]),\n",
       " tensor([[-231.0000,   -6.7812,    3.7344,  ...,   -5.9375,   -6.8750,\n",
       "            -6.8125]]),\n",
       " tensor([[-348.0000,   -6.4375,    2.6406,  ...,   -5.1562,   -5.6875,\n",
       "            -7.0312]]),\n",
       " tensor([[-492.0000,   -7.7188,    5.7500,  ...,   -6.8750,   -9.1875,\n",
       "            -7.3125]]),\n",
       " tensor([[-446.0000,   -7.5625,    4.5312,  ...,   -6.2188,   -7.1250,\n",
       "            -5.4375]]),\n",
       " tensor([[-488.0000,   -7.0000,    5.8750,  ...,   -7.6875,   -7.0625,\n",
       "            -8.4375]]),\n",
       " tensor([[-244.0000,   -8.8750,    5.2812,  ...,  -11.4375,   -7.1250,\n",
       "            -7.1875]]),\n",
       " tensor([[-464.0000,   -7.2500,    6.1250,  ...,   -7.4688,   -8.0625,\n",
       "            -8.2500]]),\n",
       " tensor([[-380.0000,   -3.1719,    4.4062,  ...,   -4.4375,   -4.7500,\n",
       "            -1.8828]]),\n",
       " tensor([[-458.0000,   -6.9375,    6.7500,  ...,   -8.3125,   -9.9375,\n",
       "            -7.8125]]),\n",
       " tensor([[-196.0000,   -5.0312,    4.8125,  ...,   -5.3438,   -6.1250,\n",
       "            -5.8750]]),\n",
       " tensor([[-201.0000,   -6.1250,    4.4375,  ...,   -5.5625,   -5.8750,\n",
       "            -8.4375]]),\n",
       " tensor([[-394.0000,   -6.6250,    5.9375,  ...,   -5.3125,   -5.1875,\n",
       "            -6.8750]]),\n",
       " tensor([[-484.0000,   -6.0938,    5.2188,  ...,   -5.8125,   -7.7812,\n",
       "            -7.8750]]),\n",
       " tensor([[-300.0000,   -7.0938,    4.9062,  ...,   -4.2812,   -7.2500,\n",
       "            -5.7500]]),\n",
       " tensor([[-364.0000,   -5.7188,    4.5312,  ...,   -4.3750,   -5.5000,\n",
       "            -4.6562]]),\n",
       " tensor([[-302.0000,   -7.7188,    4.6562,  ...,   -4.2188,   -5.9062,\n",
       "            -6.3125]]),\n",
       " tensor([[-234.0000,   -7.6250,    4.7500,  ...,   -6.0938,   -6.3438,\n",
       "            -4.4375]]),\n",
       " tensor([[-410.0000,   -4.5312,    8.6875,  ...,   -7.1875,   -8.5000,\n",
       "            -5.9688]]),\n",
       " tensor([[-223.0000,   -7.4062,    5.7812,  ...,   -6.4688,   -8.3750,\n",
       "            -5.4062]]),\n",
       " tensor([[-147.0000,   -8.4375,    6.3125,  ...,   -5.7812,   -6.3125,\n",
       "            -5.7500]]),\n",
       " tensor([[-169.0000,   -0.4492,    3.8125,  ...,   -1.1562,   -1.6328,\n",
       "            -0.3359]]),\n",
       " tensor([[-206.0000,   -4.3750,    7.6875,  ...,   -5.7812,   -5.8438,\n",
       "            -5.7500]]),\n",
       " tensor([[-386.0000,   -6.6562,    7.4375,  ...,   -7.5000,   -8.5000,\n",
       "            -7.5312]]),\n",
       " tensor([[-239.0000,   -7.3750,    5.1562,  ...,   -6.8750,   -9.6250,\n",
       "            -7.4375]]),\n",
       " tensor([[-134.0000,   -9.3125,    7.5312,  ...,   -6.9688,   -7.1562,\n",
       "            -5.4375]]),\n",
       " tensor([[-276.0000,   -7.5000,    8.8750,  ...,   -8.0625,   -9.0625,\n",
       "            -8.5625]]),\n",
       " tensor([[-356.0000,   -6.8750,    5.5312,  ...,   -4.6875,   -6.9375,\n",
       "            -6.3125]]),\n",
       " tensor([[-268.0000,   -4.9688,    6.4375,  ...,   -1.8125,   -1.7266,\n",
       "            -2.5781]]),\n",
       " tensor([[-238.0000,   -3.9219,    4.5625,  ...,    1.2188,   -0.5234,\n",
       "            -1.8672]]),\n",
       " tensor([[-138.0000,   -4.1250,    3.2188,  ...,    0.3750,   -1.7266,\n",
       "            -4.2812]]),\n",
       " tensor([[-243.0000,   -6.3438,    3.4688,  ...,   -4.2188,   -5.7500,\n",
       "            -4.0625]]),\n",
       " tensor([[-422.0000,   -8.3125,    3.9219,  ...,   -7.2500,   -6.5938,\n",
       "            -7.3438]]),\n",
       " tensor([[-408.0000,   -5.8125,    5.6562,  ...,   -6.0312,   -7.3125,\n",
       "            -7.2812]]),\n",
       " tensor([[-282.0000,   -8.3125,    4.7500,  ...,   -6.0938,   -8.2500,\n",
       "            -7.5312]]),\n",
       " tensor([[-474.0000,   -7.7500,    3.4844,  ...,   -9.2500,   -7.6875,\n",
       "            -8.8750]]),\n",
       " tensor([[-234.0000,   -6.2812,    4.5625,  ...,   -7.4375,   -7.1250,\n",
       "            -7.0938]]),\n",
       " tensor([[-218.0000,   -8.0000,    4.4375,  ...,   -7.2500,   -8.0000,\n",
       "            -7.7500]]),\n",
       " tensor([[-197.0000,   -7.3438,    4.5938,  ...,   -4.6875,   -5.2188,\n",
       "            -6.7812]]),\n",
       " tensor([[-318.0000,   -6.9375,    6.2812,  ...,   -7.1250,   -5.9062,\n",
       "            -7.7812]]),\n",
       " tensor([[-250.0000,   -7.5312,    4.9062,  ...,   -6.7500,   -6.5000,\n",
       "            -7.6562]]),\n",
       " tensor([[-246.0000,   -7.6562,    7.0000,  ...,   -3.8906,   -6.3438,\n",
       "            -6.7500]]),\n",
       " tensor([[-171.0000,   -8.4375,    4.4375,  ...,   -7.9062,   -7.0938,\n",
       "            -6.1250]]),\n",
       " tensor([[-144.0000,   -8.7500,    8.0000,  ...,   -8.4375,   -7.5312,\n",
       "            -6.5312]]),\n",
       " tensor([[-247.0000,   -7.6562,    4.8750,  ...,   -9.0625,   -6.1875,\n",
       "            -6.9062]]),\n",
       " tensor([[-264.0000,   -8.4375,    9.3750,  ...,   -7.5938,   -9.0000,\n",
       "            -8.6875]]),\n",
       " tensor([[-274.0000,   -6.2500,    7.4688,  ...,   -5.9062,   -7.4062,\n",
       "            -7.0000]]),\n",
       " tensor([[-169.0000,   -6.0000,    2.8750,  ...,   -5.4688,   -4.9062,\n",
       "            -4.7812]]),\n",
       " tensor([[-130.0000,   -6.6250,    5.4062,  ...,   -6.7812,   -5.4375,\n",
       "            -6.7188]]),\n",
       " tensor([[-248.0000,   -8.5625,    6.1562,  ...,   -8.5000,   -7.6250,\n",
       "            -7.4375]]),\n",
       " tensor([[-211.0000,   -9.5625,    7.4688,  ...,   -8.0625,   -6.5000,\n",
       "            -6.2500]]),\n",
       " tensor([[-126.0000,   -9.4375,    8.1875,  ...,   -7.5625,   -7.4375,\n",
       "            -6.2188]]),\n",
       " tensor([[-126.5000,   -8.2500,    8.5625,  ...,   -7.7188,   -7.8438,\n",
       "            -5.8125]]),\n",
       " tensor([[-188.0000,   -8.1250,    9.7500,  ...,   -8.7500,   -8.7500,\n",
       "            -8.0000]]),\n",
       " tensor([[-135.0000,   -8.6875,    4.4062,  ...,   -7.2500,   -4.8438,\n",
       "            -5.6875]]),\n",
       " tensor([[-212.0000,   -7.3125,    7.4688,  ...,  -11.3125,   -6.3750,\n",
       "            -6.8750]]),\n",
       " tensor([[-206.0000,   -7.4375,    6.1875,  ...,   -6.5938,   -6.8438,\n",
       "            -5.7188]]),\n",
       " tensor([[-224.0000,   -6.4688,    8.5625,  ...,  -11.2500,   -7.7812,\n",
       "            -6.4688]]),\n",
       " tensor([[-232.0000,   -9.2500,    8.9375,  ...,   -9.5000,   -7.5938,\n",
       "            -8.5625]]),\n",
       " tensor([[-255.0000,   -6.4062,   10.1875,  ...,   -6.7500,   -8.8750,\n",
       "            -7.1562]]),\n",
       " tensor([[-258.0000,   -5.9688,    7.8438,  ...,   -2.1562,   -5.2812,\n",
       "            -4.1250]]),\n",
       " tensor([[-310.0000,   -8.1250,    6.9062,  ...,   -5.2188,   -6.7812,\n",
       "            -6.3750]]),\n",
       " tensor([[-206.0000,   -8.1875,    6.0938,  ...,   -4.5938,   -6.1562,\n",
       "            -6.8750]]),\n",
       " tensor([[-132.0000,   -7.2812,    5.2500,  ...,   -7.0625,   -5.9062,\n",
       "            -4.4688]]),\n",
       " tensor([[-227.0000,   -5.9375,   10.5000,  ...,   -8.2500,   -6.4688,\n",
       "            -4.5625]]),\n",
       " tensor([[-464.0000,   -4.7188,   12.2500,  ...,   -6.2812,   -6.1250,\n",
       "            -4.9062]]),\n",
       " tensor([[-310.0000,   -3.3750,    3.1094,  ...,   -2.1250,   -4.1875,\n",
       "            -3.2188]]),\n",
       " tensor([[-328.0000,   -5.4062,    4.8125,  ...,   -4.9062,   -4.2188,\n",
       "            -1.4297]]),\n",
       " tensor([[-201.0000,    0.3047,    1.3828,  ...,    2.3281,   -3.3906,\n",
       "            -3.3125]]),\n",
       " tensor([[-134.0000,   -1.0781,    3.9219,  ...,   -1.4062,   -1.0156,\n",
       "            -1.1641]]),\n",
       " tensor([[-91.0000,  -2.9688,   2.2969,  ...,  -3.2188,  -5.1562,  -3.8125]]),\n",
       " tensor([[-97.0000,  -3.3594,  -0.4355,  ...,  -5.1250,  -3.1250,  -2.7969]]),\n",
       " tensor([[-464.0000,   -4.6875,    7.0625,  ...,   -5.5938,   -5.0312,\n",
       "            -4.5938]]),\n",
       " tensor([[-278.0000,   -6.7500,    4.8438,  ...,   -5.3750,   -6.9375,\n",
       "            -5.4375]]),\n",
       " tensor([[-225.0000,   -8.3750,    6.1250,  ...,   -6.2188,   -7.6562,\n",
       "            -6.2500]]),\n",
       " tensor([[-214.0000,   -6.8125,    7.3750,  ...,   -8.5625,   -8.6875,\n",
       "            -6.6250]]),\n",
       " tensor([[-248.0000,   -7.3125,    8.8125,  ...,   -7.2500,   -7.3125,\n",
       "            -7.5312]]),\n",
       " tensor([[-255.0000,   -8.0000,    8.2500,  ...,   -6.5000,   -8.9375,\n",
       "            -8.1250]]),\n",
       " tensor([[-161.0000,   -8.4375,    7.7500,  ...,   -6.7812,   -8.6250,\n",
       "            -7.3750]]),\n",
       " tensor([[-282.0000,   -8.7500,   11.3125,  ...,   -8.1250,   -9.6875,\n",
       "            -9.1250]]),\n",
       " tensor([[-245.0000,   -8.8125,    8.9375,  ...,   -6.4375,   -7.4688,\n",
       "            -7.7188]]),\n",
       " tensor([[-249.0000,   -8.1875,   10.8750,  ...,   -8.0000,   -8.3125,\n",
       "            -7.7188]]),\n",
       " tensor([[-268.0000,   -9.4375,    9.5000,  ...,   -8.9375,   -7.3438,\n",
       "            -7.6875]]),\n",
       " tensor([[-199.0000,   -9.6250,   11.1250,  ...,   -8.7500,   -8.5625,\n",
       "            -9.1250]]),\n",
       " tensor([[-181.0000,   -8.3125,   10.1875,  ...,   -7.0938,   -7.1562,\n",
       "            -7.8750]]),\n",
       " tensor([[-276.0000,   -7.5312,    9.5000,  ...,   -8.3750,   -7.7500,\n",
       "            -5.8438]]),\n",
       " tensor([[-374.0000,   -7.2188,    7.7188,  ...,   -6.4688,   -6.8125,\n",
       "            -6.6562]]),\n",
       " tensor([[-432.0000,   -7.4375,    9.8125,  ...,   -5.9062,   -7.0000,\n",
       "            -6.4688]]),\n",
       " tensor([[-316.0000,   -7.3125,    7.3438,  ...,   -4.3750,   -8.5625,\n",
       "            -6.2188]]),\n",
       " tensor([[-262.0000,   -6.7500,    8.0000,  ...,   -4.6250,   -6.4688,\n",
       "            -5.8750]]),\n",
       " tensor([[-338.0000,   -6.7188,    5.0000,  ...,   -4.5625,   -4.0625,\n",
       "            -6.0938]]),\n",
       " tensor([[-173.0000,   -5.9062,    8.2500,  ...,   -5.4688,   -3.2656,\n",
       "            -4.4062]]),\n",
       " tensor([[-145.0000,   -9.1250,    7.5312,  ...,   -7.1250,   -6.3750,\n",
       "            -8.0625]]),\n",
       " tensor([[-172.0000,   -6.5625,    5.1562,  ...,   -7.8438,   -6.0000,\n",
       "            -8.3750]]),\n",
       " tensor([[-229.0000,   -8.0625,    8.3125,  ...,   -4.6875,   -5.3750,\n",
       "            -6.5625]]),\n",
       " tensor([[-216.0000,   -8.0625,   10.6875,  ...,   -5.4688,   -7.0312,\n",
       "            -6.9062]]),\n",
       " tensor([[-129.0000,   -5.1250,    8.1250,  ...,   -5.0312,   -5.0625,\n",
       "            -3.4062]]),\n",
       " tensor([[-149.0000,   -8.1875,   10.7500,  ...,   -6.5938,   -5.8125,\n",
       "            -4.9375]]),\n",
       " tensor([[-145.0000,   -5.1875,    6.6562,  ...,   -4.0625,   -3.5312,\n",
       "            -1.8828]]),\n",
       " tensor([[-189.0000,   -9.8125,   11.4375,  ...,   -9.7500,   -8.1875,\n",
       "            -6.5938]]),\n",
       " tensor([[-228.0000,   -6.8750,    6.0938,  ...,   -8.1250,   -6.1875,\n",
       "            -7.2500]]),\n",
       " tensor([[-142.0000,   -8.1250,    8.1250,  ...,   -6.7812,   -6.2500,\n",
       "            -6.7812]]),\n",
       " tensor([[-223.0000,   -7.9688,    9.0000,  ...,   -5.3125,   -5.6250,\n",
       "            -6.8438]]),\n",
       " tensor([[-191.0000,   -9.5000,    9.4375,  ...,   -7.6875,   -7.1250,\n",
       "            -7.4062]]),\n",
       " tensor([[-174.0000,   -8.8750,   10.3750,  ...,   -8.8125,   -8.0625,\n",
       "            -9.0625]]),\n",
       " tensor([[-306.0000,   -9.0000,   10.5625,  ...,   -8.1250,   -9.1250,\n",
       "            -7.4062]]),\n",
       " tensor([[-314.0000,   -7.6875,   10.1250,  ...,   -5.5312,   -6.2812,\n",
       "            -6.5938]]),\n",
       " tensor([[-286.0000,   -7.3438,    9.1875,  ...,   -6.5000,   -7.2188,\n",
       "            -6.5312]]),\n",
       " tensor([[-167.0000,   -6.8125,   11.4375,  ...,   -4.8125,   -5.6250,\n",
       "            -6.9688]]),\n",
       " tensor([[-153.0000,   -6.1875,   10.9375,  ...,   -4.4062,   -5.3438,\n",
       "            -6.0312]]),\n",
       " tensor([[-214.0000,   -8.0000,   11.3750,  ...,   -8.7500,   -6.7812,\n",
       "            -6.8438]]),\n",
       " tensor([[-222.0000,   -8.6875,   10.2500,  ...,   -9.2500,   -8.6875,\n",
       "            -8.4375]]),\n",
       " tensor([[-336.0000,   -8.1250,    8.0625,  ...,   -8.7500,   -8.8750,\n",
       "            -8.3750]]),\n",
       " tensor([[-330.0000,   -7.5625,    9.1250,  ...,   -6.3125,   -6.3750,\n",
       "            -6.2500]]),\n",
       " tensor([[-330.0000,   -8.4375,   10.5000,  ...,   -8.5000,   -8.3750,\n",
       "            -7.5938]]),\n",
       " tensor([[-342.0000,   -8.6875,    9.8750,  ...,   -7.8438,   -8.6250,\n",
       "            -6.2812]]),\n",
       " tensor([[-290.0000,   -9.0000,   11.6250,  ...,   -9.1250,   -9.0625,\n",
       "            -7.6250]]),\n",
       " tensor([[-113.5000,   -6.7500,   10.5625,  ...,   -4.8438,   -4.3438,\n",
       "            -3.4219]]),\n",
       " tensor([[-168.0000,   -7.6875,    8.9375,  ...,   -6.9375,   -4.3750,\n",
       "            -4.6250]]),\n",
       " tensor([[-352.0000,   -7.6562,    7.9688,  ...,   -9.1250,   -8.3750,\n",
       "            -7.0312]]),\n",
       " tensor([[-420.0000,   -6.9375,   11.7500,  ...,   -8.1250,   -7.8750,\n",
       "            -6.4375]]),\n",
       " tensor([[-286.0000,   -6.6562,    8.7500,  ...,   -6.0625,   -7.6562,\n",
       "            -5.5938]]),\n",
       " tensor([[-249.0000,   -6.3750,    8.9375,  ...,   -6.0938,   -6.2812,\n",
       "            -6.4062]]),\n",
       " tensor([[-352.0000,   -6.8125,    6.8438,  ...,   -5.8438,   -4.9375,\n",
       "            -6.1875]]),\n",
       " tensor([[-270.0000,   -4.9688,    7.2500,  ...,   -2.0469,    0.8984,\n",
       "            -1.0391]]),\n",
       " tensor([[-348.0000,   -6.9688,    7.0312,  ...,   -7.2500,   -4.8125,\n",
       "            -6.1250]]),\n",
       " tensor([[-444.0000,   -6.8438,    8.5625,  ...,   -6.1875,   -6.9062,\n",
       "            -6.5625]]),\n",
       " tensor([[-416.0000,   -5.8438,    9.3125,  ...,   -6.7812,   -6.2188,\n",
       "            -5.7500]]),\n",
       " tensor([[-161.0000,   -7.4688,    6.7812,  ...,   -7.5312,   -2.5156,\n",
       "            -3.2969]]),\n",
       " tensor([[-198.0000,   -6.0000,    6.1875,  ...,   -7.2188,   -6.0625,\n",
       "            -5.4062]]),\n",
       " tensor([[-237.0000,   -5.3438,    6.0625,  ...,   -4.7812,   -5.5938,\n",
       "            -5.7188]]),\n",
       " tensor([[-190.0000,   -6.1562,    5.3438,  ...,   -5.9375,   -4.5625,\n",
       "            -5.8125]]),\n",
       " tensor([[-190.0000,   -8.5000,    7.2188,  ...,   -6.9375,   -5.7188,\n",
       "            -6.2500]]),\n",
       " tensor([[-214.0000,   -7.2812,    5.9062,  ...,  -10.3125,   -6.7812,\n",
       "            -6.6250]]),\n",
       " tensor([[-1.6800e+02, -3.2656e+00,  7.4062e+00,  ..., -5.0781e-01,\n",
       "           1.2656e+00, -1.4844e-01]]),\n",
       " tensor([[-228.0000,   -7.7500,    7.2188,  ...,   -4.1250,   -3.9219,\n",
       "            -5.3125]]),\n",
       " tensor([[-195.0000,   -6.6562,   11.0625,  ...,   -4.7188,   -5.3750,\n",
       "            -4.6875]]),\n",
       " tensor([[-142.0000,   -8.3125,    6.4375,  ...,   -7.2500,   -5.5312,\n",
       "            -5.7812]]),\n",
       " tensor([[-200.0000,   -7.3750,    4.4062,  ...,   -8.6875,   -6.4375,\n",
       "            -4.2188]]),\n",
       " tensor([[-205.0000,   -7.1875,    5.4062,  ...,   -7.0938,   -7.0625,\n",
       "            -5.4688]]),\n",
       " tensor([[-193.0000,   -9.6250,   10.1250,  ...,   -9.1875,   -8.0000,\n",
       "            -6.6875]]),\n",
       " tensor([[-228.0000,   -8.1875,    6.9062,  ...,   -8.2500,   -6.0625,\n",
       "            -5.2812]]),\n",
       " tensor([[-253.0000,   -6.5000,   10.8750,  ...,   -6.9062,   -5.0625,\n",
       "            -5.9375]]),\n",
       " tensor([[-268.0000,   -9.1250,    7.0625,  ...,   -6.7812,   -5.7188,\n",
       "            -7.2812]]),\n",
       " tensor([[-242.0000,   -8.7500,    7.8125,  ...,   -8.5625,   -7.0938,\n",
       "            -8.0625]]),\n",
       " tensor([[-258.0000,   -6.5312,   10.1875,  ...,   -4.5312,   -7.9375,\n",
       "            -7.9375]]),\n",
       " tensor([[-308.0000,   -8.3125,   10.2500,  ...,   -6.1875,   -7.0312,\n",
       "            -7.5312]]),\n",
       " tensor([[-216.0000,   -7.8438,    9.5000,  ...,   -5.1562,   -6.2500,\n",
       "            -6.9688]]),\n",
       " tensor([[-264.0000,   -9.8125,    8.3125,  ...,   -9.3125,   -8.0625,\n",
       "            -7.2188]]),\n",
       " tensor([[-308.0000,   -8.7500,   10.1875,  ...,  -10.6875,   -9.0625,\n",
       "            -6.4688]]),\n",
       " tensor([[-288.0000,   -7.8438,    7.5625,  ...,  -11.1875,   -7.6250,\n",
       "            -5.3750]]),\n",
       " tensor([[-418.0000,   -7.6562,   11.8750,  ...,   -8.7500,   -7.5312,\n",
       "            -6.8125]]),\n",
       " tensor([[-262.0000,   -6.4688,    9.3750,  ...,   -6.2812,   -6.8750,\n",
       "            -5.5625]]),\n",
       " tensor([[-243.0000,   -7.5625,    7.6875,  ...,   -6.7500,   -5.6562,\n",
       "            -7.2500]]),\n",
       " tensor([[-348.0000,   -9.5000,    8.0625,  ...,   -8.8125,   -5.9688,\n",
       "            -8.0625]]),\n",
       " tensor([[-224.0000,   -8.5625,   10.8750,  ...,   -9.1875,   -9.3125,\n",
       "            -8.0625]]),\n",
       " tensor([[-255.0000,   -8.3750,   10.1875,  ...,   -7.8750,   -6.8750,\n",
       "            -7.6562]]),\n",
       " tensor([[-310.0000,   -7.7500,    9.5000,  ...,   -8.1250,   -6.9062,\n",
       "            -8.6250]]),\n",
       " tensor([[-264.0000,   -7.9375,   10.6250,  ...,   -6.9062,   -7.0312,\n",
       "            -8.2500]]),\n",
       " tensor([[-243.0000,   -7.9375,   11.2500,  ...,   -9.9375,   -7.4062,\n",
       "            -8.1875]]),\n",
       " tensor([[-207.0000,   -7.6875,    9.1250,  ...,   -7.4062,   -6.0312,\n",
       "            -7.1250]]),\n",
       " tensor([[-182.0000,   -4.5625,    9.6875,  ...,   -0.3477,   -1.3906,\n",
       "            -2.9062]]),\n",
       " tensor([[-182.0000,   -6.9062,    8.8750,  ...,   -5.3438,   -4.6875,\n",
       "            -5.1250]]),\n",
       " tensor([[-108.0000,   -9.5625,    6.3750,  ...,   -7.1875,   -6.6562,\n",
       "            -5.8438]]),\n",
       " tensor([[-268.0000,   -8.2500,    8.3750,  ...,   -9.3750,   -7.6250,\n",
       "            -5.6562]]),\n",
       " tensor([[-204.0000,   -8.2500,    7.5312,  ...,   -7.3750,   -5.8125,\n",
       "            -5.7500]]),\n",
       " tensor([[-182.0000,   -9.1250,   10.1250,  ...,   -7.4375,   -8.8750,\n",
       "            -7.0312]]),\n",
       " tensor([[-205.0000,   -8.3125,   10.0625,  ...,   -7.0625,   -8.2500,\n",
       "            -5.8438]]),\n",
       " tensor([[-245.0000,   -8.4375,   10.6250,  ...,   -7.6875,   -6.9062,\n",
       "            -6.8750]]),\n",
       " tensor([[-266.0000,   -8.3750,   11.2500,  ...,   -7.0625,   -7.5000,\n",
       "            -7.9375]]),\n",
       " tensor([[-292.0000,   -5.8750,   12.5625,  ...,   -7.2500,   -5.7812,\n",
       "            -5.8750]]),\n",
       " tensor([[-247.0000,   -9.1250,   10.6875,  ...,   -5.3750,   -6.1875,\n",
       "            -7.5000]]),\n",
       " tensor([[-290.0000,   -7.7188,   11.1250,  ...,   -5.7500,   -5.2812,\n",
       "            -6.8438]]),\n",
       " tensor([[-270.0000,   -7.2812,   11.1250,  ...,   -5.7812,   -6.7812,\n",
       "            -7.5938]]),\n",
       " tensor([[-258.0000,   -8.6250,   12.1250,  ...,   -5.4375,   -5.5312,\n",
       "            -6.0000]]),\n",
       " tensor([[-237.0000,   -9.3125,   10.6875,  ...,   -5.4375,   -6.8750,\n",
       "            -7.0938]]),\n",
       " tensor([[-314.0000,   -7.5625,    9.6250,  ...,   -9.9375,   -6.9688,\n",
       "            -6.3750]]),\n",
       " tensor([[-412.0000,   -6.1562,   12.9375,  ...,   -7.0000,   -8.4375,\n",
       "            -7.4062]]),\n",
       " tensor([[-254.0000,   -5.3750,    9.6250,  ...,   -4.9688,   -8.0000,\n",
       "            -5.7188]]),\n",
       " tensor([[-236.0000,   -5.5625,    9.1875,  ...,   -4.5625,   -5.0000,\n",
       "            -4.8125]]),\n",
       " tensor([[-364.0000,   -5.8438,    8.8750,  ...,   -3.1562,   -5.9375,\n",
       "            -5.5938]]),\n",
       " tensor([[-221.0000,   -4.2500,    9.3750,  ...,    1.4766,   -1.2500,\n",
       "            -3.0156]]),\n",
       " tensor([[-145.0000,   -5.3750,    7.8438,  ...,    2.0000,   -3.5625,\n",
       "            -4.6875]]),\n",
       " tensor([[-203.0000,   -7.4375,    8.3750,  ...,   -3.8125,   -5.7812,\n",
       "            -4.9688]]),\n",
       " tensor([[-400.0000,   -6.0000,    8.5625,  ...,   -5.2188,   -6.1875,\n",
       "            -5.8438]]),\n",
       " tensor([[-326.0000,   -5.9375,   11.3750,  ...,   -5.2812,   -6.8438,\n",
       "            -6.3125]]),\n",
       " tensor([[-274.0000,   -8.0625,    9.5000,  ...,   -5.6875,   -8.7500,\n",
       "            -7.9688]]),\n",
       " tensor([[-426.0000,   -9.1250,    8.7500,  ...,   -8.5000,   -8.7500,\n",
       "            -8.5000]]),\n",
       " tensor([[-230.0000,   -7.0312,    8.1875,  ...,   -7.7500,   -8.5000,\n",
       "            -7.2500]]),\n",
       " tensor([[-220.0000,   -8.1875,    8.0625,  ...,   -6.7812,   -8.0625,\n",
       "            -7.2500]]),\n",
       " tensor([[-156.0000,   -7.8750,    8.1875,  ...,   -4.8750,   -5.0312,\n",
       "            -5.4688]]),\n",
       " tensor([[-284.0000,   -7.0000,   11.7500,  ...,   -6.3438,   -7.8125,\n",
       "            -8.8125]]),\n",
       " tensor([[-270.0000,   -7.8125,    8.5000,  ...,   -6.2188,   -8.1875,\n",
       "            -8.6250]]),\n",
       " tensor([[-239.0000,   -7.5625,   11.1250,  ...,   -5.8438,   -9.1250,\n",
       "            -7.7188]]),\n",
       " tensor([[-264.0000,   -8.8125,   11.3750,  ...,   -9.4375,   -9.1875,\n",
       "            -8.9375]]),\n",
       " tensor([[-245.0000,   -8.4375,   12.6250,  ...,   -8.1875,   -8.3750,\n",
       "            -8.0625]]),\n",
       " tensor([[-280.0000,   -7.2812,   13.6250,  ...,   -8.9375,   -8.5625,\n",
       "            -7.7812]]),\n",
       " tensor([[-270.0000,   -7.2500,   12.1875,  ...,   -8.1250,   -9.8750,\n",
       "            -8.6250]]),\n",
       " tensor([[-324.0000,   -6.7500,   11.4375,  ...,   -5.9375,   -7.5312,\n",
       "            -7.7812]]),\n",
       " tensor([[-300.0000,   -6.5625,   12.1250,  ...,   -6.5625,   -8.6250,\n",
       "            -7.0625]]),\n",
       " tensor([[-195.0000,   -8.7500,   13.0000,  ...,   -6.6562,   -9.1250,\n",
       "            -8.7500]]),\n",
       " tensor([[-302.0000,   -7.5625,   13.0000,  ...,   -8.0625,   -9.2500,\n",
       "            -8.8125]]),\n",
       " tensor([[-220.0000,  -10.3750,   12.8125,  ...,  -10.6250,   -7.7812,\n",
       "            -7.7812]]),\n",
       " tensor([[-232.0000,   -8.6875,   13.3125,  ...,   -8.5000,   -9.5625,\n",
       "            -8.5000]]),\n",
       " tensor([[-226.0000,   -7.5625,   13.3125,  ...,   -6.3438,   -9.8750,\n",
       "            -6.5312]]),\n",
       " tensor([[-288.0000,   -7.5312,   14.0625,  ...,   -8.6875,   -9.8750,\n",
       "            -9.0625]]),\n",
       " tensor([[-239.0000,   -9.5625,   12.1250,  ...,   -6.1562,   -9.7500,\n",
       "            -7.7500]]),\n",
       " tensor([[-284.0000,   -7.7500,   13.5625,  ...,   -9.6250,   -9.1875,\n",
       "            -8.3125]]),\n",
       " tensor([[-253.0000,   -7.5000,   11.8125,  ...,   -6.6875,   -9.3125,\n",
       "            -8.9375]]),\n",
       " tensor([[-300.0000,   -7.3438,   13.4375,  ...,   -9.4375,   -9.6250,\n",
       "            -7.2188]]),\n",
       " tensor([[-246.0000,  -10.2500,   13.8125,  ...,  -11.1875,  -10.0000,\n",
       "            -8.8125]]),\n",
       " tensor([[-264.0000,   -6.1562,   14.3750,  ...,   -6.6875,   -8.8750,\n",
       "            -7.3750]]),\n",
       " tensor([[-207.0000,   -6.1250,   11.8750,  ...,   -2.0938,   -6.0938,\n",
       "            -5.0625]]),\n",
       " tensor([[-231.0000,   -8.3750,   12.1875,  ...,   -3.6250,   -6.7500,\n",
       "            -7.1875]]),\n",
       " tensor([[-166.0000,   -8.5625,   10.6250,  ...,   -3.9531,   -7.0625,\n",
       "            -7.7188]]),\n",
       " tensor([[-101.0000,   -6.5312,   12.0000,  ...,   -7.0000,   -5.7812,\n",
       "            -4.3438]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(scores_self.unsqueeze(1), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# simulates processors and gets next tokens\n",
    "\n",
    "\n",
    "min(50, scores_self.size(-1))\n",
    "top_k = 50\n",
    "indices_to_remove = scores_self < torch.topk(scores_self, top_k)[0][..., -1, None]\n",
    "indices_to_remove\n",
    "scores_processed_top_k = scores_self.masked_fill(indices_to_remove, -float(\"Inf\"))\n",
    "torch.max(scores_processed_top_k [0])\n",
    "\n",
    "top_p = 0.0\n",
    "\n",
    "sorted_logits, sorted_indices = torch.sort(scores_processed_top_k, descending=False)\n",
    "cumulative_probs = sorted_logits.softmax(dim=-1).cumsum(dim=-1)\n",
    "\n",
    "# Remove tokens with cumulative top_p above the threshold (token with 0 are kept)\n",
    "sorted_indices_to_remove = cumulative_probs <= (1 - top_p)\n",
    "# Keep at least min_tokens_to_keep\n",
    "sorted_indices_to_remove[..., -1 :] = 0\n",
    "\n",
    "# scatter sorted tensors to original indexing\n",
    "indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
    "scores_processed_top_p = scores_processed_top_k.masked_fill(indices_to_remove, -float(\"Inf\"))\n",
    "print(torch.max(scores_processed_top_k [0]))\n",
    "scores_processed_top_p \n",
    "\n",
    "probs = F.softmax(scores_processed_top_p , dim=-1)\n",
    "next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "next_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokens_and_logprobs(sequence_ids, logits):\n",
    "    probs = torch.log_softmax(torch.stack(list(logits), dim=0), dim=-1).detach()\n",
    "\n",
    "    # collect the probability of the generated token -- probability at index 0 corresponds to the token at index 1\n",
    "    probs = probs[:-1, :, :] # match shift -> no probability for first token\n",
    "    sequence_ids = sequence_ids.unsqueeze(0)[:, 1:] # shift away first token as probs[0] -> token[1]\n",
    "    gen_probs = torch.gather(probs, 2, sequence_ids[:,None,:]).squeeze(1)\n",
    "    print(gen_probs.shape)\n",
    "    print(sequence_ids.shape)\n",
    "    batch = []\n",
    "    for generation, probs in zip(sequence_ids, gen_probs):\n",
    "        text_sequence = []\n",
    "        #print(generation.shape)\n",
    "        #print(probs.shape)\n",
    "        for token, p in zip(generation, probs):\n",
    "            if token not in tokenizer.all_special_ids:\n",
    "                #print(token.shape)\n",
    "                #print(p.shape)\n",
    "                text_sequence.append((tokenizer.decode(token.item()), p.item()))\n",
    "        batch.append(text_sequence)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 248])\n",
      "torch.Size([1, 248])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('answer', -8.649835586547852),\n",
       "  ('this', -11.462335586547852),\n",
       "  ('question', -15.505304336547852),\n",
       "  (',', -15.126398086547852),\n",
       "  ('we', -15.587335586547852),\n",
       "  ('need', -13.923273086547852),\n",
       "  ('to', -5.087335586547852),\n",
       "  ('identify', -13.438898086547852),\n",
       "  ('the', -11.321710586547852),\n",
       "  ('documents', -16.55608558654785),\n",
       "  ('that', -14.024835586547852),\n",
       "  ('can', -15.407648086547852),\n",
       "  ('be', -14.173273086547852),\n",
       "  ('accepted', -12.829523086547852),\n",
       "  ('as', -13.423273086547852),\n",
       "  ('proof', -17.47796058654785),\n",
       "  ('of', -13.173273086547852),\n",
       "  ('German', -10.852960586547852),\n",
       "  ('language', -14.243585586547852),\n",
       "  ('skills', -17.72796058654785),\n",
       "  ('mentioned', -14.237726211547852),\n",
       "  ('in', -12.477960586547852),\n",
       "  ('the', -11.321710586547852),\n",
       "  ('context', -10.524835586547852),\n",
       "  ('.', -13.079523086547852),\n",
       "  ('The', -3.5873355865478516),\n",
       "  ('relevant', -15.247491836547852),\n",
       "  ('information', -16.03264808654785),\n",
       "  ('is', -13.974054336547852),\n",
       "  ('found', -16.52483558654785),\n",
       "  ('in', -12.477960586547852),\n",
       "  ('the', -11.321710586547852),\n",
       "  ('sentence', -11.931085586547852),\n",
       "  (':', -10.337335586547852),\n",
       "  ('##', -8.993585586547852),\n",
       "  ('begin', -11.634210586547852),\n",
       "  ('_', -12.954523086547852),\n",
       "  ('quote', -13.423273086547852),\n",
       "  ('##', -11.149835586547852),\n",
       "  ('\"', -11.524835586547852),\n",
       "  ('F', -16.37639808654785),\n",
       "  ('er', -14.573602676391602),\n",
       "  ('ner', -14.535821914672852),\n",
       "  ('kann', -14.268976211547852),\n",
       "  ('der', -12.056085586547852),\n",
       "  ('Spr', -13.118585586547852),\n",
       "  ('ach', -16.69671058654785),\n",
       "  ('n', -12.688898086547852),\n",
       "  ('ach', -16.69671058654785),\n",
       "  ('we', -20.46233558654785),\n",
       "  ('is', -17.72796058654785),\n",
       "  ('durch', -14.646661758422852),\n",
       "  ('die', -12.688898086547852),\n",
       "  ('Vor', -12.306085586547852),\n",
       "  ('lage', -16.31389808654785),\n",
       "  ('eines', -12.181085586547852),\n",
       "  ('der', -12.056085586547852),\n",
       "  ('folg', -13.024835586547852),\n",
       "  ('enden', -16.18889808654785),\n",
       "  ('D', -10.118585586547852),\n",
       "  ('ok', -16.14202308654785),\n",
       "  ('ument', -15.751398086547852),\n",
       "  ('e', -16.77483558654785),\n",
       "  ('er', -13.235773086547852),\n",
       "  ('br', -14.424249649047852),\n",
       "  ('acht', -14.731866836547852),\n",
       "  ('werden', -12.977960586547852),\n",
       "  (':\"', -13.321710586547852),\n",
       "  ('##', -8.993585586547852),\n",
       "  ('end', -18.32171058654785),\n",
       "  ('_', -12.954523086547852),\n",
       "  ('quote', -13.423273086547852),\n",
       "  ('##', -11.149835586547852),\n",
       "  ('This', -4.274835586547852),\n",
       "  ('sentence', -11.931085586547852),\n",
       "  ('indicates', -14.506280899047852),\n",
       "  ('that', -14.024835586547852),\n",
       "  ('there', -15.497491836547852),\n",
       "  ('are', -15.497491836547852),\n",
       "  ('certain', -18.54046058654785),\n",
       "  ('documents', -16.55608558654785),\n",
       "  ('that', -14.024835586547852),\n",
       "  ('can', -15.407648086547852),\n",
       "  ('serve', -16.75921058654785),\n",
       "  ('as', -13.423273086547852),\n",
       "  ('evidence', -15.899835586547852),\n",
       "  ('of', -13.173273086547852),\n",
       "  ('German', -10.852960586547852),\n",
       "  ('language', -14.243585586547852),\n",
       "  ('prof', -15.899835586547852),\n",
       "  ('iciency', -18.38421058654785),\n",
       "  ('.', -13.079523086547852),\n",
       "  ('The', -3.5873355865478516),\n",
       "  ('list', -15.821710586547852),\n",
       "  ('of', -13.173273086547852),\n",
       "  ('these', -14.839288711547852),\n",
       "  ('documents', -16.55608558654785),\n",
       "  ('is', -13.974054336547852),\n",
       "  ('given', -14.118585586547852),\n",
       "  ('in', -12.477960586547852),\n",
       "  ('the', -11.321710586547852),\n",
       "  ('subsequent', -15.177179336547852),\n",
       "  ('sentences', -12.337335586547852),\n",
       "  ('.', -13.079523086547852),\n",
       "  ('\\n', -7.493585586547852),\n",
       "  ('\\n', -7.493585586547852),\n",
       "  ('<', -9.993585586547852),\n",
       "  ('AN', -12.181085586547852),\n",
       "  ('SW', -17.77483558654785),\n",
       "  ('ER', -14.206476211547852),\n",
       "  ('>:', -15.069757461547852),\n",
       "  ('The', -3.5873355865478516),\n",
       "  ('documents', -16.55608558654785),\n",
       "  ('that', -14.024835586547852),\n",
       "  ('can', -15.407648086547852),\n",
       "  ('be', -14.173273086547852),\n",
       "  ('accepted', -12.829523086547852),\n",
       "  ('as', -13.423273086547852),\n",
       "  ('proof', -17.47796058654785),\n",
       "  ('of', -13.173273086547852),\n",
       "  ('German', -10.852960586547852),\n",
       "  ('language', -14.243585586547852),\n",
       "  ('skills', -17.72796058654785),\n",
       "  ('include', -15.946710586547852),\n",
       "  (':', -10.337335586547852),\n",
       "  ('', -6.962335586547852),\n",
       "  ('1', -14.944757461547852),\n",
       "  ('.', -13.079523086547852),\n",
       "  ('A', -7.431085586547852),\n",
       "  ('certificate', -17.14983558654785),\n",
       "  ('of', -13.173273086547852),\n",
       "  ('successful', -15.552179336547852),\n",
       "  ('completion', -15.532648086547852),\n",
       "  ('of', -13.173273086547852),\n",
       "  ('a', -12.071710586547852),\n",
       "  ('course', -15.446710586547852),\n",
       "  ('of', -13.173273086547852),\n",
       "  ('study', -16.34514808654785),\n",
       "  ('at', -15.380304336547852),\n",
       "  ('a', -12.071710586547852),\n",
       "  ('university', -16.21233558654785),\n",
       "  (',', -15.126398086547852),\n",
       "  ('', -6.962335586547852),\n",
       "  ('2', -15.368585586547852),\n",
       "  ('.', -13.079523086547852),\n",
       "  ('A', -7.431085586547852),\n",
       "  ('Test', -11.118585586547852),\n",
       "  ('Deutsch', -11.556085586547852),\n",
       "  ('als', -12.118585586547852),\n",
       "  ('F', -10.962335586547852),\n",
       "  ('rem', -17.07171058654785),\n",
       "  ('ds', -16.37639808654785),\n",
       "  ('pr', -17.21233558654785),\n",
       "  ('ache', -16.14983558654785),\n",
       "  ('(', -11.556085586547852),\n",
       "  ('Test', -16.33733558654785),\n",
       "  ('Da', -14.505304336547852),\n",
       "  ('F', -16.37639808654785),\n",
       "  ('),', -14.466730117797852),\n",
       "  ('if', -15.602960586547852),\n",
       "  ('the', -11.321710586547852),\n",
       "  ('average', -15.798273086547852),\n",
       "  ('score', -15.161554336547852),\n",
       "  ('was', -15.735773086547852),\n",
       "  ('at', -15.380304336547852),\n",
       "  ('least', -16.38421058654785),\n",
       "  ('level', -15.727960586547852),\n",
       "  ('TD', -14.685480117797852),\n",
       "  ('N', -14.335382461547852),\n",
       "  ('', -6.962335586547852),\n",
       "  ('4', -14.706476211547852),\n",
       "  (',', -15.126398086547852),\n",
       "  ('', -6.962335586547852),\n",
       "  ('3', -15.302179336547852),\n",
       "  ('.', -13.079523086547852),\n",
       "  ('A', -7.431085586547852),\n",
       "  ('German', -10.852960586547852),\n",
       "  ('Language', -11.556085586547852),\n",
       "  ('Prof', -13.938898086547852),\n",
       "  ('iciency', -18.38421058654785),\n",
       "  ('Test', -11.118585586547852),\n",
       "  ('for', -13.188898086547852),\n",
       "  ('University', -13.888116836547852),\n",
       "  ('Ad', -12.321710586547852),\n",
       "  ('mission', -18.71233558654785),\n",
       "  ('(', -11.556085586547852),\n",
       "  ('D', -14.909601211547852),\n",
       "  ('SH', -15.720148086547852),\n",
       "  ('),', -14.466730117797852),\n",
       "  ('if', -15.602960586547852),\n",
       "  ('it', -12.556085586547852),\n",
       "  ('was', -15.735773086547852),\n",
       "  ('completed', -11.712335586547852),\n",
       "  ('with', -13.942804336547852),\n",
       "  ('at', -15.380304336547852),\n",
       "  ('least', -16.38421058654785),\n",
       "  ('the', -11.321710586547852),\n",
       "  ('level', -15.727960586547852),\n",
       "  ('D', -10.118585586547852),\n",
       "  ('SH', -15.720148086547852),\n",
       "  ('-', -12.243585586547852),\n",
       "  ('2', -15.368585586547852),\n",
       "  (',', -15.126398086547852),\n",
       "  ('or', -13.517023086547852),\n",
       "  ('', -6.962335586547852),\n",
       "  ('4', -14.706476211547852),\n",
       "  ('.', -13.079523086547852),\n",
       "  ('\"', -11.524835586547852),\n",
       "  ('T', -16.15764808654785),\n",
       "  ('el', -16.63421058654785),\n",
       "  ('c', -18.33733558654785),\n",
       "  ('Deutsch', -11.556085586547852),\n",
       "  ('C', -12.337335586547852),\n",
       "  ('1', -14.944757461547852),\n",
       "  ('Hoch', -10.899835586547852),\n",
       "  ('sch', -18.10296058654785),\n",
       "  ('ule', -15.727960586547852),\n",
       "  ('\"', -13.227960586547852),\n",
       "  ('or', -13.517023086547852),\n",
       "  ('an', -12.352960586547852),\n",
       "  ('equivalent', -14.340265274047852),\n",
       "  ('language', -14.243585586547852),\n",
       "  ('test', -16.44671058654785),\n",
       "  ('according', -13.477960586547852),\n",
       "  ('to', -5.087335586547852),\n",
       "  ('the', -11.321710586547852),\n",
       "  ('Frame', -11.868585586547852),\n",
       "  ('work', -19.52483558654785),\n",
       "  ('Ord', -14.001398086547852),\n",
       "  ('in', -17.94671058654785),\n",
       "  ('ance', -22.08733558654785),\n",
       "  ('on', -16.58733558654785),\n",
       "  ('German', -10.852960586547852),\n",
       "  ('Language', -11.556085586547852),\n",
       "  ('Ex', -9.087335586547852),\n",
       "  ('amin', -23.14983558654785),\n",
       "  ('ations', -15.360773086547852),\n",
       "  ('for', -13.188898086547852),\n",
       "  ('Hig', -13.591241836547852),\n",
       "  ('her', -15.618585586547852),\n",
       "  ('Education', -12.431085586547852),\n",
       "  ('Studies', -14.564508438110352),\n",
       "  ('(', -11.556085586547852),\n",
       "  ('RO', -15.384210586547852),\n",
       "  ('-', -12.243585586547852),\n",
       "  ('DT', -17.04046058654785),\n",
       "  (').', -13.282648086547852)]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = to_tokens_and_logprobs(sequences[-1][input_ids.shape[1]:], logits)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([647, 1, 32768])\n",
      "torch.Size([1, 3163])\n",
      "torch.Size([1, 3810])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([647])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.stack(list(logits), dim=0).shape)\n",
    "print(input_ids.shape)\n",
    "print(sequences.shape)\n",
    "sequences[-1][input_ids.shape[1]:].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
