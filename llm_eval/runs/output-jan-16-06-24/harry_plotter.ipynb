{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>output</th>\n",
       "      <th>answer</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>question</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>timings.load_time.time</th>\n",
       "      <th>timings.sample_time.time</th>\n",
       "      <th>timings.sample_time.runs</th>\n",
       "      <th>...</th>\n",
       "      <th>timings.prompt_eval_time.tokens_per_second</th>\n",
       "      <th>timings.eval_time.time</th>\n",
       "      <th>timings.eval_time.runs</th>\n",
       "      <th>timings.eval_time.ms_per_token</th>\n",
       "      <th>timings.eval_time.tokens_per_second</th>\n",
       "      <th>timings.total_time.time</th>\n",
       "      <th>timings.total_time.tokens</th>\n",
       "      <th>token_usage.prompt_tokens</th>\n",
       "      <th>token_usage.completion_tokens</th>\n",
       "      <th>token_usage.total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral-7b-instruct-v0.2.Q4_K_M</td>\n",
       "      <td>(Translation: Which documents can be accepted...</td>\n",
       "      <td>Als Nachweis für deutsche Sprachkenntnisse kön...</td>\n",
       "      <td>1.065307</td>\n",
       "      <td>length</td>\n",
       "      <td>Welche Dokumente können als Nachweis für deuts...</td>\n",
       "      <td>32778</td>\n",
       "      <td>1381.2</td>\n",
       "      <td>81.14</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>183.21</td>\n",
       "      <td>14015.64</td>\n",
       "      <td>14015</td>\n",
       "      <td>54.96</td>\n",
       "      <td>18.19</td>\n",
       "      <td>16716.99</td>\n",
       "      <td>16716</td>\n",
       "      <td>253</td>\n",
       "      <td>256</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  \\\n",
       "0  mistral-7b-instruct-v0.2.Q4_K_M   \n",
       "\n",
       "                                              output  \\\n",
       "0   (Translation: Which documents can be accepted...   \n",
       "\n",
       "                                              answer  perplexity  \\\n",
       "0  Als Nachweis für deutsche Sprachkenntnisse kön...    1.065307   \n",
       "\n",
       "  finish_reason                                           question  \\\n",
       "0        length  Welche Dokumente können als Nachweis für deuts...   \n",
       "\n",
       "   latency_ms  timings.load_time.time  timings.sample_time.time  \\\n",
       "0       32778                  1381.2                     81.14   \n",
       "\n",
       "   timings.sample_time.runs  ...  timings.prompt_eval_time.tokens_per_second  \\\n",
       "0                        81  ...                                      183.21   \n",
       "\n",
       "   timings.eval_time.time  timings.eval_time.runs  \\\n",
       "0                14015.64                   14015   \n",
       "\n",
       "   timings.eval_time.ms_per_token  timings.eval_time.tokens_per_second  \\\n",
       "0                           54.96                                18.19   \n",
       "\n",
       "   timings.total_time.time  timings.total_time.tokens  \\\n",
       "0                 16716.99                      16716   \n",
       "\n",
       "   token_usage.prompt_tokens  token_usage.completion_tokens  \\\n",
       "0                        253                            256   \n",
       "\n",
       "   token_usage.total_tokens  \n",
       "0                       509  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('output_generation_results.json', encoding='utf-8-sig') as f_input:\n",
    "    df = pd.json_normalize(json.load(f_input))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "with open('output_generation_results.json', encoding='utf-8-sig') as f_input:\n",
    "    df = pd.json_normalize(json.load(f_input))\n",
    "\n",
    "\n",
    "df = df.sort_values(by='model')\n",
    "\n",
    "# Unique Models\n",
    "unique_models = sorted(df['model'].unique())\n",
    "\n",
    "llm_column = 'model'\n",
    "\n",
    "# only metrci column names\n",
    "metric_columns = [col for col in df.columns if col != llm_column and col != 'question' and col != 'answer']\n",
    "\n",
    "\n",
    "\n",
    "for metric in metric_columns:\n",
    "\n",
    "    metric_data = df[metric]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6.5))\n",
    "    \n",
    "    plt.subplot(4, 1, 1)\n",
    "    sns.boxplot(data=metric_data, x='Similarity Score', y='Model', color='skyblue', order=unique_models)\n",
    "    plt.xlabel('Metric Score')\n",
    "    plt.title(f'Similarity Scores Modelle - {metric}')\n",
    "    plt.xlim(-0.02, 1.02)  \n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    weighted_specificities = metric_data['Similarity Score'] * (1-metric_data['Specificity']) * metric_data['Relevance']\n",
    "    sns.boxplot(x=weighted_specificities, y=metric_data['Model'], color='orange', width=0.5, fliersize=0, order=unique_models)\n",
    "    plt.xlabel('Weighted [Specificity, Relevance] Score')\n",
    "    plt.title(f'Gewichtete [Specificity, Relevance] Scores Modelle - {metric}')\n",
    "    #plt.xlim(-0.02, 1.02) \n",
    "    \n",
    "    plt.subplot(4, 1, 3)\n",
    "    weighted_specificities = metric_data['Similarity Score'] * (1-metric_data['Specificity'])\n",
    "    sns.boxplot(x=weighted_specificities, y=metric_data['Model'], color='red', width=0.5, fliersize=0, order=unique_models)\n",
    "    plt.xlabel('Weighted [Specificity] Score')\n",
    "    plt.title(f'Gewichtete [Specificity] Scores Modelle - {metric}')\n",
    "    #plt.xlim(-0.02, 1.02) \n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    weighted_relevances = metric_data['Similarity Score'] * metric_data['Relevance']\n",
    "    sns.boxplot(x=weighted_relevances, y=metric_data['Model'], color='green', width=0.5, fliersize=0, order=unique_models)\n",
    "    plt.xlabel('Weighted [Relevance] Score')\n",
    "    plt.title(f'Gewichtete [Relevance] Scores Modelle - {metric}')\n",
    "    #plt.xlim(-0.02, 1.02)  \n",
    "    \n",
    "    plt.subplots_adjust(hspace=100)\n",
    "\n",
    "    # Plotten\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>output</th>\n",
       "      <th>answer</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>question</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>timings.load_time.time</th>\n",
       "      <th>timings.sample_time.time</th>\n",
       "      <th>timings.sample_time.runs</th>\n",
       "      <th>...</th>\n",
       "      <th>timings.prompt_eval_time.tokens_per_second</th>\n",
       "      <th>timings.eval_time.time</th>\n",
       "      <th>timings.eval_time.runs</th>\n",
       "      <th>timings.eval_time.ms_per_token</th>\n",
       "      <th>timings.eval_time.tokens_per_second</th>\n",
       "      <th>timings.total_time.time</th>\n",
       "      <th>timings.total_time.tokens</th>\n",
       "      <th>token_usage.prompt_tokens</th>\n",
       "      <th>token_usage.completion_tokens</th>\n",
       "      <th>token_usage.total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral-7b-instruct-v0.2.Q4_K_M</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>1.065307</td>\n",
       "      <td>length</td>\n",
       "      <td>Welche Dokumente können als Nachweis für deuts...</td>\n",
       "      <td>32778</td>\n",
       "      <td>1381.2</td>\n",
       "      <td>81.14</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>183.21</td>\n",
       "      <td>14015.64</td>\n",
       "      <td>14015</td>\n",
       "      <td>54.96</td>\n",
       "      <td>18.19</td>\n",
       "      <td>16716.99</td>\n",
       "      <td>16716</td>\n",
       "      <td>253</td>\n",
       "      <td>256</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model output answer  perplexity finish_reason  \\\n",
       "0  mistral-7b-instruct-v0.2.Q4_K_M   test   test    1.065307        length   \n",
       "\n",
       "                                            question  latency_ms  \\\n",
       "0  Welche Dokumente können als Nachweis für deuts...       32778   \n",
       "\n",
       "   timings.load_time.time  timings.sample_time.time  timings.sample_time.runs  \\\n",
       "0                  1381.2                     81.14                        81   \n",
       "\n",
       "   ...  timings.prompt_eval_time.tokens_per_second  timings.eval_time.time  \\\n",
       "0  ...                                      183.21                14015.64   \n",
       "\n",
       "   timings.eval_time.runs  timings.eval_time.ms_per_token  \\\n",
       "0                   14015                           54.96   \n",
       "\n",
       "   timings.eval_time.tokens_per_second  timings.total_time.time  \\\n",
       "0                                18.19                 16716.99   \n",
       "\n",
       "   timings.total_time.tokens  token_usage.prompt_tokens  \\\n",
       "0                      16716                        253   \n",
       "\n",
       "   token_usage.completion_tokens  token_usage.total_tokens  \n",
       "0                            256                       509  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"model\": \"mistral-7b-instruct-v0.2.Q4_K_M\",\n",
    "        \"output\": 'test',      \n",
    "        \"answer\": 'test',\n",
    "        \"perplexity\": 1.0653073614871005,\n",
    "        \"timings\": {\n",
    "            \"load_time\": {\"time\": 1381.2},\n",
    "            \"sample_time\": {\"time\": 81.14, \"runs\": 81, \"ms_per_token\": 0.32, \"tokens_per_second\": 3155.2},\n",
    "            \"prompt_eval_time\": {\"time\": 1380.92, \"tokens\": 1380, \"ms_per_token\": 5.46, \"tokens_per_second\": 183.21},\n",
    "            \"eval_time\": {\"time\": 14015.64, \"runs\": 14015, \"ms_per_token\": 54.96, \"tokens_per_second\": 18.19},\n",
    "            \"total_time\": {\"time\": 16716.99, \"tokens\": 16716}\n",
    "        },\n",
    "        \"token_usage\": {\"prompt_tokens\": 253, \"completion_tokens\": 256, \"total_tokens\": 509},\n",
    "        \"finish_reason\": \"length\",\n",
    "        \"question\": \"Welche Dokumente können als Nachweis für deutsche Sprachkenntnisse akzeptiert werden?\",\n",
    "        \"latency_ms\": 32778\n",
    "    }\n",
    "]\n",
    "\n",
    "# Flatten JSON data into a pandas DataFrame\n",
    "df = pd.json_normalize(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/environments/rag/lib/python3.10/site-packages/pandas/io/json/_normalize.py:443\u001b[0m, in \u001b[0;36mjson_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[1;32m    439\u001b[0m     data \u001b[38;5;241m=\u001b[39m [data]\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, abc\u001b[38;5;241m.\u001b[39mIterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# GH35923 Fix pd.json_normalize to not skip the first element of a\u001b[39;00m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# generator input\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
