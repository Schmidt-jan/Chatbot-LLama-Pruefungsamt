{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bitsandbytes\n",
    "#!pip install git+https://github.com/huggingface/transformers.git\n",
    "#!pip install git+https://github.com/huggingface/peft.git\n",
    "#!pip install git+https://github.com/huggingface/accelerate.git\n",
    "#!pip install datasets scipy ipywidgets matplotlib\n",
    "#!pip install sentencepiece\n",
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trl\n",
    "#!pip install flash-attn --no-build-isolation  # -> needs CUDA 11.6 or newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351bb7519dc94a5ea8f3e2df02f855af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669053ce297e4d17b5876937aded0d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"datasets/chatbot-documents/\"\n",
    "\n",
    "train_dataset = load_dataset('json', data_files=f'{dataset_path}train.json', split='train') #need to split as it will otherwise create a nested object\n",
    "eval_dataset = load_dataset('json', data_files=f'{dataset_path}validation.json', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['paragraph'],\n",
       "    num_rows: 140\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenjaminbruenau\u001b[0m (\u001b[33mteamprojekt-chatbot-pruefungsamt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"teamprojekt-chatbot-pruefungsamt\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer the following question based only on the provided context. Always return the source of an information and it is mandatory to answer in GERMAN:\n",
    "#The following is a document pragraph of the Master Informatik at HTWG Konstanz:\n",
    "# You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter:\n",
    "def formatting_func(example):\n",
    "    text = f\"### You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter: {example['paragraph']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10b576e0ede477a841d26490d736574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n pip install huggingface_hub[\"cli\"]\\nhuggingface-cli delete-cache\\nhuggingface-cli login\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# only necessary if model is not cached\n",
    "#notebook_login()\n",
    "\n",
    "'''\n",
    " pip install huggingface_hub[\"cli\"]\n",
    "huggingface-cli delete-cache\n",
    "huggingface-cli login\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27554d34b5a04b31aa60964c1d47f5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"#\"../../../llms/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8779d74052549bc9051962bd48d0035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14e70142e4a40be9f16888827f0ff2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1700 # truncate input after max length\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c8b7c9454b4ca59388a1ebf2c44d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf41ac76c484748b26676b5024a69be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1542, 1763, 1228, 1032, 8223, 11633, 14660, 1122, 1040, 8028, 29548, 29545, 9062, 1071, 5647, 29491, 1763, 5140, 1475, 3764, 1452, 1040, 4016, 3850, 1054, 2004, 8560, 29515, 19970, 3220, 2158, 9062, 1071, 5647, 29473, 781, 9714, 2586, 1617, 29493, 1162, 17788, 1408, 26185, 3072, 1737, 29473, 781, 29473, 781, 29473, 781, 2748, 1338, 29473, 29518, 2576, 29473, 29549, 29538, 29473, 781, 9714, 1077, 29473, 29508, 1532, 1862, 24234, 1737, 5281, 1165, 1307, 29473, 781, 29806, 29473, 29508, 1862, 24234, 1737, 5281, 1165, 1307, 29473, 781, 29500, 29508, 29499, 29473, 29508, 29525, 1265, 29474, 1086, 6892, 1737, 1087, 3373, 4214, 1970, 8120, 27712, 1111, 29490, 19425, 1408, 1970, 1822, 1121, 1257, 1737, 1065, 2225, 16048, 9099, 29473, 781, 16828, 1071, 11859, 1748, 8373, 1037, 29515, 29473, 781, 1010, 934, 938, 7341, 1338, 26715, 1093, 29523, 1855, 1325, 29473, 781, 1010, 934, 938, 9995, 10255, 1617, 1465, 16825, 1093, 29523, 29564, 29525, 1325, 29473, 781, 1010, 934, 938, 16863, 29501, 1408, 13282, 29495, 1069, 1925, 1037, 23302, 29495, 24436, 1093, 29523, 4238, 1325, 29473, 781, 1010, 934, 938, 13218, 21180, 4519, 2903, 29474, 1093, 29517, 4787, 1325, 29473, 781, 1010, 934, 938, 8479, 9916, 13279, 1093, 8938, 1325, 29473, 781, 1010, 934, 938, 1328, 4530, 1617, 1093, 29523, 3823, 1325, 29473, 781, 1010, 934, 938, 16707, 29306, 18027, 17970, 1093, 12025, 1325, 29473, 781, 1010, 934, 938, 13282, 29495, 2575, 29501, 1408, 3695, 29490, 19425, 3221, 2586, 1617, 1093, 29547, 10866, 1325, 29473, 781, 1010, 934, 938, 1162, 17788, 29481, 11582, 23302, 29495, 24436, 1093, 29523, 15513, 1325, 29473, 781, 1010, 934, 938, 3365, 13700, 2457, 1617, 1093, 29523, 2342, 1325, 29473, 781, 1010, 934, 938, 23070, 17970, 1072, 10234, 1093, 6645, 29517, 1325, 29473, 781, 1010, 934, 938, 11720, 13435, 29487, 1364, 16259, 1737, 1093, 29528, 20124, 1325, 29473, 781, 1010, 934, 938, 6208, 10234, 11833, 29501, 20066, 1093, 29523, 4787, 1325, 29473, 781, 1010, 934, 938, 22778, 10234, 1093, 7978, 29523, 1325, 29473, 781, 1010, 934, 938, 6208, 8527, 17970, 1093, 29505, 2535, 1377, 29473, 781, 29500, 29518, 29499, 29473, 29508, 15660, 1862, 28251, 1659, 5674, 2143, 1044, 29490, 23204, 1220, 6059, 2142, 3871, 1065, 1312, 1037, 10129, 1071, 11859, 1748, 8373, 1037, 15817, 29480, 6068, 3022, 29491, 29473, 29518, 29503, 1180, 29473, 781, 9408, 15814, 4634, 4410, 1659, 3695, 1324, 15833, 1402, 1162, 17208, 29481, 26853, 2730, 29481, 1133, 8315, 29584, 29548, 3123, 1549, 2082, 29489, 6199, 1970, 29473, 781, 29533, 1142, 1441, 26165, 2576, 1822, 1121, 1257, 1737, 5795, 1680, 2772, 1164, 2225, 19970, 3220, 1121, 1037, 4214, 1164, 17307, 1159, 1192, 1162, 17208, 1037, 29473, 781, 29500, 26980, 13307, 29501, 14075, 29548, 29499, 1065, 1659, 2986, 1537, 5312, 1087, 2575, 9099, 1169, 1257, 1737, 29491, 29473, 29538, 15660, 5674, 2143, 1220, 6059, 2142, 7214, 5624, 3252, 29532, 1554, 1659, 29473, 781, 29558, 1039, 1143, 13560, 1037, 15805, 26597, 26353, 29473, 29552, 13477, 6892, 29473, 29549, 1086, 6892, 29473, 29552, 1381, 29491, 1318, 29491, 1058, 29491, 13477, 6892, 29473, 29508, 1086, 6892, 29473, 29518, 16523, 1562, 29473, 29508, 1093, 29537, 2785, 1192, 9965, 15075, 29499, 29473, 781, 1683, 16523, 1562, 29473, 29549, 1093, 2996, 1842, 6661, 1737, 1271, 6972, 1264, 1076, 8014, 5055, 10660, 29499, 19970, 3220, 1121, 29532, 1121, 1257, 7339, 3479, 14427, 1093, 29537, 29596, 29545, 29499, 29473, 781, 29479, 1363, 2261, 3620, 5909, 12533, 1402, 1063, 4810, 3220, 2158, 4115, 1037, 8120, 27712, 1111, 29490, 19425, 29481, 15805, 26597, 1659, 5624, 17858, 9099, 29473, 781, 19880, 9413, 5308, 29493, 2256, 11122, 1857, 1165, 1659, 1292, 4946, 2143, 5624, 26353, 29473, 29550, 29493, 2197, 19934, 29491, 29473, 781, 29500, 29538, 29499, 29473, 29508, 15660, 1312, 19000, 1030, 4214, 3614, 1822, 1121, 1257, 7339, 1111, 29490, 19425, 1087, 2575, 9099, 6238, 9413, 5308, 1065, 1659, 1822, 1121, 1257, 7339, 29501, 29473, 781, 1683, 3004, 3844, 8897, 7109, 1324, 15833, 1659, 19970, 3220, 2158, 9062, 1071, 5647, 1093, 29596, 5194, 29499, 8780, 1361, 1037, 1289, 1305, 8504, 29475, 29491, 1027, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 2]\n",
      "176\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse akzeptiert werden?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse akzeptiert werden?\n",
      "\n",
      "## German Language Requirements for Immigration to Canada\n",
      "\n",
      "If you are planning on immigrating to Canada, it is important that you understand the language requirements. The Canadian government has set up a point system called Express Entry which allows immigrants from all over the world to apply for permanent residency in Canada. One of the factors considered when determining your eligibility under this program is whether or not you have sufficient knowledge of either English or French (or both). This blog post will discuss what documents can be used as proof of proficiency in these languages and how they may affect your application process!\n",
      "\n",
      "### What Documents Can Be Used As Proof Of Proficiency In These Languages And How They May Affect Your Application Process?\n",
      "\n",
      "There are many different types of documents that can be used as proof of proficiency in these languages. Some examples include:\n",
      "\n",
      "- Official transcripts from high school or university courses where the language was taught;\n",
      "- Certificates issued by an accredited institution showing completion of a course related to oneâ€™s desired profession;\n",
      "- Test scores such as TOEFL/IELTS results indicating fluency level achieved after taking examinations designed specifically for non-native speakers who wish to study abroad at\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32768, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85065728 || all params: 3843428352 || trainable%: 2.213277319342624\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32768, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32768, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32768, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "'''\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "#run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "#run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tpllmws23/Chatbot-LLama-Pruefungsamt/Chatbot-Benni/finetune/wandb/run-20240603_112933-9y5vfhek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/9y5vfhek' target=\"_blank\">Mistral-7B-v0.3-chatbot-pruefungsamt-finetune-2024-06-03-11-29</a></strong> to <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/9y5vfhek' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/9y5vfhek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 3:59:19, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.299500</td>\n",
       "      <td>1.489248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.898800</td>\n",
       "      <td>1.413895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>1.428244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>1.436466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.578100</td>\n",
       "      <td>1.426388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>1.527874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>1.513356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.389400</td>\n",
       "      <td>1.505803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>1.669006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>1.642109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>1.673851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>1.756534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>1.778848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>1.741483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>1.903520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>1.910608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>1.956910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>2.070651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>2.029626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>2.034780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.3770284667015076, metrics={'train_runtime': 14382.4808, 'train_samples_per_second': 0.07, 'train_steps_per_second': 0.035, 'total_flos': 7.34284898304e+16, 'train_loss': 0.3770284667015076, 'epoch': 7.142857142857143})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 25 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 25 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kill Kernel and Try the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9df603e7f9a405a9ea62b47591e1466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "#base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, run_name + \"/checkpoint-500\")\n",
    "#ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse an der HTWG akzeptiert werden?\n",
      "===============================================================================================\n",
      "\n",
      "Die folgenden Nachweise sind als Gleichwertige Urkunden zu einem Notenspiegel der\n",
      "HTWG Konstanz eingerechnet:\n",
      "\n",
      "1.  Das Schulabschlusszeugnis, aus dem die mindestens mit â€žausreichendâ€œ bewertete\n",
      "    Leistung des Deutschen Als PrÃ¼fungsmodalitÃ¤ten im Rahmen des grundstÃ¤ndigen\n",
      "    Studiums gemÃ¤ÃŸ Amtlichen Nahauflageplan des Landes Baden-WÃ¼rttemberg zugeordneten\n",
      "    Unterrichtsfaches hervorgeht oder eine Zugangsberechtigung zum berufsbegleitenden\n",
      "    Studium (Zugangsvoraussetzung ist ein wirtschaftswissenschaftlicher Abschluss).\n",
      "2.  Ein Notenspiegel, aus dem die bestandene PrÃ¼fungsleistung Ã¼ber das Deutsch als\n",
      "    Umgangssprache im Rahmen des fernunterrichtlichen Studiums der Berufspflege\n",
      "    (FuBer) der Hochschule Konstanz hervorgeht.\n",
      "3.  Eine Bescheinigung Ã¼ber den Abschluss eines grundstÃ¤ndigen Hochschulstudiums,\n",
      "    dessen PrÃ¼fungsmodulhandbuch oder Studienplan das Packages â€œDeutschâ€ enth\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse an der HTWG akzeptiert werden?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\n",
      "\n",
      "# You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter: Hochschule Konstanz \n",
      "Technik, Wirtschaft und Gestaltung \n",
      " \n",
      " \n",
      "Seite 30 von 43 \n",
      "(3) Kriterien fÃ¼r die Auswahl der Bewerber und Bewerberinnen zu dem \n",
      "AuswahlgesprÃ¤ch nach Â§ 9a Abs. 1 \n",
      "Unter den Bewerbern und Bewerberinnen, die die Zugangsvoraussetzungen gemÃ¤ÃŸ Abs. 1 \n",
      "erfÃ¼llen, findet zur Begrenzung der Teilnehmerzahl an den AuswahlgesprÃ¤chen eine \n",
      "Vorauswahl nach einer Rangliste statt. Diese Rangliste wird anhand der Teilnote 2 erstellt. Die \n",
      "Zahl der einzuladenden rangbesten Bewerber und Bewerberinnen betrÃ¤gt das Dreifache der \n",
      "zur VerfÃ¼gung stehenden StudienplÃ¤tze im Masterstudiengang Legal Management. \n",
      "(4) Erstellung einer Rangliste fÃ¼r die Auswahlentscheidung nach Â§ 10 \n",
      "FÃ¼r die Auswahlentscheidung wird unter den Bewerbern und Bewerberinnen, die am \n",
      "Aus\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was sind Zulassungsvorraussetzungen fÃ¼r den Master Informatik?\n",
      "Zugangsvoraussetzung ist ein mit der Note 2,9 oder besser abgeschlossenes grundstÃ¤ndiges Hochschulstudium gemÃ¤ÃŸ Â§ 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtung Informatik oder einer verwandten Fachrichtung (fÃ¼r den Studiengang MSI) bzw. eine um die Fachrichtung Wirtschaftsmanagement erweiterte Ausbildung (fÃ¼r den Studiengang MIM). Bewerber*innen aus einem nicht deutschen Studiensystem mÃ¼ssen ihre Qualifikation Ã¼berdecken, dass eine Mindestzahl von 20 ECTS-Punkten im Bereich Informatik/ IT-Management studiert wurde. Die Zulassung zum Masterstudiengang erfolgt nach dem Ergebnis des hochschuleigenen Auswahlverfahrens gemÃ¤ÃŸ Â§ 6.\n",
      "Wie lautet die Auswahlkriterien fÃ¼r das hochschuleigene Auswahlverfahren?\n",
      "Das hochschulinterne Auswahlverfahren fÃ¼r den Masterstudiengang MSI / MIM erstreckt sich Ã¼ber zwei Rundungen; in jeder Rundung werden die Bewerber*innen auf Grund der erbrachten Leistungen anhand einer Rangliste gewÃ¤hlt. FÃ¼r jede\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Was sind Zulassungsvorraussetzungen fÃ¼r den Master Informatik?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the documents of the HTWG Konstanz: \n",
      "Was sind Zulassungsvorraussetzungen fÃ¼r den Master Informatik? #Zulassung \t\n",
      "Sie finden Sie unter folgender Link: https://www.htwg-konstanz.de/studium/master/informatik/zugangsvoraussetzungen/. \t\n",
      "Welche Studienrichtungen kann ich im Masterstudiengang Informatik wÃ¤hlen? #Studienrichtungen \t\n",
      "Sie kÃ¶nnen zwischen den drei Studienrichtungen Autonome Systeme, IT-Management und Software Engineering wÃ¤hlen. \t\n",
      "#AutonomeSysteme \t\n",
      "#ITManagement \t\n",
      "#SoftwareEngineering \t\n",
      "Wie lange dauert der Masterstudiengang Informatik? #Masterstudiengang \t\n",
      "Der Masterstudiengang Informatik ist ein berufsbegleitender Studiengang und dauert drei Semester (90 ECTS). \t\n",
      "Wie hoch ist das Studiumsvolumen? #Studiumsvolumen \t\n",
      "Das Studiumsvolumen betrÃ¤gt 25 Vorlesungsunterlagen/Semester Ã— 3 Semester = 75 Vorlesungsunterlagen. \t\n",
      "In welchem Fachsemester ist der Arbeitsgemeinschaftszeitaufwand von 100 Stunden zu erfÃ¼llen? #AG \t\n",
      "Der Arbeitsgemeinschaftszeitaufwand von 100 Stunden ist im Fachsemester zu erbringen, in dem der Nachweis Ã¼ber \t\n",
      "die Erstellung eines Masterarbeitsplans gefordert wird. \t\n",
      "Wann ist der Antrag auf Zulassung zum Masterstudiengang Informatik zu stellen? #Zulassungsspezifisch \t\n",
      "FÃ¼r das Wintersemester: Bis 1. Juni des jeweiligen Jahres. FÃ¼r das Sommersemester: Bis 1. Dezember des \t\n",
      "jeweiligen Jahres.  \n",
      "Bedeutet der/r Bewerber/in die ZulassungssprachprÃ¼fung nicht erfolgreich abgeschlossen hat, sondern \t\n",
      "sprachliche Kompetenzen durch regionales Lern- und Lebenshintergrundprofil nachgewiesen\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "eval_prompt = \"You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the documents of the HTWG Konstanz: \\nWas sind Zulassungsvorraussetzungen fÃ¼r den Master Informatik? #\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
