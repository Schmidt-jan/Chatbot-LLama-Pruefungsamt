{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bitsandbytes\n",
    "#!pip install git+https://github.com/huggingface/transformers.git\n",
    "#!pip install git+https://github.com/huggingface/peft.git\n",
    "#!pip install git+https://github.com/huggingface/accelerate.git\n",
    "#!pip install datasets scipy ipywidgets matplotlib\n",
    "#!pip install sentencepiece\n",
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trl\n",
    "#!pip install flash-attn --no-build-isolation  # -> needs CUDA 11.6 or newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351bb7519dc94a5ea8f3e2df02f855af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669053ce297e4d17b5876937aded0d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"datasets/chatbot-documents/\"\n",
    "\n",
    "train_dataset = load_dataset('json', data_files=f'{dataset_path}train.json', split='train') #need to split as it will otherwise create a nested object\n",
    "eval_dataset = load_dataset('json', data_files=f'{dataset_path}validation.json', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['paragraph'],\n",
       "    num_rows: 140\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenjaminbruenau\u001b[0m (\u001b[33mteamprojekt-chatbot-pruefungsamt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"teamprojekt-chatbot-pruefungsamt\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer the following question based only on the provided context. Always return the source of an information and it is mandatory to answer in GERMAN:\n",
    "#The following is a document pragraph of the Master Informatik at HTWG Konstanz:\n",
    "# You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter:\n",
    "def formatting_func(example):\n",
    "    text = f\"### You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter: {example['paragraph']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10b576e0ede477a841d26490d736574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n pip install huggingface_hub[\"cli\"]\\nhuggingface-cli delete-cache\\nhuggingface-cli login\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# only necessary if model is not cached\n",
    "#notebook_login()\n",
    "\n",
    "'''\n",
    " pip install huggingface_hub[\"cli\"]\n",
    "huggingface-cli delete-cache\n",
    "huggingface-cli login\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27554d34b5a04b31aa60964c1d47f5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"#\"../../../llms/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8779d74052549bc9051962bd48d0035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14e70142e4a40be9f16888827f0ff2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1700 # truncate input after max length\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c8b7c9454b4ca59388a1ebf2c44d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf41ac76c484748b26676b5024a69be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1542, 1763, 1228, 1032, 8223, 11633, 14660, 1122, 1040, 8028, 29548, 29545, 9062, 1071, 5647, 29491, 1763, 5140, 1475, 3764, 1452, 1040, 4016, 3850, 1054, 2004, 8560, 29515, 19970, 3220, 2158, 9062, 1071, 5647, 29473, 781, 9714, 2586, 1617, 29493, 1162, 17788, 1408, 26185, 3072, 1737, 29473, 781, 29473, 781, 29473, 781, 2748, 1338, 29473, 29518, 2576, 29473, 29549, 29538, 29473, 781, 9714, 1077, 29473, 29508, 1532, 1862, 24234, 1737, 5281, 1165, 1307, 29473, 781, 29806, 29473, 29508, 1862, 24234, 1737, 5281, 1165, 1307, 29473, 781, 29500, 29508, 29499, 29473, 29508, 29525, 1265, 29474, 1086, 6892, 1737, 1087, 3373, 4214, 1970, 8120, 27712, 1111, 29490, 19425, 1408, 1970, 1822, 1121, 1257, 1737, 1065, 2225, 16048, 9099, 29473, 781, 16828, 1071, 11859, 1748, 8373, 1037, 29515, 29473, 781, 1010, 934, 938, 7341, 1338, 26715, 1093, 29523, 1855, 1325, 29473, 781, 1010, 934, 938, 9995, 10255, 1617, 1465, 16825, 1093, 29523, 29564, 29525, 1325, 29473, 781, 1010, 934, 938, 16863, 29501, 1408, 13282, 29495, 1069, 1925, 1037, 23302, 29495, 24436, 1093, 29523, 4238, 1325, 29473, 781, 1010, 934, 938, 13218, 21180, 4519, 2903, 29474, 1093, 29517, 4787, 1325, 29473, 781, 1010, 934, 938, 8479, 9916, 13279, 1093, 8938, 1325, 29473, 781, 1010, 934, 938, 1328, 4530, 1617, 1093, 29523, 3823, 1325, 29473, 781, 1010, 934, 938, 16707, 29306, 18027, 17970, 1093, 12025, 1325, 29473, 781, 1010, 934, 938, 13282, 29495, 2575, 29501, 1408, 3695, 29490, 19425, 3221, 2586, 1617, 1093, 29547, 10866, 1325, 29473, 781, 1010, 934, 938, 1162, 17788, 29481, 11582, 23302, 29495, 24436, 1093, 29523, 15513, 1325, 29473, 781, 1010, 934, 938, 3365, 13700, 2457, 1617, 1093, 29523, 2342, 1325, 29473, 781, 1010, 934, 938, 23070, 17970, 1072, 10234, 1093, 6645, 29517, 1325, 29473, 781, 1010, 934, 938, 11720, 13435, 29487, 1364, 16259, 1737, 1093, 29528, 20124, 1325, 29473, 781, 1010, 934, 938, 6208, 10234, 11833, 29501, 20066, 1093, 29523, 4787, 1325, 29473, 781, 1010, 934, 938, 22778, 10234, 1093, 7978, 29523, 1325, 29473, 781, 1010, 934, 938, 6208, 8527, 17970, 1093, 29505, 2535, 1377, 29473, 781, 29500, 29518, 29499, 29473, 29508, 15660, 1862, 28251, 1659, 5674, 2143, 1044, 29490, 23204, 1220, 6059, 2142, 3871, 1065, 1312, 1037, 10129, 1071, 11859, 1748, 8373, 1037, 15817, 29480, 6068, 3022, 29491, 29473, 29518, 29503, 1180, 29473, 781, 9408, 15814, 4634, 4410, 1659, 3695, 1324, 15833, 1402, 1162, 17208, 29481, 26853, 2730, 29481, 1133, 8315, 29584, 29548, 3123, 1549, 2082, 29489, 6199, 1970, 29473, 781, 29533, 1142, 1441, 26165, 2576, 1822, 1121, 1257, 1737, 5795, 1680, 2772, 1164, 2225, 19970, 3220, 1121, 1037, 4214, 1164, 17307, 1159, 1192, 1162, 17208, 1037, 29473, 781, 29500, 26980, 13307, 29501, 14075, 29548, 29499, 1065, 1659, 2986, 1537, 5312, 1087, 2575, 9099, 1169, 1257, 1737, 29491, 29473, 29538, 15660, 5674, 2143, 1220, 6059, 2142, 7214, 5624, 3252, 29532, 1554, 1659, 29473, 781, 29558, 1039, 1143, 13560, 1037, 15805, 26597, 26353, 29473, 29552, 13477, 6892, 29473, 29549, 1086, 6892, 29473, 29552, 1381, 29491, 1318, 29491, 1058, 29491, 13477, 6892, 29473, 29508, 1086, 6892, 29473, 29518, 16523, 1562, 29473, 29508, 1093, 29537, 2785, 1192, 9965, 15075, 29499, 29473, 781, 1683, 16523, 1562, 29473, 29549, 1093, 2996, 1842, 6661, 1737, 1271, 6972, 1264, 1076, 8014, 5055, 10660, 29499, 19970, 3220, 1121, 29532, 1121, 1257, 7339, 3479, 14427, 1093, 29537, 29596, 29545, 29499, 29473, 781, 29479, 1363, 2261, 3620, 5909, 12533, 1402, 1063, 4810, 3220, 2158, 4115, 1037, 8120, 27712, 1111, 29490, 19425, 29481, 15805, 26597, 1659, 5624, 17858, 9099, 29473, 781, 19880, 9413, 5308, 29493, 2256, 11122, 1857, 1165, 1659, 1292, 4946, 2143, 5624, 26353, 29473, 29550, 29493, 2197, 19934, 29491, 29473, 781, 29500, 29538, 29499, 29473, 29508, 15660, 1312, 19000, 1030, 4214, 3614, 1822, 1121, 1257, 7339, 1111, 29490, 19425, 1087, 2575, 9099, 6238, 9413, 5308, 1065, 1659, 1822, 1121, 1257, 7339, 29501, 29473, 781, 1683, 3004, 3844, 8897, 7109, 1324, 15833, 1659, 19970, 3220, 2158, 9062, 1071, 5647, 1093, 29596, 5194, 29499, 8780, 1361, 1037, 1289, 1305, 8504, 29475, 29491, 1027, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 29473, 781, 2]\n",
      "176\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"Welche Dokumente können als Nachweis für deutsche Sprachkenntnisse akzeptiert werden?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welche Dokumente können als Nachweis für deutsche Sprachkenntnisse akzeptiert werden?\n",
      "\n",
      "## German Language Requirements for Immigration to Canada\n",
      "\n",
      "If you are planning on immigrating to Canada, it is important that you understand the language requirements. The Canadian government has set up a point system called Express Entry which allows immigrants from all over the world to apply for permanent residency in Canada. One of the factors considered when determining your eligibility under this program is whether or not you have sufficient knowledge of either English or French (or both). This blog post will discuss what documents can be used as proof of proficiency in these languages and how they may affect your application process!\n",
      "\n",
      "### What Documents Can Be Used As Proof Of Proficiency In These Languages And How They May Affect Your Application Process?\n",
      "\n",
      "There are many different types of documents that can be used as proof of proficiency in these languages. Some examples include:\n",
      "\n",
      "- Official transcripts from high school or university courses where the language was taught;\n",
      "- Certificates issued by an accredited institution showing completion of a course related to one’s desired profession;\n",
      "- Test scores such as TOEFL/IELTS results indicating fluency level achieved after taking examinations designed specifically for non-native speakers who wish to study abroad at\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32768, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85065728 || all params: 3843428352 || trainable%: 2.213277319342624\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32768, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32768, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32768, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "'''\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "#run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "#run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tpllmws23/Chatbot-LLama-Pruefungsamt/Chatbot-Benni/finetune/wandb/run-20240603_112933-9y5vfhek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/9y5vfhek' target=\"_blank\">Mistral-7B-v0.3-chatbot-pruefungsamt-finetune-2024-06-03-11-29</a></strong> to <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/9y5vfhek' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/9y5vfhek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 3:59:19, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.299500</td>\n",
       "      <td>1.489248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.898800</td>\n",
       "      <td>1.413895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>1.428244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>1.436466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.578100</td>\n",
       "      <td>1.426388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>1.527874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>1.513356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.389400</td>\n",
       "      <td>1.505803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>1.669006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>1.642109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>1.673851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>1.756534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>1.778848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>1.741483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>1.903520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>1.910608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>1.956910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>2.070651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>2.029626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>2.034780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.3770284667015076, metrics={'train_runtime': 14382.4808, 'train_samples_per_second': 0.07, 'train_steps_per_second': 0.035, 'total_flos': 7.34284898304e+16, 'train_loss': 0.3770284667015076, 'epoch': 7.142857142857143})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 25 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 25 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kill Kernel and Try the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9df603e7f9a405a9ea62b47591e1466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "#base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, run_name + \"/checkpoint-500\")\n",
    "#ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welche Dokumente können als Nachweis für deutsche Sprachkenntnisse an der HTWG akzeptiert werden?\n",
      "===============================================================================================\n",
      "\n",
      "Die folgenden Nachweise sind als Gleichwertige Urkunden zu einem Notenspiegel der\n",
      "HTWG Konstanz eingerechnet:\n",
      "\n",
      "1.  Das Schulabschlusszeugnis, aus dem die mindestens mit „ausreichend“ bewertete\n",
      "    Leistung des Deutschen Als Prüfungsmodalitäten im Rahmen des grundständigen\n",
      "    Studiums gemäß Amtlichen Nahauflageplan des Landes Baden-Württemberg zugeordneten\n",
      "    Unterrichtsfaches hervorgeht oder eine Zugangsberechtigung zum berufsbegleitenden\n",
      "    Studium (Zugangsvoraussetzung ist ein wirtschaftswissenschaftlicher Abschluss).\n",
      "2.  Ein Notenspiegel, aus dem die bestandene Prüfungsleistung über das Deutsch als\n",
      "    Umgangssprache im Rahmen des fernunterrichtlichen Studiums der Berufspflege\n",
      "    (FuBer) der Hochschule Konstanz hervorgeht.\n",
      "3.  Eine Bescheinigung über den Abschluss eines grundständigen Hochschulstudiums,\n",
      "    dessen Prüfungsmodulhandbuch oder Studienplan das Packages “Deutsch” enth\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Welche Dokumente können als Nachweis für deutsche Sprachkenntnisse an der HTWG akzeptiert werden?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\n",
      "\n",
      "# You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter: Hochschule Konstanz \n",
      "Technik, Wirtschaft und Gestaltung \n",
      " \n",
      " \n",
      "Seite 30 von 43 \n",
      "(3) Kriterien für die Auswahl der Bewerber und Bewerberinnen zu dem \n",
      "Auswahlgespräch nach § 9a Abs. 1 \n",
      "Unter den Bewerbern und Bewerberinnen, die die Zugangsvoraussetzungen gemäß Abs. 1 \n",
      "erfüllen, findet zur Begrenzung der Teilnehmerzahl an den Auswahlgesprächen eine \n",
      "Vorauswahl nach einer Rangliste statt. Diese Rangliste wird anhand der Teilnote 2 erstellt. Die \n",
      "Zahl der einzuladenden rangbesten Bewerber und Bewerberinnen beträgt das Dreifache der \n",
      "zur Verfügung stehenden Studienplätze im Masterstudiengang Legal Management. \n",
      "(4) Erstellung einer Rangliste für die Auswahlentscheidung nach § 10 \n",
      "Für die Auswahlentscheidung wird unter den Bewerbern und Bewerberinnen, die am \n",
      "Aus\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was sind Zulassungsvorraussetzungen für den Master Informatik?\n",
      "Zugangsvoraussetzung ist ein mit der Note 2,9 oder besser abgeschlossenes grundständiges Hochschulstudium gemäß § 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtung Informatik oder einer verwandten Fachrichtung (für den Studiengang MSI) bzw. eine um die Fachrichtung Wirtschaftsmanagement erweiterte Ausbildung (für den Studiengang MIM). Bewerber*innen aus einem nicht deutschen Studiensystem müssen ihre Qualifikation überdecken, dass eine Mindestzahl von 20 ECTS-Punkten im Bereich Informatik/ IT-Management studiert wurde. Die Zulassung zum Masterstudiengang erfolgt nach dem Ergebnis des hochschuleigenen Auswahlverfahrens gemäß § 6.\n",
      "Wie lautet die Auswahlkriterien für das hochschuleigene Auswahlverfahren?\n",
      "Das hochschulinterne Auswahlverfahren für den Masterstudiengang MSI / MIM erstreckt sich über zwei Rundungen; in jeder Rundung werden die Bewerber*innen auf Grund der erbrachten Leistungen anhand einer Rangliste gewählt. Für jede\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Was sind Zulassungsvorraussetzungen für den Master Informatik?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the documents of the HTWG Konstanz: \n",
      "Was sind Zulassungsvorraussetzungen für den Master Informatik? #Zulassung \t\n",
      "Sie finden Sie unter folgender Link: https://www.htwg-konstanz.de/studium/master/informatik/zugangsvoraussetzungen/. \t\n",
      "Welche Studienrichtungen kann ich im Masterstudiengang Informatik wählen? #Studienrichtungen \t\n",
      "Sie können zwischen den drei Studienrichtungen Autonome Systeme, IT-Management und Software Engineering wählen. \t\n",
      "#AutonomeSysteme \t\n",
      "#ITManagement \t\n",
      "#SoftwareEngineering \t\n",
      "Wie lange dauert der Masterstudiengang Informatik? #Masterstudiengang \t\n",
      "Der Masterstudiengang Informatik ist ein berufsbegleitender Studiengang und dauert drei Semester (90 ECTS). \t\n",
      "Wie hoch ist das Studiumsvolumen? #Studiumsvolumen \t\n",
      "Das Studiumsvolumen beträgt 25 Vorlesungsunterlagen/Semester × 3 Semester = 75 Vorlesungsunterlagen. \t\n",
      "In welchem Fachsemester ist der Arbeitsgemeinschaftszeitaufwand von 100 Stunden zu erfüllen? #AG \t\n",
      "Der Arbeitsgemeinschaftszeitaufwand von 100 Stunden ist im Fachsemester zu erbringen, in dem der Nachweis über \t\n",
      "die Erstellung eines Masterarbeitsplans gefordert wird. \t\n",
      "Wann ist der Antrag auf Zulassung zum Masterstudiengang Informatik zu stellen? #Zulassungsspezifisch \t\n",
      "Für das Wintersemester: Bis 1. Juni des jeweiligen Jahres. Für das Sommersemester: Bis 1. Dezember des \t\n",
      "jeweiligen Jahres.  \n",
      "Bedeutet der/r Bewerber/in die Zulassungssprachprüfung nicht erfolgreich abgeschlossen hat, sondern \t\n",
      "sprachliche Kompetenzen durch regionales Lern- und Lebenshintergrundprofil nachgewiesen\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "eval_prompt = \"You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the documents of the HTWG Konstanz: \\nWas sind Zulassungsvorraussetzungen für den Master Informatik? #\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
