{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bitsandbytes\n",
    "#!pip install git+https://github.com/huggingface/transformers.git\n",
    "#!pip install git+https://github.com/huggingface/peft.git\n",
    "#!pip install git+https://github.com/huggingface/accelerate.git\n",
    "#!pip install datasets scipy ipywidgets matplotlib\n",
    "#!pip install sentencepiece\n",
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trl\n",
    "#!pip install flash-attn --no-build-isolation  # -> needs CUDA 11.6 or newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"datasets/chatbot-qac-pairs/\"\n",
    "\n",
    "train_dataset = load_dataset('json', data_files=f'{dataset_path}train.json', split='train') #need to split as it will otherwise create a nested object\n",
    "eval_dataset = load_dataset('json', data_files=f'{dataset_path}validation.json', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'context'],\n",
       "    num_rows: 192\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenjaminbruenau\u001b[0m (\u001b[33mteamprojekt-chatbot-pruefungsamt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"teamprojekt-chatbot-pruefungsamt\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer the following question based only on the provided context. Always return the source of an information and it is mandatory to answer in GERMAN:\n",
    "#The following is a document pragraph of the Master Informatik at HTWG Konstanz:\n",
    "# You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter:\n",
    "def formatting_func(example):\n",
    "    #text = f\"### You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter: {example['paragraph']}\"\n",
    "    text = f\"### Question: {example['question']}\\n ### Context: {example['context']}\\n ### Answer: {example['answer']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10b576e0ede477a841d26490d736574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n pip install huggingface_hub[\"cli\"]\\nhuggingface-cli delete-cache\\nhuggingface-cli login\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# only necessary if model is not cached\n",
    "#notebook_login()\n",
    "\n",
    "'''\n",
    " pip install huggingface_hub[\"cli\"]\n",
    "huggingface-cli delete-cache\n",
    "huggingface-cli login\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb19239f71d4bf1af60a14764476a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"#\"../../../llms/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7219777b4164143b555faf6ac9568f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ccbd6f3c5e4bd69755d897b39d926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDt0lEQVR4nO3deVxV1f7/8fdRRkFAFAEnNMVZzNSMK5UDRmqmaTlcK+XqtUFz7nZtUkujrJwa1CbNyiwtLSs1Z29eNTXNtERxHhi8lQymgLB+f/jjfPcRVEDkAL6ej8d53M7a6+z92Wcd6rzv2nsdmzHGCAAAAAAgSSrn7AIAAAAAoCQhJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkASjTJkyYIJvNVizHateundq1a2d/vn79etlsNi1evLhYjj9w4EDVrl27WI5VWGlpaRo8eLCCgoJks9k0cuRIZ5dU5Ip73K9mxYoVuvnmm+Xh4SGbzaYzZ87k2W/evHmy2Ww6cuRIsdZ3PRTkXGrXrq2BAwde95oAlC6EJAClRs4Xn5yHh4eHqlWrpqioKM2cOVOpqalFcpxTp05pwoQJ2rVrV5HsryiV5Nry46WXXtK8efP02GOP6aOPPtJDDz102b61a9fWPffcU4zVFcyCBQs0ffp0Z5dxRb///rt69+4tT09PvfXWW/roo4/k5eXl7LLy5ddff9WECRPKRGgDUPq4OLsAACioF154QXXq1FFmZqYSEhK0fv16jRw5UlOnTtXXX3+tsLAwe99nn31W//73vwu0/1OnTmnixImqXbu2br755ny/7vvvvy/QcQrjSrW9++67ys7Ovu41XIu1a9fqtttu0/jx451dyjVbsGCB9uzZU6Jnw7Zt26bU1FS9+OKLioyMvGLfhx56SH379pW7u3sxVXdlv/76qyZOnKh27doVeIa0pJ0LgNKHkASg1OncubNatWplfz5u3DitXbtW99xzj+6991799ttv8vT0lCS5uLjIxeX6/qvur7/+UoUKFeTm5nZdj3M1rq6uTj1+fiQlJalx48bOLuOGkZSUJEny8/O7at/y5curfPny17mi4lGWzgWAc3C5HYAyoUOHDnruued09OhRffzxx/b2vO5JWrVqlSIiIuTn5ydvb281aNBATz/9tKSL95O0bt1akhQdHW2/tG/evHmSLt531LRpU+3YsUN33HGHKlSoYH/tpfck5cjKytLTTz+toKAgeXl56d5779Xx48cd+lzuvgjrPq9WW173JJ09e1ZjxoxRzZo15e7urgYNGui1116TMcahn81m07Bhw7R06VI1bdpU7u7uatKkiVasWJH3G36JpKQkDRo0SIGBgfLw8FDz5s314Ycf2rfn3Kdz+PBhffvtt/bai+JSqo8//lgtW7aUp6en/P391bdv31zvb864/frrr2rfvr0qVKig6tWra8qUKbn2d/ToUd17773y8vJS1apVNWrUKK1cuVI2m03r16+37+/bb7/V0aNH7edy6XufnZ2tyZMnq0aNGvLw8FDHjh0VFxfn0OfAgQPq1auXgoKC5OHhoRo1aqhv375KTk6+6nkvWrTIft5VqlTRgw8+qJMnTzqc84ABAyRJrVu3ls1mu+K9N3ndx5NzyeMPP/ygW2+9VR4eHrrppps0f/78PF+7ceNGPfLII6pcubJ8fHz08MMP688//3Toa7PZNGHChFzHt/4NzJs3Tw888IAkqX379vb3OOf9v5q8zsUYo0mTJqlGjRqqUKGC2rdvr7179+Z6bWZmpiZOnKjQ0FB5eHiocuXKioiI0KpVq/J1bABlAzNJAMqMhx56SE8//bS+//57/fOf/8yzz969e3XPPfcoLCxML7zwgtzd3RUXF6dNmzZJkho1aqQXXnhBzz//vIYMGaLbb79dkvS3v/3Nvo/ff/9dnTt3Vt++ffXggw8qMDDwinVNnjxZNptNTz31lJKSkjR9+nRFRkZq165d9hmv/MhPbVbGGN17771at26dBg0apJtvvlkrV67Uk08+qZMnT2ratGkO/X/44Qd9+eWXevzxx1WxYkXNnDlTvXr10rFjx1S5cuXL1nXu3Dm1a9dOcXFxGjZsmOrUqaNFixZp4MCBOnPmjEaMGKFGjRrpo48+0qhRo1SjRg2NGTNGkhQQEJDv88/L5MmT9dxzz6l3794aPHiwTp8+rTfeeEN33HGHdu7c6TCD8ueff+ruu+9Wz5491bt3by1evFhPPfWUmjVrps6dO0u6GCo7dOig+Ph4jRgxQkFBQVqwYIHWrVvncNxnnnlGycnJOnHihP199Pb2dujz8ssvq1y5cho7dqySk5M1ZcoU9e/fX1u3bpUkZWRkKCoqSunp6XriiScUFBSkkydP6ptvvtGZM2fk6+t72fOeN2+eoqOj1bp1a8XExCgxMVEzZszQpk2b7Of9zDPPqEGDBnrnnXfsl6jWrVu3wO9xXFyc7r//fg0aNEgDBgzQBx98oIEDB6ply5Zq0qSJQ99hw4bJz89PEyZMUGxsrGbNmqWjR4/aQ3J+3XHHHRo+fLhmzpypp59+Wo0aNZIk+/8WxvPPP69JkyapS5cu6tKli3766SfdddddysjIcOg3YcIExcTEaPDgwbr11luVkpKi7du366efflKnTp0KfXwApYwBgFJi7ty5RpLZtm3bZfv4+vqaFi1a2J+PHz/eWP9VN23aNCPJnD59+rL72LZtm5Fk5s6dm2vbnXfeaSSZ2bNn57ntzjvvtD9ft26dkWSqV69uUlJS7O2ff/65kWRmzJhhbwsJCTEDBgy46j6vVNuAAQNMSEiI/fnSpUuNJDNp0iSHfvfff7+x2WwmLi7O3ibJuLm5ObT9/PPPRpJ54403ch3Lavr06UaS+fjjj+1tGRkZJjw83Hh7ezuce0hIiOnatesV95ffvkeOHDHly5c3kydPdmj/5ZdfjIuLi0N7zrjNnz/f3paenm6CgoJMr1697G2vv/66kWSWLl1qbzt37pxp2LChkWTWrVtnb+/atavD+50jZ9wbNWpk0tPT7e0zZswwkswvv/xijDFm586dRpJZtGjR1d8Mi4yMDFO1alXTtGlTc+7cOXv7N998YySZ559/3t6Wn7+ZS/sePnzY3hYSEmIkmY0bN9rbkpKSjLu7uxkzZkyu17Zs2dJkZGTY26dMmWIkma+++sreJsmMHz8+1/Ev/RtYtGhRrvc8vy49l6SkJOPm5ma6du1qsrOz7f2efvppI8nhuM2bN8/3ZxRA2cXldgDKFG9v7yuucpczs/DVV18VepEDd3d3RUdH57v/ww8/rIoVK9qf33///QoODtZ3331XqOPn13fffafy5ctr+PDhDu1jxoyRMUbLly93aI+MjHSYaQgLC5OPj48OHTp01eMEBQWpX79+9jZXV1cNHz5caWlp2rBhQxGcTW5ffvmlsrOz1bt3b/3vf/+zP4KCghQaGppr9sfb21sPPvig/bmbm5tuvfVWh/NbsWKFqlevrnvvvdfe5uHhcdmZySuJjo52uE8tZ+Yv53g5M0UrV67UX3/9le/9bt++XUlJSXr88cfl4eFhb+/atasaNmyob7/9tsC1Xknjxo3ttUsXZ/8aNGiQ5+diyJAhDvfGPfbYY3Jxcbnun/WrWb16tTIyMvTEE084zGjlteiGn5+f9u7dqwMHDhRjhQBKGkISgDIlLS3NIZBcqk+fPmrbtq0GDx6swMBA9e3bV59//nmBAlP16tULtEhDaGiow3ObzaZ69epd96WNjx49qmrVquV6P3IuWTp69KhDe61atXLto1KlSrnuKcnrOKGhoSpXzvE/KZc7TlE5cOCAjDEKDQ1VQECAw+O3336zL1qQo0aNGrku+br0/I4ePaq6devm6levXr0C13fp+1mpUiVJsh+vTp06Gj16tN577z1VqVJFUVFReuutt656P1LO+9mgQYNc2xo2bFjk73dBPheXfta9vb0VHBzs9GW8c96TS+sLCAiwj0uOF154QWfOnFH9+vXVrFkzPfnkk9q9e3ex1QqgZCAkASgzTpw4oeTk5Ct+ofX09NTGjRu1evVqPfTQQ9q9e7f69OmjTp06KSsrK1/HKch9RPl1ufs18ltTUbjcamDmkkUeSors7GzZbDatWLFCq1atyvWYM2eOQ//iPr/8HO/111/X7t279fTTT+vcuXMaPny4mjRpohMnTlyXmgqjuN634vysX8kdd9yhgwcP6oMPPlDTpk313nvv6ZZbbtF7773n7NIAFCNCEoAy46OPPpIkRUVFXbFfuXLl1LFjR02dOlW//vqrJk+erLVr19ovzyrIDeb5cellO8YYxcXFOayGVqlSJZ05cybXay+dFShIbSEhITp16lSuyw/37dtn314UQkJCdODAgVyzcUV9nEvVrVtXxhjVqVNHkZGRuR633XZbgfcZEhKigwcP5goAl65KJxXd56RZs2Z69tlntXHjRv3nP//RyZMnNXv27CvWKEmxsbG5tsXGxl639zs/Lv2sp6WlKT4+/qqf9YyMDMXHxzu0FeXfYc57cml9p0+fznNGzN/fX9HR0fr00091/PhxhYWF5bkiH4Cyi5AEoExYu3atXnzxRdWpU0f9+/e/bL8//vgjV1vOj7Kmp6dLkry8vCQpz9BSGPPnz3cIKosXL1Z8fLx9RTXp4hf+LVu2OKy09c033+RayrogtXXp0kVZWVl68803HdqnTZsmm83mcPxr0aVLFyUkJOizzz6zt124cEFvvPGGvL29deeddxbJcS7Vs2dPlS9fXhMnTswVaowx+v333wu8z6ioKJ08eVJff/21ve38+fN69913c/X18vLK11Ldl5OSkqILFy44tDVr1kzlypWzfxbz0qpVK1WtWlWzZ8926Ld8+XL99ttv6tq1a6FrulbvvPOOMjMz7c9nzZqlCxcu5Pqsb9y4MdfrLp1JKsq/w8jISLm6uuqNN95w+KxMnz49V99LPzfe3t6qV6/eFccEQNnDEuAASp3ly5dr3759unDhghITE7V27VqtWrVKISEh+vrrrx1uZr/UCy+8oI0bN6pr164KCQlRUlKS3n77bdWoUUMRERGSLn6J8/Pz0+zZs1WxYkV5eXmpTZs2qlOnTqHq9ff3V0REhKKjo5WYmKjp06erXr16DosBDB48WIsXL9bdd9+t3r176+DBg/r4449zLdlckNq6deum9u3b65lnntGRI0fUvHlzff/99/rqq680cuTIQi0HnZchQ4Zozpw5GjhwoHbs2KHatWtr8eLF2rRpk6ZPn37Fe8SuJi4uTpMmTcrV3qJFC3Xt2lWTJk3SuHHjdOTIEfXo0UMVK1bU4cOHtWTJEg0ZMkRjx44t0PEeeeQRvfnmm+rXr59GjBih4OBgffLJJ/bPlHV2o2XLlvrss880evRotW7dWt7e3urWrVu+j7V27VoNGzZMDzzwgOrXr68LFy7oo48+Uvny5dWrV6/Lvs7V1VWvvPKKoqOjdeedd6pfv372JcBr166tUaNGFeici1JGRoY6duyo3r17KzY2Vm+//bYiIiIcFsIYPHiwHn30UfXq1UudOnXSzz//rJUrV6pKlSoO+7r55ptVvnx5vfLKK0pOTpa7u7s6dOigqlWrFriugIAAjR07VjExMbrnnnvUpUsX7dy5U8uXL8913MaNG6tdu3Zq2bKl/P39tX37di1evFjDhg0r3JsCoHRyzqJ6AFBwOcv65jzc3NxMUFCQ6dSpk5kxY4bDUtM5Ll0CfM2aNaZ79+6mWrVqxs3NzVSrVs3069fP7N+/3+F1X331lWncuLFxcXFxWHL7zjvvNE2aNMmzvsstAf7pp5+acePGmapVqxpPT0/TtWtXc/To0Vyvf/3110316tWNu7u7adu2rdm+fXuufV6ptkuXADfGmNTUVDNq1ChTrVo14+rqakJDQ82rr77qsAyyMReXZR46dGiumi63NPmlEhMTTXR0tKlSpYpxc3MzzZo1y3OZ8oIuAW4db+tj0KBB9n5ffPGFiYiIMF5eXsbLy8s0bNjQDB061MTGxtr7XG7c8nrPDh06ZLp27Wo8PT1NQECAGTNmjPniiy+MJLNlyxZ7v7S0NPP3v//d+Pn5GUn2/eSM+6VLex8+fNhhvA4dOmT+8Y9/mLp16xoPDw/j7+9v2rdvb1avXp2v9+ezzz4zLVq0MO7u7sbf39/079/fnDhxwqFPUSwBntd4Xfq5zHnthg0bzJAhQ0ylSpWMt7e36d+/v/n9998dXpuVlWWeeuopU6VKFVOhQgUTFRVl4uLi8vysvfvuu+amm24y5cuXL9By4HmdS1ZWlpk4caIJDg42np6epl27dmbPnj25jjtp0iRz6623Gj8/P+Pp6WkaNmxoJk+e7LC0OYCyz2ZMCb0jFwCAEmL69OkaNWqUTpw4oerVqzu7nBIn58dtt23bplatWjm7HAC4ZtyTBACAxblz5xyenz9/XnPmzFFoaCgBCQBuENyTBACARc+ePVWrVi3dfPPNSk5O1scff6x9+/bpk08+cXZpN7y0tDSlpaVdsU9AQMBlly0HgPwiJAEAYBEVFaX33ntPn3zyibKystS4cWMtXLhQffr0cXZpN7zXXntNEydOvGKfw4cPOyw5DgCFwT1JAACgVDh06JAOHTp0xT4RERFXXOESAPKDkAQAAAAAFizcAAAAAAAWTr0nacKECbmuLW7QoIH27dsn6eKKQmPGjNHChQuVnp6uqKgovf322woMDMz3MbKzs3Xq1ClVrFjR4UcAAQAAANxYjDFKTU1VtWrVVK7c5eeLnL5wQ5MmTbR69Wr7cxeX/ytp1KhR+vbbb7Vo0SL5+vpq2LBh6tmzpzZt2pTv/Z86dUo1a9Ys0poBAAAAlF7Hjx9XjRo1Lrvd6SHJxcVFQUFBudqTk5P1/vvva8GCBerQoYMkae7cuWrUqJG2bNmi2267LV/7r1ixoqSLb4SPj0/RFQ4AAACgVElJSVHNmjXtGeFynB6SDhw4oGrVqsnDw0Ph4eGKiYlRrVq1tGPHDmVmZioyMtLet2HDhqpVq5Y2b9582ZCUnp6u9PR0+/PU1FRJko+PDyEJAAAAwFVvw3Hqwg1t2rTRvHnztGLFCs2aNUuHDx/W7bffrtTUVCUkJMjNzU1+fn4OrwkMDFRCQsJl9xkTEyNfX1/7g0vtAAAAABSEU2eSOnfubP/nsLAwtWnTRiEhIfr888/l6elZqH2OGzdOo0ePtj/PmVIDAAAAgPwoUUuA+/n5qX79+oqLi1NQUJAyMjJ05swZhz6JiYl53sOUw93d3X5pHZfYAQAAACioEhWS0tLSdPDgQQUHB6tly5ZydXXVmjVr7NtjY2N17NgxhYeHO7FKAAAAAGWZUy+3Gzt2rLp166aQkBCdOnVK48ePV/ny5dWvXz/5+vpq0KBBGj16tPz9/eXj46MnnnhC4eHh+V7ZDgAAAAAKyqkh6cSJE+rXr59+//13BQQEKCIiQlu2bFFAQIAkadq0aSpXrpx69erl8GOyAAAAAHC92IwxxtlFXE8pKSny9fVVcnIy9ycBAAAAN7D8ZoMSdU8SAAAAADgbIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALF2cXAOTo1s3ZFfyfZcucXQEAAACchZkkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYFFiQtLLL78sm82mkSNH2tvOnz+voUOHqnLlyvL29lavXr2UmJjovCIBAAAAlHklIiRt27ZNc+bMUVhYmEP7qFGjtGzZMi1atEgbNmzQqVOn1LNnTydVCQAAAOBG4PSQlJaWpv79++vdd99VpUqV7O3Jycl6//33NXXqVHXo0EEtW7bU3Llz9d///ldbtmxxYsUAAAAAyjKnh6ShQ4eqa9euioyMdGjfsWOHMjMzHdobNmyoWrVqafPmzZfdX3p6ulJSUhweAAAAAJBfLs48+MKFC/XTTz9p27ZtubYlJCTIzc1Nfn5+Du2BgYFKSEi47D5jYmI0ceLEoi4VAAAAwA3CaTNJx48f14gRI/TJJ5/Iw8OjyPY7btw4JScn2x/Hjx8vsn0DAAAAKPucFpJ27NihpKQk3XLLLXJxcZGLi4s2bNigmTNnysXFRYGBgcrIyNCZM2ccXpeYmKigoKDL7tfd3V0+Pj4ODwAAAADIL6ddbtexY0f98ssvDm3R0dFq2LChnnrqKdWsWVOurq5as2aNevXqJUmKjY3VsWPHFB4e7oySAQAAANwAnBaSKlasqKZNmzq0eXl5qXLlyvb2QYMGafTo0fL395ePj4+eeOIJhYeH67bbbnNGyQAAAABuAE5duOFqpk2bpnLlyqlXr15KT09XVFSU3n77bWeXBQAAAKAMsxljjLOLuJ5SUlLk6+ur5ORk7k8q4bp1c3YF/2fZMmdXAAAAgKKW32zg9N9JAgAAAICShJAEAAAAABYl+p4kAFyGCAAAUNyYSQIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYMGPyRYzfhgUAAAAKNmYSQIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAwsXZBcB5unVzdgUAAABAycNMEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABYuzi4AKIm6dXN2BQAAAHAWZpIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALJwakmbNmqWwsDD5+PjIx8dH4eHhWr58uX37+fPnNXToUFWuXFne3t7q1auXEhMTnVgxAAAAgLLOqSGpRo0aevnll7Vjxw5t375dHTp0UPfu3bV3715J0qhRo7Rs2TItWrRIGzZs0KlTp9SzZ09nlgwAAACgjLMZY4yzi7Dy9/fXq6++qvvvv18BAQFasGCB7r//fknSvn371KhRI23evFm33XZbvvaXkpIiX19fJScny8fH53qWni/8/g5Ks2XLnF0BAABA4eU3G5SYe5KysrK0cOFCnT17VuHh4dqxY4cyMzMVGRlp79OwYUPVqlVLmzdvvux+0tPTlZKS4vAAAAAAgPxyekj65Zdf5O3tLXd3dz366KNasmSJGjdurISEBLm5ucnPz8+hf2BgoBISEi67v5iYGPn6+tofNWvWvM5nAAAAAKAscXpIatCggXbt2qWtW7fqscce04ABA/Trr78Wen/jxo1TcnKy/XH8+PEirBYAAABAWefi7ALc3NxUr149SVLLli21bds2zZgxQ3369FFGRobOnDnjMJuUmJiooKCgy+7P3d1d7u7u17tsAAAAAGWU02eSLpWdna309HS1bNlSrq6uWrNmjX1bbGysjh07pvDwcCdWCAAAAKAsc+pM0rhx49S5c2fVqlVLqampWrBggdavX6+VK1fK19dXgwYN0ujRo+Xv7y8fHx898cQTCg8Pz/fKdgAAAABQUE4NSUlJSXr44YcVHx8vX19fhYWFaeXKlerUqZMkadq0aSpXrpx69eql9PR0RUVF6e2333ZmyQAAAADKuBL3O0lFjd9JAooOv5MEAABKs1L3O0kAAAAAUBIQkgAAAADAgpAEAAAAABaEJAAAAACwKFRIOnToUFHXAQAAAAAlQqFCUr169dS+fXt9/PHHOn/+fFHXBAAAAABOU6iQ9NNPPyksLEyjR49WUFCQHnnkEf34449FXRsAAAAAFLtChaSbb75ZM2bM0KlTp/TBBx8oPj5eERERatq0qaZOnarTp08XdZ0AAAAAUCyuaeEGFxcX9ezZU4sWLdIrr7yiuLg4jR07VjVr1tTDDz+s+Pj4oqoTAAAAAIrFNYWk7du36/HHH1dwcLCmTp2qsWPH6uDBg1q1apVOnTql7t27F1WdAAAAAFAsXArzoqlTp2ru3LmKjY1Vly5dNH/+fHXp0kXlyl3MXHXq1NG8efNUu3btoqwVAAAAAK67QoWkWbNm6R//+IcGDhyo4ODgPPtUrVpV77///jUVBwAAAADFrVAh6cCBA1ft4+bmpgEDBhRm9wAAAADgNIW6J2nu3LlatGhRrvZFixbpww8/vOaiAAAAAMBZChWSYmJiVKVKlVztVatW1UsvvXTNRQEAAACAsxQqJB07dkx16tTJ1R4SEqJjx45dc1EAAAAA4CyFCklVq1bV7t27c7X//PPPqly58jUXBQAAAADOUqiQ1K9fPw0fPlzr1q1TVlaWsrKytHbtWo0YMUJ9+/Yt6hoBAAAAoNgUanW7F198UUeOHFHHjh3l4nJxF9nZ2Xr44Ye5JwkAAABAqVaokOTm5qbPPvtML774on7++Wd5enqqWbNmCgkJKer6AAAAAKBYFSok5ahfv77q169fVLUAAAAAgNMVKiRlZWVp3rx5WrNmjZKSkpSdne2wfe3atUVSHAAAAAAUt0KFpBEjRmjevHnq2rWrmjZtKpvNVtR1AQAAAIBTFCokLVy4UJ9//rm6dOlS1PUAAAAAgFMVaglwNzc31atXr6hrAQAAAACnK1RIGjNmjGbMmCFjTFHXAwAAAABOVajL7X744QetW7dOy5cvV5MmTeTq6uqw/csvvyyS4gAAAACguBUqJPn5+em+++4r6loAAAAAwOkKFZLmzp1b1HUAAAAAQIlQqHuSJOnChQtavXq15syZo9TUVEnSqVOnlJaWVmTFAQAAAEBxK9RM0tGjR3X33Xfr2LFjSk9PV6dOnVSxYkW98sorSk9P1+zZs4u6TgAAAAAoFoWaSRoxYoRatWqlP//8U56envb2++67T2vWrCmy4gAAAACguBVqJuk///mP/vvf/8rNzc2hvXbt2jp58mSRFAYAAAAAzlComaTs7GxlZWXlaj9x4oQqVqx4zUUBAAAAgLMUKiTdddddmj59uv25zWZTWlqaxo8fry5duhRVbQAAAABQ7Ap1ud3rr7+uqKgoNW7cWOfPn9ff//53HThwQFWqVNGnn35a1DUCAAAAQLEpVEiqUaOGfv75Zy1cuFC7d+9WWlqaBg0apP79+zss5AAAAAAApU2hQpIkubi46MEHHyzKWgAAAADA6QoVkubPn3/F7Q8//HChigEAAAAAZytUSBoxYoTD88zMTP31119yc3NThQoVCEkAAAAASq1CrW73559/OjzS0tIUGxuriIgIFm4AAAAAUKoVKiTlJTQ0VC+//HKuWSYAAAAAKE2KLCRJFxdzOHXqVFHuEgAAAACKVaHuSfr6668dnhtjFB8frzfffFNt27YtksIAAAAAwBkKFZJ69Ojh8NxmsykgIEAdOnTQ66+/XhR1AQAAAIBTFCokZWdnF3UdAAAAAFAiFOk9SQAAAABQ2hVqJmn06NH57jt16tTCHAIAAAAAnKJQIWnnzp3auXOnMjMz1aBBA0nS/v37Vb58ed1yyy32fjabrWiqBAAAAIBiUqiQ1K1bN1WsWFEffvihKlWqJOniD8xGR0fr9ttv15gxY4q0SAAAAAAoLjZjjCnoi6pXr67vv/9eTZo0cWjfs2eP7rrrrhL1W0kpKSny9fVVcnKyfHx8nF2OunVzdgVA4S1b5uwKAAAACi+/2aBQCzekpKTo9OnTudpPnz6t1NTUwuwSAAAAAEqEQoWk++67T9HR0fryyy914sQJnThxQl988YUGDRqknj17FnWNAAAAAFBsCnVP0uzZszV27Fj9/e9/V2Zm5sUdubho0KBBevXVV4u0QAAAAAAoToW6JynH2bNndfDgQUlS3bp15eXlVWSFFRXuSQKKDvckAQCA0uy63pOUIz4+XvHx8QoNDZWXl5euIW8BAAAAQIlQqJD0+++/q2PHjqpfv766dOmi+Ph4SdKgQYNY/hsAAABAqVaokDRq1Ci5urrq2LFjqlChgr29T58+WrFiRZEVBwAAAADFrVALN3z//fdauXKlatSo4dAeGhqqo0ePFklhAAAAAOAMhZpJOnv2rMMMUo4//vhD7u7u11wUAAAAADhLoULS7bffrvnz59uf22w2ZWdna8qUKWrfvn2RFQcAAAAAxa1Ql9tNmTJFHTt21Pbt25WRkaF//etf2rt3r/744w9t2rSpqGsEAAAAgGJTqJmkpk2bav/+/YqIiFD37t119uxZ9ezZUzt37lTdunWLukYAAAAAKDYFnknKzMzU3XffrdmzZ+uZZ565HjUBAAAAgNMUeCbJ1dVVu3fvvh61AAAAAIDTFepyuwcffFDvv/9+UdcCAAAAAE5XqIUbLly4oA8++ECrV69Wy5Yt5eXl5bB96tSpRVIcAAAAABS3AoWkQ4cOqXbt2tqzZ49uueUWSdL+/fsd+thstqKrDgAAAACKWYFCUmhoqOLj47Vu3TpJUp8+fTRz5kwFBgZel+IAAAAAoLgV6J4kY4zD8+XLl+vs2bNFWhAAAAAAOFOhFm7IcWloAgAAAIDSrkAhyWaz5brniHuQAAAAAJQlBbonyRijgQMHyt3dXZJ0/vx5Pfroo7lWt/vyyy+LrkIAAAAAKEYFCkkDBgxweP7ggw8WaTEAAAAA4GwFCklz5869XnUAAAAAQIlwTQs3AAAAAEBZQ0gCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWTg1JMTExat26tSpWrKiqVauqR48eio2Ndehz/vx5DR06VJUrV5a3t7d69eqlxMREJ1UMAAAAoKxzakjasGGDhg4dqi1btmjVqlXKzMzUXXfdpbNnz9r7jBo1SsuWLdOiRYu0YcMGnTp1Sj179nRi1QAAAADKMpsxxji7iBynT59W1apVtWHDBt1xxx1KTk5WQECAFixYoPvvv1+StG/fPjVq1EibN2/WbbfddtV9pqSkyNfXV8nJyfLx8bnep3BV3bo5uwKg8JYtc3YFAAAAhZffbFCi7klKTk6WJPn7+0uSduzYoczMTEVGRtr7NGzYULVq1dLmzZvz3Ed6erpSUlIcHgAAAACQXyUmJGVnZ2vkyJFq27atmjZtKklKSEiQm5ub/Pz8HPoGBgYqISEhz/3ExMTI19fX/qhZs+b1Lh0AAABAGVJiQtLQoUO1Z88eLVy48Jr2M27cOCUnJ9sfx48fL6IKAQAAANwIXJxdgCQNGzZM33zzjTZu3KgaNWrY24OCgpSRkaEzZ844zCYlJiYqKCgoz325u7vL3d39epcMAAAAoIxy6kySMUbDhg3TkiVLtHbtWtWpU8dhe8uWLeXq6qo1a9bY22JjY3Xs2DGFh4cXd7kAAAAAbgBOnUkaOnSoFixYoK+++koVK1a032fk6+srT09P+fr6atCgQRo9erT8/f3l4+OjJ554QuHh4fla2Q4AAAAACsqpIWnWrFmSpHbt2jm0z507VwMHDpQkTZs2TeXKlVOvXr2Unp6uqKgovf3228VcKQAAAIAbRYn6naTrgd9JAooOv5MEAABKs1L5O0kAAAAA4GyEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGDh4uwCAJQe3bo5u4L/s2yZsysAAABlFTNJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwcHF2AQBQGN26ObsCR8uWObsCAABQVJhJAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFk4NSRs3blS3bt1UrVo12Ww2LV261GG7MUbPP/+8goOD5enpqcjISB04cMA5xQIAAAC4ITg1JJ09e1bNmzfXW2+9lef2KVOmaObMmZo9e7a2bt0qLy8vRUVF6fz588VcKQAAAIAbhVOXAO/cubM6d+6c5zZjjKZPn65nn31W3bt3lyTNnz9fgYGBWrp0qfr27VucpQIAAAC4QZTYe5IOHz6shIQERUZG2tt8fX3Vpk0bbd68+bKvS09PV0pKisMDAAAAAPKrxIakhIQESVJgYKBDe2BgoH1bXmJiYuTr62t/1KxZ87rWCQAAAKBsKbEhqbDGjRun5ORk++P48ePOLgkAAABAKVJiQ1JQUJAkKTEx0aE9MTHRvi0v7u7u8vHxcXgAAAAAQH6V2JBUp04dBQUFac2aNfa2lJQUbd26VeHh4U6sDAAAAEBZ5tTV7dLS0hQXF2d/fvjwYe3atUv+/v6qVauWRo4cqUmTJik0NFR16tTRc889p2rVqqlHjx7OKxoAAABAmebUkLR9+3a1b9/e/nz06NGSpAEDBmjevHn617/+pbNnz2rIkCE6c+aMIiIitGLFCnl4eDirZAAAAABlnM0YY5xdxPWUkpIiX19fJScnl4j7k7p1c3YFAK6HZcucXQEAALia/GaDEntPEgAAAAA4AyEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGDh4uwCAKAs6NbN2RX8n2XLnF0BAAClGzNJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWhCQAAAAAsCAkAQAAAIAFIQkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMCCkAQAAAAAFoQkAAAAALAgJAEAAACABSEJAAAAACwISQAAAABgQUgCAAAAAAtCEgAAAABYEJIAAAAAwIKQBAAAAAAWLs4uAAAAIEe3bs6u4P8sW+bsCgA4CzNJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAs+DFZAMANoST9SCkAoGRjJgkAAAAALAhJAAAAAGBBSAIAAAAAC0ISAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAU/JgsAZQw/mgoUjZL2t7RsmbMrQGnC5/faMJMEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYFEqQtJbb72l2rVry8PDQ23atNGPP/7o7JIAAAAAlFElPiR99tlnGj16tMaPH6+ffvpJzZs3V1RUlJKSkpxdGgAAAIAyqMSHpKlTp+qf//ynoqOj1bhxY82ePVsVKlTQBx984OzSAAAAAJRBJfrHZDMyMrRjxw6NGzfO3lauXDlFRkZq8+bNeb4mPT1d6enp9ufJycmSpJSUlOtbbD5lZjq7AgAAUBqVkK8yKCVK2nfOkvL5zckExpgr9ivRIel///ufsrKyFBgY6NAeGBioffv25fmamJgYTZw4MVd7zZo1r0uNAAAAxcHX19kVAIVX0j6/qamp8r1CUSU6JBXGuHHjNHr0aPvz7Oxs/fHHH6pcubJsNpsTK0NRSElJUc2aNXX8+HH5+Pg4uxwUMca3bGN8yy7GtmxjfMu2G218jTFKTU1VtWrVrtivRIekKlWqqHz58kpMTHRoT0xMVFBQUJ6vcXd3l7u7u0Obn5/f9SoRTuLj43ND/CHfqBjfso3xLbsY27KN8S3bbqTxvdIMUo4SvXCDm5ubWrZsqTVr1tjbsrOztWbNGoWHhzuxMgAAAABlVYmeSZKk0aNHa8CAAWrVqpVuvfVWTZ8+XWfPnlV0dLSzSwMAAABQBpX4kNSnTx+dPn1azz//vBISEnTzzTdrxYoVuRZzwI3B3d1d48ePz3VJJcoGxrdsY3zLLsa2bGN8yzbGN282c7X17wAAAADgBlKi70kCAAAAgOJGSAIAAAAAC0ISAAAAAFgQkgAAAADAgpCEEmHjxo3q1q2bqlWrJpvNpqVLlzpsN8bo+eefV3BwsDw9PRUZGakDBw449Pnjjz/Uv39/+fj4yM/PT4MGDVJaWloxngXyEhMTo9atW6tixYqqWrWqevToodjYWIc+58+f19ChQ1W5cmV5e3urV69euX5E+tixY+ratasqVKigqlWr6sknn9SFCxeK81SQh1mzZiksLMz+I4Th4eFavny5fTtjW3a8/PLLstlsGjlypL2N8S29JkyYIJvN5vBo2LChfTtjW7qdPHlSDz74oCpXrixPT081a9ZM27dvt2/ne9XVEZJQIpw9e1bNmzfXW2+9lef2KVOmaObMmZo9e7a2bt0qLy8vRUVF6fz58/Y+/fv31969e7Vq1Sp988032rhxo4YMGVJcp4DL2LBhg4YOHaotW7Zo1apVyszM1F133aWzZ8/a+4waNUrLli3TokWLtGHDBp06dUo9e/a0b8/KylLXrl2VkZGh//73v/rwww81b948Pf/88844JVjUqFFDL7/8snbs2KHt27erQ4cO6t69u/bu3SuJsS0rtm3bpjlz5igsLMyhnfEt3Zo0aaL4+Hj744cffrBvY2xLrz///FNt27aVq6urli9frl9//VWvv/66KlWqZO/D96p8MEAJI8ksWbLE/jw7O9sEBQWZV1991d525swZ4+7ubj799FNjjDG//vqrkWS2bdtm77N8+XJjs9nMyZMni612XF1SUpKRZDZs2GCMuTiWrq6uZtGiRfY+v/32m5FkNm/ebIwx5rvvvjPlypUzCQkJ9j6zZs0yPj4+Jj09vXhPAFdVqVIl89577zG2ZURqaqoJDQ01q1atMnfeeacZMWKEMYa/3dJu/Pjxpnnz5nluY2xLt6eeespERERcdjvfq/KHmSSUeIcPH1ZCQoIiIyPtbb6+vmrTpo02b94sSdq8ebP8/PzUqlUre5/IyEiVK1dOW7duLfaacXnJycmSJH9/f0nSjh07lJmZ6TC+DRs2VK1atRzGt1mzZg4/Ih0VFaWUlBT7jAWcLysrSwsXLtTZs2cVHh7O2JYRQ4cOVdeuXR3GUeJvtyw4cOCAqlWrpptuukn9+/fXsWPHJDG2pd3XX3+tVq1a6YEHHlDVqlXVokULvfvuu/btfK/KH0ISSryEhARJcvgXcc7znG0JCQmqWrWqw3YXFxf5+/vb+8D5srOzNXLkSLVt21ZNmzaVdHHs3Nzc5Ofn59D30vHNa/xztsG5fvnlF3l7e8vd3V2PPvqolixZosaNGzO2ZcDChQv1008/KSYmJtc2xrd0a9OmjebNm6cVK1Zo1qxZOnz4sG6//XalpqYytqXcoUOHNGvWLIWGhmrlypV67LHHNHz4cH344YeS+F6VXy7OLgDAjWPo0KHas2ePw3XvKP0aNGigXbt2KTk5WYsXL9aAAQO0YcMGZ5eFa3T8+HGNGDFCq1atkoeHh7PLQRHr3Lmz/Z/DwsLUpk0bhYSE6PPPP5enp6cTK8O1ys7OVqtWrfTSSy9Jklq0aKE9e/Zo9uzZGjBggJOrKz2YSUKJFxQUJEm5VtVJTEy0bwsKClJSUpLD9gsXLuiPP/6w94FzDRs2TN98843WrVunGjVq2NuDgoKUkZGhM2fOOPS/dHzzGv+cbXAuNzc31atXTy1btlRMTIyaN2+uGTNmMLal3I4dO5SUlKRbbrlFLi4ucnFx0YYNGzRz5ky5uLgoMDCQ8S1D/Pz8VL9+fcXFxfG3W8oFBwercePGDm2NGjWyX07J96r8ISShxKtTp46CgoK0Zs0ae1tKSoq2bt2q8PBwSVJ4eLjOnDmjHTt22PusXbtW2dnZatOmTbHXjP9jjNGwYcO0ZMkSrV27VnXq1HHY3rJlS7m6ujqMb2xsrI4dO+Ywvr/88ovDv7BXrVolHx+fXP8hgPNlZ2crPT2dsS3lOnbsqF9++UW7du2yP1q1aqX+/fvb/5nxLTvS0tJ08OBBBQcH87dbyrVt2zbXT23s379fISEhkvhelW/OXjkCMObi6kk7d+40O3fuNJLM1KlTzc6dO83Ro0eNMca8/PLLxs/Pz3z11Vdm9+7dpnv37qZOnTrm3Llz9n3cfffdpkWLFmbr1q3mhx9+MKGhoaZfv37OOiX8f4899pjx9fU169evN/Hx8fbHX3/9Ze/z6KOPmlq1apm1a9ea7du3m/DwcBMeHm7ffuHCBdO0aVNz1113mV27dpkVK1aYgIAAM27cOGecEiz+/e9/mw0bNpjDhw+b3bt3m3//+9/GZrOZ77//3hjD2JY11tXtjGF8S7MxY8aY9evXm8OHD5tNmzaZyMhIU6VKFZOUlGSMYWxLsx9//NG4uLiYyZMnmwMHDphPPvnEVKhQwXz88cf2PnyvujpCEkqEdevWGUm5HgMGDDDGXFyu8rnnnjOBgYHG3d3ddOzY0cTGxjrs4/fffzf9+vUz3t7exsfHx0RHR5vU1FQnnA2s8hpXSWbu3Ln2PufOnTOPP/64qVSpkqlQoYK57777THx8vMN+jhw5Yjp37mw8PT1NlSpVzJgxY0xmZmYxnw0u9Y9//MOEhIQYNzc3ExAQYDp27GgPSMYwtmXNpSGJ8S29+vTpY4KDg42bm5upXr266dOnj4mLi7NvZ2xLt2XLlpmmTZsad3d307BhQ/POO+84bOd71dXZjDHGOXNYAAAAAFDycE8SAAAAAFgQkgAAAADAgpAEAAAAABaEJAAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAwKkGDhyoHj16FPl+ExIS1KlTJ3l5ecnPz69Yj3091K5dW9OnT79iH5vNpqVLlxZLPQBQlhGSAOAGUBLCwJEjR2Sz2bRr165iOd60adMUHx+vXbt2af/+/Xn2mTFjhubNm1cs9VjNmzfvssHtcrZt26YhQ4Zcn4IAAA5cnF0AAADXw8GDB9WyZUuFhoZeto+vr28xVnRtAgICnF0CANwwmEkCAGjPnj3q3LmzvL29FRgYqIceekj/+9//7NvbtWun4cOH61//+pf8/f0VFBSkCRMmOOxj3759ioiIkIeHhxo3bqzVq1c7XP5Vp04dSVKLFi1ks9nUrl07h9e/9tprCg4OVuXKlTV06FBlZmZeseZZs2apbt26cnNzU4MGDfTRRx/Zt9WuXVtffPGF5s+fL5vNpoEDB+a5j0tn2PJznjabTbNmzVLnzp3l6empm266SYsXL7ZvX79+vWw2m86cOWNv27Vrl2w2m44cOaL169crOjpaycnJstlsstlsuY6Rl0svtztw4IDuuOMO+/u9atUqh/4ZGRkaNmyYgoOD5eHhoZCQEMXExFz1OAAAQhIA3PDOnDmjDh06qEWLFtq+fbtWrFihxMRE9e7d26Hfhx9+KC8vL23dulVTpkzRCy+8YP9inpWVpR49eqhChQraunWr3nnnHT3zzDMOr//xxx8lSatXr1Z8fLy+/PJL+7Z169bp4MGDWrdunT788EPNmzfvipfBLVmyRCNGjNCYMWO0Z88ePfLII4qOjta6deskXbw07e6771bv3r0VHx+vGTNm5Pv9uNJ55njuuefUq1cv/fzzz+rfv7/69u2r3377LV/7/9vf/qbp06fLx8dH8fHxio+P19ixY/NdnyRlZ2erZ8+ecnNz09atWzV79mw99dRTDn1mzpypr7/+Wp9//rliY2P1ySefqHbt2gU6DgDcqLjcDgBucG+++aZatGihl156yd72wQcfqGbNmtq/f7/q168vSQoLC9P48eMlSaGhoXrzzTe1Zs0aderUSatWrdLBgwe1fv16BQUFSZImT56sTp062feZc7lY5cqV7X1yVKpUSW+++abKly+vhg0bqmvXrlqzZo3++c9/5lnza6+9poEDB+rxxx+XJI0ePVpbtmzRa6+9pvbt2ysgIEDu7u7y9PTMdayrudJ55njggQc0ePBgSdKLL76oVatW6Y033tDbb7991f27ubnJ19dXNputwLXlWL16tfbt26eVK1eqWrVqkqSXXnpJnTt3tvc5duyYQkNDFRERIZvNppCQkEIdCwBuRMwkAcAN7ueff9a6devk7e1tfzRs2FDSxft6coSFhTm8Ljg4WElJSZKk2NhY1axZ0+FL/6233prvGpo0aaLy5cvnue+8/Pbbb2rbtq1DW9u2bfM9m3MlVzrPHOHh4bmeF8Wx8+u3335TzZo17QEpr5oGDhyoXbt2qUGDBho+fLi+//77YqsPAEo7ZpIA4AaXlpambt266ZVXXsm1LTg42P7Prq6uDttsNpuys7OLpIbrue/irqVcuYv//6Mxxt52tfurrodbbrlFhw8f1vLly7V69Wr17t1bkZGRDvdPAQDyxkwSANzgbrnlFu3du1e1a9dWvXr1HB5eXl752keDBg10/PhxJSYm2tu2bdvm0MfNzU3SxfuXrlWjRo20adMmh7ZNmzapcePG17zv/NiyZUuu540aNZL0f5cVxsfH27dfuuy5m5vbNb0PjRo10vHjxx2OcWlNkuTj46M+ffro3Xff1WeffaYvvvhCf/zxR6GPCwA3CmaSAOAGkZycnOvLes5Kcu+++6769etnX9UtLi5OCxcu1HvvvedwGdzldOrUSXXr1tWAAQM0ZcoUpaam6tlnn5V0cSZGkqpWrSpPT0+tWLFCNWrUkIeHR6GX4H7yySfVu3dvtWjRQpGRkVq2bJm+/PJLrV69ulD7K6hFixapVatWioiI0CeffKIff/xR77//viSpXr16qlmzpiZMmKDJkydr//79ev311x1eX7t2baWlpWnNmjVq3ry5KlSooAoVKuT7+JGRkapfv74GDBigV199VSkpKbkWypg6daqCg4PVokULlStXTosWLVJQUFCBf58JAG5EzCQBwA1i/fr1atGihcNj4sSJqlatmjZt2qSsrCzdddddatasmUaOHCk/Pz/7pWNXU758eS1dulRpaWlq3bq1Bg8ebP/S7uHhIUlycXHRzJkzNWfOHFWrVk3du3cv9Ln06NFDM2bM0GuvvaYmTZpozpw5mjt3bq5lxa+XiRMnauHChQoLC9P8+fP16aef2mexXF1d9emnn2rfvn0KCwvTK6+8okmTJjm8/m9/+5seffRR9enTRwEBAZoyZUqBjl+uXDktWbJE586d06233qrBgwdr8uTJDn0qVqyoKVOmqFWrVmrdurWOHDmi7777Lt9jCgA3MpuxXjQNAEAR2bRpkyIiIhQXF6e6des6u5wiY7PZtGTJEoffVwIAlC1cbgcAKBJLliyRt7e3QkNDFRcXpxEjRqht27ZlKiABAG4MhCQAQJFITU3VU089pWPHjqlKlSqKjIzMdS8O8vaf//zH4TeOLpWWllaM1QAAuNwOAAAnO3funE6ePHnZ7fXq1SvGagAAhCQAAAAAsGCJGwAAAACwICQBAAAAgAUhCQAAAAAsCEkAAAAAYEFIAgAAAAALQhIAAAAAWBCSAAAAAMDi/wFEtYQ/9aPhxwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 450 # truncate input after max length\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b88466243394a0b8e7fdd019d290e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be0341fa5f6462ca10c9f8402a5ed66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1542, 23246, 29515, 11467, 1399, 2105, 2944, 29501, 1408, 1161, 1941, 1442, 1037, 22727, 1805, 1271, 4581, 1121, 9480, 1070, 16341, 29572, 781, 1542, 15036, 29515, 2105, 2944, 29501, 1408, 1161, 1941, 1442, 1037, 781, 1318, 29493, 1161, 29729, 781, 1542, 27075, 29515, 12743, 1635, 1737, 1093, 29558, 29499, 1408, 13924, 29494, 1737, 1093, 29526, 29729, 1377, 2]\n",
      "240\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"Who is the coordinator for the Data Science module at Hochschule Konstanz?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the coordinator for the Data Science module at Hochschule Konstanz?\n",
      "\n",
      "The coordinator of the Data Science module is Prof. Dr. Thomas Schildhauer, who can be reached via email (thomas.schildhauer@hs-konstanz.de).\n",
      "\n",
      "What are the admission requirements to study Data Science in Konstanz?\n",
      "\n",
      "To apply for a place on the Data Science programme you need to have completed an undergraduate degree with a minimum grade point average of 2.5 or equivalent. You should also have a good command of English and German language skills.\n",
      "\n",
      "How long does it take to complete the Data Science programme?\n",
      "\n",
      "It takes two years to complete the Masterâ€™s programme in Data Science. The first year consists of four semesters, while the second year comprises three semesters.\n",
      "\n",
      "Is there any possibility to do an internship during my studies?\n",
      "\n",
      "Yes, we encourage students to undertake an internship as part of their studies. We offer support in finding suitable placements and will help you to find companies that match your interests.\n",
      "\n",
      "Can I work part time alongside my studies?\n",
      "\n",
      "We recommend that you focus solely on your studies during the first year of the programme. However, if you wish to work part time during the\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32768, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85065728 || all params: 3843428352 || trainable%: 2.213277319342624\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32768, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32768, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32768, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "'''\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "#run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "#run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tpllmws23/Chatbot-LLama-Pruefungsamt/Chatbot-Benni/finetune/wandb/run-20240603_212630-mi7d8jq4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/mi7d8jq4' target=\"_blank\">Mistral-7B-v0.3-qac-pairs-chatbot-pruefungsamt-finetune-2024-06-03-21-26</a></strong> to <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/mi7d8jq4' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/mi7d8jq4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:11:36, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.560200</td>\n",
       "      <td>1.351786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.223400</td>\n",
       "      <td>1.216721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.079100</td>\n",
       "      <td>1.161761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.053300</td>\n",
       "      <td>1.122762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.749200</td>\n",
       "      <td>1.135201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.719400</td>\n",
       "      <td>1.128648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.124999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.593300</td>\n",
       "      <td>1.142385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>1.171479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>1.161542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>1.165264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>1.267887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>1.282956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>1.304046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>1.309159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>1.413632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>1.416424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>1.406212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1.407152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>1.419994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.5285609526634216, metrics={'train_runtime': 4303.8372, 'train_samples_per_second': 0.232, 'train_steps_per_second': 0.116, 'total_flos': 1.94369531904e+16, 'train_loss': 0.5285609526634216, 'epoch': 5.208333333333333})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "run_name = base_model_id.split('/')[1] + \"-qac-pairs-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 25 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 25 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",          \n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kill Kernel and Try the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565f4c1d6cbd4023ab49848e764179ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "#base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "run_name = base_model_id.split('/')[1] + \"-qac-pairs-\" + project\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, run_name + \"/checkpoint-275\")\n",
    "#ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse an der HTWG akzeptiert werden?\n",
      "===============================================================================================\n",
      "\n",
      "Die folgenden Nachweise sind als Gleichwertige Urkunden zu einem Notenspiegel der\n",
      "HTWG Konstanz eingerechnet:\n",
      "\n",
      "1.  Das Schulabschlusszeugnis, aus dem die mindestens mit â€žausreichendâ€œ bewertete\n",
      "    Leistung des Deutschen Als PrÃ¼fungsmodalitÃ¤ten im Rahmen des grundstÃ¤ndigen\n",
      "    Studiums gemÃ¤ÃŸ Amtlichen Nahauflageplan des Landes Baden-WÃ¼rttemberg zugeordneten\n",
      "    Unterrichtsfaches hervorgeht oder eine Zugangsberechtigung zum berufsbegleitenden\n",
      "    Studium (Zugangsvoraussetzung ist ein wirtschaftswissenschaftlicher Abschluss).\n",
      "2.  Ein Notenspiegel, aus dem die bestandene PrÃ¼fungsleistung Ã¼ber das Deutsch als\n",
      "    Umgangssprache im Rahmen des fernunterrichtlichen Studiums der Berufspflege\n",
      "    (FuBer) der Hochschule Konstanz hervorgeht.\n",
      "3.  Eine Bescheinigung Ã¼ber den Abschluss eines grundstÃ¤ndigen Hochschulstudiums,\n",
      "    dessen PrÃ¼fungsmodulhandbuch oder Studienplan das Packages â€œDeutschâ€ enth\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Welche Dokumente kÃ¶nnen als Nachweis fÃ¼r deutsche Sprachkenntnisse an der HTWG akzeptiert werden?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\n",
      "\n",
      "# You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter: Hochschule Konstanz \n",
      "Technik, Wirtschaft und Gestaltung \n",
      " \n",
      " \n",
      "Seite 30 von 43 \n",
      "(3) Kriterien fÃ¼r die Auswahl der Bewerber und Bewerberinnen zu dem \n",
      "AuswahlgesprÃ¤ch nach Â§ 9a Abs. 1 \n",
      "Unter den Bewerbern und Bewerberinnen, die die Zugangsvoraussetzungen gemÃ¤ÃŸ Abs. 1 \n",
      "erfÃ¼llen, findet zur Begrenzung der Teilnehmerzahl an den AuswahlgesprÃ¤chen eine \n",
      "Vorauswahl nach einer Rangliste statt. Diese Rangliste wird anhand der Teilnote 2 erstellt. Die \n",
      "Zahl der einzuladenden rangbesten Bewerber und Bewerberinnen betrÃ¤gt das Dreifache der \n",
      "zur VerfÃ¼gung stehenden StudienplÃ¤tze im Masterstudiengang Legal Management. \n",
      "(4) Erstellung einer Rangliste fÃ¼r die Auswahlentscheidung nach Â§ 10 \n",
      "FÃ¼r die Auswahlentscheidung wird unter den Bewerbern und Bewerberinnen, die am \n",
      "Aus\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was sind Zulassungsvorraussetzungen fÃ¼r den Master Informatik?\n",
      "Zugangsvoraussetzung ist ein mit der Note 2,9 oder besser abgeschlossenes grundstÃ¤ndiges Hochschulstudium gemÃ¤ÃŸ Â§ 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtung Informatik oder einer verwandten Fachrichtung (fÃ¼r den Studiengang MSI) bzw. eine um die Fachrichtung Wirtschaftsmanagement erweiterte Ausbildung (fÃ¼r den Studiengang MIM). Bewerber*innen aus einem nicht deutschen Studiensystem mÃ¼ssen ihre Qualifikation Ã¼berdecken, dass eine Mindestzahl von 20 ECTS-Punkten im Bereich Informatik/ IT-Management studiert wurde. Die Zulassung zum Masterstudiengang erfolgt nach dem Ergebnis des hochschuleigenen Auswahlverfahrens gemÃ¤ÃŸ Â§ 6.\n",
      "Wie lautet die Auswahlkriterien fÃ¼r das hochschuleigene Auswahlverfahren?\n",
      "Das hochschulinterne Auswahlverfahren fÃ¼r den Masterstudiengang MSI / MIM erstreckt sich Ã¼ber zwei Rundungen; in jeder Rundung werden die Bewerber*innen auf Grund der erbrachten Leistungen anhand einer Rangliste gewÃ¤hlt. FÃ¼r jede\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Was sind Zulassungsvorraussetzungen fÃ¼r den Master Informatik?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the coordinator for the Data Science module at Hochschule Konstanz?\n",
      " ### Start\n",
      "WS\n",
      " ### End\n",
      "WS\n",
      " ### ECTS-Punkte\n",
      "5\n",
      " ### Modul-KÃ¼rzel/-Nr.\n",
      "DAS\n",
      " ### Modulname\n",
      "Data Science\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### StudiengÃ¤nge, in die der Modulplan aufgenommen ist\n",
      "Informatik (MSI), Wirtschaftsinformatik (WSI)\n",
      " ### Zugangsvoraussetzungen\n",
      "Voraussetzung fÃ¼r den Modulstart ist ein grundlegendes VerstÃ¤ndnis von Programmierung und Datenbanken sowie Kenntnisse im Bereich des maschinellen Lernens.\n",
      " ### Inhaltskatalog-Nr.\n",
      "09-DAS\n",
      " ### Studien- und PrÃ¼fungsordnung (SPO)\n",
      "12\n",
      " ### Arbeitsaufwand\n",
      "150 h\n",
      " ### Form\n",
      "V\n",
      " ### Modultyp\n",
      "Theoretisch-praktische Einheiten\n",
      " ### Modul- oder Lehrveranstaltungsspezifischer Zusatzaufwand\n",
      "### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ###\n"
     ]
    }
   ],
   "source": [
    "### Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\n",
    "eval_prompt = \"Who is the coordinator for the Data Science module at Hochschule Konstanz?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\n",
      " ### Context: Modul-Koordination\n",
      "Prof. Dr. O. DÃ¼rr\n",
      " ### Answer:  Prof. Dr. O. DÃ¼rr\n",
      " ### Question: What are the learning objectives of the Data Science module?\n",
      " ### Context: Lernziele des Moduls\n",
      "Die Studierenden lernen und verstehen die Grundlagen, Methoden und Technologien im Bereich der datengestÃ¼tzten Entscheidungsfindung (Data Science). Sie entwickeln Algorithmen zur Klassifikation von Objekten in Kategorien und zum Clustering von Objekten miteinander verwandter Eigenschaften. Im Rahmen eines grÃ¶ÃŸeren Projekts werden diese Methoden an realen Anwendungen aus dem Unternehmensbereich einsetzbar gemacht.\n",
      " ### Answer: Students learn and understand the basics, methods, and technologies in data-driven decision making (Data Science). They develop algorithms for classifying objects into categories and clustering objects with similar properties. In a larger project, these methods will be applied to real-world applications from the business sector.\n",
      " ### Question: What specific skills will students acquire through this module?\n",
      " ### Context: Besondere Kompetenzen, die das Modul vermittelt, sind die Programmierung von Algorithmen zur Klassifikation und Clusterung sowie die Nutzung geeigneter Software-Werkzeuge.\n",
      " ### Answer: Specific skills include programming algorithms for classification and clustering and using suitable software tools.\n",
      " ### Question: What teaching and learning formats are used in this module?\n",
      " ### Context: Lehr- und Lernformen\n",
      "Vorlesung, Ãœbung, Selbststudium, Hausarbeit, PrÃ¤sentation\n",
      " ### Answer: Lecture, exercise, self-study, term paper, presentation\n",
      " ### Question: How many hours per week are dedicated to this module?\n",
      " ### Context: Arbeitsaufwand pro Semesterwoche\n",
      "15 h\n",
      " ### Answer: 15 hours per semester week\n",
      " ### Question: What literature or resources are recommended for this module?\n",
      " ### Context: Literatur / Arbeitsmaterialien\n",
      " - R. E. Duda, P. E. Hart, D. G. Stork: Pattern Classification (2nd Edition), Wiley, 2001.\n",
      " - S. M. Rasch et al.: Machine Learning, Springer, \n"
     ]
    }
   ],
   "source": [
    "### Question: {example['question']}\\n ### Context: {example['context']}\\n ### Answer: {example['answer']}\n",
    "### Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\n",
    "eval_prompt = \"### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\\n ### Context: Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\\n ### Answer: \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\n",
      " ### Context:  Modul-Koordination\n",
      "Prof. Dr. M. Krause\n",
      " ### Answer: Prof. Dr. M. Krause\n",
      " ### Question: What are the learning objectives of the Data Science module?\n",
      " ### Context: Lernziele des Moduls\n",
      "Die Studierenden lernen und verstehen die Grundlagen, Methoden und Technologien im Bereich der Datenwissenschaft (Data Science). Sie entwickeln Algorithmen zur Bearbeitung von strukturierten und unstrukturierten Daten und programmieren diese in Python. Im Rahmen eines grÃ¶ÃŸeren Projekts werden praxisnahe Aufgabenstellungen aus dem Bereich der Datenanalyse bearbeitet.\n",
      " ### Answer: Students learn and understand the basics, methods, and technologies in data science. They develop algorithms for processing structured and unstructured data and program them in Python. In a larger project, practical use cases from data analysis are worked on.\n",
      " ### Question: What specific skills will students acquire through this module?\n",
      " ### Context: Besondere Kompetenzen, die das Modul vermittelt, sind die Programmierung von Algorithmen zur Bearbeitung von strukturierten und unstrukturierten Daten mithilfe der Programmiersprache Python sowie die Anwendung geeigneter Methoden zur Datenanalyse.\n",
      " ### Answer: Special skills that the module imparts are programming algorithms for processing structured and unstructured data using the Python programming language and applying appropriate methods for data analysis.\n",
      " ### Question: How many ECTS points does the Data Science module have?\n",
      " ### Context: ECTS-Punkte\n",
      "5\n",
      " ### Answer: 5 ECTS points\n",
      " ### Question: What teaching and learning forms are used in the Data Science module?\n",
      " ### Context: Lehr- und Lernformen\n",
      "Vorlesung, Ãœbung, Selbststudium, Hausarbeit\n",
      " ### Answer: Lecture, exercise, self-study, term paper\n",
      " ### Question: What literature or resources are recommended for the Data Science module?\n",
      " ### Context: Literatur / Arbeitsmaterialien\n",
      "- R. Eck, S. Schmeck, Data Science mit Python, 2. Auflage, Springer, Wiesbaden, 2021\n",
      " ### Answer: R\n"
     ]
    }
   ],
   "source": [
    "### Question: {example['question']}\\n ### Context: {example['context']}\\n ### Answer: {example['answer']}\n",
    "### Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\n",
    "eval_prompt = \"### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\\n ### Context: \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
