{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bitsandbytes\n",
    "#!pip install git+https://github.com/huggingface/transformers.git\n",
    "#!pip install git+https://github.com/huggingface/peft.git\n",
    "#!pip install git+https://github.com/huggingface/accelerate.git\n",
    "#!pip install datasets scipy ipywidgets matplotlib\n",
    "#!pip install sentencepiece\n",
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trl\n",
    "#!pip install flash-attn --no-build-isolation  # -> needs CUDA 11.6 or newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"datasets/chatbot-qac-pairs/\"\n",
    "\n",
    "train_dataset = load_dataset('json', data_files=f'{dataset_path}train.json', split='train') #need to split as it will otherwise create a nested object\n",
    "eval_dataset = load_dataset('json', data_files=f'{dataset_path}validation.json', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'context'],\n",
       "    num_rows: 192\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenjaminbruenau\u001b[0m (\u001b[33mteamprojekt-chatbot-pruefungsamt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"teamprojekt-chatbot-pruefungsamt\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    system_prompt = \"You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. Always return the source of an information and it is mandatory to answer in GERMAN:\\n\\n\"\n",
    "    \n",
    "    text = f\"[INST]{system_prompt} Context: {example['context']}\\n\\nQuestion: {example['question']} [/INST]{example['answer']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n pip install huggingface_hub[\"cli\"]\\nhuggingface-cli delete-cache\\nhuggingface-cli login\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# only necessary if model is not cached\n",
    "#notebook_login()\n",
    "\n",
    "'''\n",
    " pip install huggingface_hub[\"cli\"]\n",
    "huggingface-cli delete-cache\n",
    "huggingface-cli login\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7023b2a09d4748907952eaacb275a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b5542d7d664d90b99c2b723aa07850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834352c1b5714bb091c1d92a53a0f2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 350 # truncate input after max length\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7177e5840c14cbeaeab7204a9fc8475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a06f01d70f4bd59381a5efb1b51307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2744, 1228, 1032, 8223, 11633, 14660, 1122, 1040, 8028, 29548, 29545, 9062, 1071, 5647, 29491, 27075, 1040, 3064, 3764, 3586, 1633, 1124, 1040, 4625, 3526, 29491, 18252, 1372, 1040, 3600, 1070, 1164, 2639, 1072, 1146, 1117, 27500, 1066, 5140, 1065, 1188, 1493, 17125, 29515, 781, 781, 15036, 29515, 2105, 2944, 29501, 1408, 1161, 1941, 1442, 1037, 781, 1318, 29493, 1161, 29729, 781, 781, 25762, 29515, 11467, 1399, 2105, 2944, 29501, 1408, 1161, 1941, 1442, 1037, 22727, 1805, 1271, 4581, 1121, 9480, 1070, 16341, 29572, 29473, 4, 29558, 1039, 1635, 1737, 1093, 29558, 29499, 1408, 13924, 29494, 1737, 1093, 29526, 29729, 1377, 2]\n",
      "240\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[INST]You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\\n\\n Context: Modul-Koordination\\nProf. Dr. O. Dürr\\n\\nQuestion: Who is the coordinator for the Data Science module at Hochschule Konstanz? [/INST]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_eval_prompt(query: str, context: str):\n",
    "    system_prompt = \"You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\\n\\n\"\n",
    "    return f\"[INST]{system_prompt} Context: {context}\\n\\nQuestion: {query} [/INST]\"\n",
    "\n",
    "eval_prompt = create_eval_prompt(\"\"\"Who is the coordinator for the Data Science module at Hochschule Konstanz?\"\"\", \"Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\")\n",
    "eval_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\n",
      "\n",
      " Context: Modul-Koordination\n",
      "Prof. Dr. O. Dürr\n",
      "\n",
      "Question: Who is the coordinator for the Data Science module at Hochschule Konstanz? \n",
      "\n",
      "Answer: Prof. Dr. O. Dürr is the coordinator for the Data Science module at Hochschule Konstanz.\n",
      "\n",
      "Context: Modul-Koordination\n",
      "Prof. Dr. O. Dürr\n",
      "\n",
      "Question: What is the name of the person who coordinates the Data Science module at Hochschule Konstanz?  */\n",
      "\n",
      "Answer: The name of the person who coordinates the Data Science module at Hochschule Konstanz is Prof. Dr. O. Dürr.\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32768, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85065728 || all params: 3843428352 || trainable%: 2.213277319342624\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32768, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32768, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32768, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "'''\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "#run_name = base_model_id.split('/')[1] + \"-\" + project\n",
    "#run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tpllmws23/Chatbot-LLama-Pruefungsamt/Chatbot-Benni/finetune/wandb/run-20240616_131034-wfb9tdca</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/wfb9tdca' target=\"_blank\">Mistral-7B-v0.3-qac-pairs-chatbot-pruefungsamt-finetune-2024-06-16-13-10</a></strong> to <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/wfb9tdca' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/wfb9tdca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:00:59, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.521700</td>\n",
       "      <td>1.140460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.989500</td>\n",
       "      <td>1.039416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.909900</td>\n",
       "      <td>0.957878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>0.913386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.593500</td>\n",
       "      <td>0.898620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.555700</td>\n",
       "      <td>0.881247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.524900</td>\n",
       "      <td>0.855541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.444800</td>\n",
       "      <td>0.898419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.880127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.888522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.890898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.980841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.972381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.964950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>1.070111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>1.101852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>1.067110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>1.064095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>1.079546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tpllmws23/environments/finetuning/lib/python3.11/site-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.42889022970199586, metrics={'train_runtime': 3665.3754, 'train_samples_per_second': 0.273, 'train_steps_per_second': 0.136, 'total_flos': 1.51176302592e+16, 'train_loss': 0.42889022970199586, 'epoch': 5.208333333333333})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "#base_model_name = \"mistral\"\n",
    "run_name = base_model_id.split('/')[1] + \"-qac-pairs-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 25 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 25 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",          \n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81026e41072423788d335960a10280b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▄▂▂▂▁▂▂▂▂▄▄▄▄▆▇▆▆▇</td></tr><tr><td>eval/runtime</td><td>▂▆▂▆▇█▄▇▆▂▃▁▁▂▃▂▆▇▅▇</td></tr><tr><td>eval/samples_per_second</td><td>▇▂▇▃▂▁▅▂▂▇▆██▆▅▇▃▂▃▂</td></tr><tr><td>eval/steps_per_second</td><td>▇▃▇▃▂▁▅▂▂▇▆██▆▆▇▃▂▃▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▄▃▃▃▂▃▅▄▄███▄▃█▂▁▂▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▄▃▃▃▂▂▂▂▁▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.07955</td></tr><tr><td>eval/runtime</td><td>41.468</td></tr><tr><td>eval/samples_per_second</td><td>1.158</td></tr><tr><td>eval/steps_per_second</td><td>0.145</td></tr><tr><td>total_flos</td><td>1.51176302592e+16</td></tr><tr><td>train/epoch</td><td>5.20833</td></tr><tr><td>train/global_step</td><td>500</td></tr><tr><td>train/grad_norm</td><td>3.22554</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0707</td></tr><tr><td>train_loss</td><td>0.42889</td></tr><tr><td>train_runtime</td><td>3665.3754</td></tr><tr><td>train_samples_per_second</td><td>0.273</td></tr><tr><td>train_steps_per_second</td><td>0.136</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Mistral-7B-v0.3-qac-pairs-chatbot-pruefungsamt-finetune-2024-06-16-13-10</strong> at: <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/wfb9tdca' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt/runs/wfb9tdca</a><br/> View project at: <a href='https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt' target=\"_blank\">https://wandb.ai/teamprojekt-chatbot-pruefungsamt/teamprojekt-chatbot-pruefungsamt</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240616_131034-wfb9tdca/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kill Kernel and Try the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7b50f92c82410c9a135325a92bf5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "#base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "#project = \"chatbot-pruefungsamt-finetune\"\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "project = \"chatbot-pruefungsamt-finetune\"\n",
    "run_name = base_model_id.split('/')[1] + \"-qac-pairs-\" + project\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, './finetune_runs/'+run_name + \"/checkpoint-25\")\n",
    "#ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_prompt(query: str, context: str):\n",
    "    system_prompt = \"You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\\n\\n\"\n",
    "    return f\"[INST]{system_prompt} Context: {context}\\n\\nQuestion: {query} [/INST]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\n",
      "\n",
      " Context: Modul-Koordination\n",
      "Prof. Dr. O. Dürr\n",
      "\n",
      "Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?  򐁀 򐃟 򐂕 򐂖 򐂗 򐂘 򐂙 򐂚 򐂛 򐂜 򐂝 򐂞 򐂟 򐂠 򐂡 򐂢 򐂣 򐂤 򐂥 򐂦 򐂧 򐂨 򐂩 򐂪 򐂫 򐂬 򐂭 򐂮 򐂯 򐂰 򐂱 򐂲 򐂳 򐂴 򐂵 򐂶 򐂷 򐂸 򐂹 򐂺 򐂻 򐂼 򐂽 򐂾 򐂿\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = create_eval_prompt(\"\"\"Who is the coordinator for the Data Science module at Hochschule Konstanz?\"\"\", \"Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\")\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\n",
      "\n",
      " Context: \n",
      "\n",
      "Question: Who is the coordinator for the Data Science module at Hochschule Konstanz? Prof. Dr. M. Koch, koch@hs-konstanz.de. ↩\n",
      "\n",
      "Answer: Prof. Dr. M. Koch, koch@hs-konstanz.de. ↩\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = create_eval_prompt(\"\"\"Who is the coordinator for the Data Science module at Hochschule Konstanz?\"\"\", \"\")\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart helpful assistant for the HTWG Konstanz. Answer the following question based only on the provided context. It is mandatory to answer in GERMAN:\n",
      "\n",
      " Context: Fachliche Kompetenzen\n",
      "- Die Studierenden kennen die Grundbegriffe der Optik; sie können einfache optische Systeme\n",
      "konstruktiv und rechnerisch bewerten.\n",
      "\n",
      "Question: Welches Hauptziel verfolgt das Modul 'Optik und bildgebende optische Systeme' bezüglich der fachlichen Kompetenzen? Das Ziel ist, dass die Studierenden die Grundbegriffe der Optik kennen und einfache optische Systeme konstruktiv und rechnerisch bewerten können. Das Modul richtet sich an Studierende des Masterstudiengangs Informatik (MSI) und des Masterstudiengangs Wirtschaftsinformatik (MWI). Für den MSI gilt, dass die Studierenden auch die theoretischen Grundlagen der Bildverarbeitung kennen und diese mit Hilfe von Programmiersprachen umsetzen können. Für den MWI gilt, dass die Studierenden auch die theoretischen Grundlagen der Bildverarbeitung kennen und diese mit Hilfe von Programmiersprachen umsetzen können.|\n",
      "\n",
      "Answer: Das Ziel ist, dass die Studierenden die Grundbegriffe der Optik kennen und einfache optische Systeme konstruktiv und rechnerisch bewerten können. Das Modul richtet sich an Studierende des Masterstudiengangs Informatik (MSI) und des Masterstudiengangs Wirtschaftsinformatik (MWI). Für den MSI gilt, dass die Studierenden auch die theoretischen Grundlagen der Bildverarbeitung kennen und diese mit Hilfe von Programmiersprachen umsetzen können. Für den MWI g\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = create_eval_prompt(\"\"\"Welches Hauptziel verfolgt das Modul 'Optik und bildgebende optische Systeme' bez\\u00fcglich der fachlichen Kompetenzen?\"\"\", \"Fachliche Kompetenzen\\n- Die Studierenden kennen die Grundbegriffe der Optik; sie k\\u00f6nnen einfache optische Systeme\\nkonstruktiv und rechnerisch bewerten.\")\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\n",
      "\n",
      "# You are a smart helpful assistant for the HTWG Konstanz. You answer any question about the document copyed hereafter: Hochschule Konstanz \n",
      "Technik, Wirtschaft und Gestaltung \n",
      " \n",
      " \n",
      "Seite 30 von 43 \n",
      "(3) Kriterien für die Auswahl der Bewerber und Bewerberinnen zu dem \n",
      "Auswahlgespräch nach § 9a Abs. 1 \n",
      "Unter den Bewerbern und Bewerberinnen, die die Zugangsvoraussetzungen gemäß Abs. 1 \n",
      "erfüllen, findet zur Begrenzung der Teilnehmerzahl an den Auswahlgesprächen eine \n",
      "Vorauswahl nach einer Rangliste statt. Diese Rangliste wird anhand der Teilnote 2 erstellt. Die \n",
      "Zahl der einzuladenden rangbesten Bewerber und Bewerberinnen beträgt das Dreifache der \n",
      "zur Verfügung stehenden Studienplätze im Masterstudiengang Legal Management. \n",
      "(4) Erstellung einer Rangliste für die Auswahlentscheidung nach § 10 \n",
      "Für die Auswahlentscheidung wird unter den Bewerbern und Bewerberinnen, die am \n",
      "Aus\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Hilfe, ich habe eine Klausur nicht bestanden! Was kann ich tun?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was sind Zulassungsvorraussetzungen für den Master Informatik?\n",
      "Zugangsvoraussetzung ist ein mit der Note 2,9 oder besser abgeschlossenes grundständiges Hochschulstudium gemäß § 5 Abs. 1 Nr. 1 in einem Studiengang der Fachrichtung Informatik oder einer verwandten Fachrichtung (für den Studiengang MSI) bzw. eine um die Fachrichtung Wirtschaftsmanagement erweiterte Ausbildung (für den Studiengang MIM). Bewerber*innen aus einem nicht deutschen Studiensystem müssen ihre Qualifikation überdecken, dass eine Mindestzahl von 20 ECTS-Punkten im Bereich Informatik/ IT-Management studiert wurde. Die Zulassung zum Masterstudiengang erfolgt nach dem Ergebnis des hochschuleigenen Auswahlverfahrens gemäß § 6.\n",
      "Wie lautet die Auswahlkriterien für das hochschuleigene Auswahlverfahren?\n",
      "Das hochschulinterne Auswahlverfahren für den Masterstudiengang MSI / MIM erstreckt sich über zwei Rundungen; in jeder Rundung werden die Bewerber*innen auf Grund der erbrachten Leistungen anhand einer Rangliste gewählt. Für jede\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Was sind Zulassungsvorraussetzungen für den Master Informatik?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the coordinator for the Data Science module at Hochschule Konstanz?\n",
      " ### Start\n",
      "WS\n",
      " ### End\n",
      "WS\n",
      " ### ECTS-Punkte\n",
      "5\n",
      " ### Modul-Kürzel/-Nr.\n",
      "DAS\n",
      " ### Modulname\n",
      "Data Science\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Studiengänge, in die der Modulplan aufgenommen ist\n",
      "Informatik (MSI), Wirtschaftsinformatik (WSI)\n",
      " ### Zugangsvoraussetzungen\n",
      "Voraussetzung für den Modulstart ist ein grundlegendes Verständnis von Programmierung und Datenbanken sowie Kenntnisse im Bereich des maschinellen Lernens.\n",
      " ### Inhaltskatalog-Nr.\n",
      "09-DAS\n",
      " ### Studien- und Prüfungsordnung (SPO)\n",
      "12\n",
      " ### Arbeitsaufwand\n",
      "150 h\n",
      " ### Form\n",
      "V\n",
      " ### Modultyp\n",
      "Theoretisch-praktische Einheiten\n",
      " ### Modul- oder Lehrveranstaltungsspezifischer Zusatzaufwand\n",
      "### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ### Modul- bzw. Lehrveranstaltungsart\n",
      "Modul\n",
      " ###\n"
     ]
    }
   ],
   "source": [
    "### Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\n",
    "eval_prompt = \"Who is the coordinator for the Data Science module at Hochschule Konstanz?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\n",
      " ### Context: Modul-Koordination\n",
      "Prof. Dr. O. Dürr\n",
      " ### Answer:  Prof. Dr. O. Dürr\n",
      " ### Question: What are the learning objectives of the Data Science module?\n",
      " ### Context: Lernziele des Moduls\n",
      "Die Studierenden lernen und verstehen die Grundlagen, Methoden und Technologien im Bereich der datengestützten Entscheidungsfindung (Data Science). Sie entwickeln Algorithmen zur Klassifikation von Objekten in Kategorien und zum Clustering von Objekten miteinander verwandter Eigenschaften. Im Rahmen eines größeren Projekts werden diese Methoden an realen Anwendungen aus dem Unternehmensbereich einsetzbar gemacht.\n",
      " ### Answer: Students learn and understand the basics, methods, and technologies in data-driven decision making (Data Science). They develop algorithms for classifying objects into categories and clustering objects with similar properties. In a larger project, these methods will be applied to real-world applications from the business sector.\n",
      " ### Question: What specific skills will students acquire through this module?\n",
      " ### Context: Besondere Kompetenzen, die das Modul vermittelt, sind die Programmierung von Algorithmen zur Klassifikation und Clusterung sowie die Nutzung geeigneter Software-Werkzeuge.\n",
      " ### Answer: Specific skills include programming algorithms for classification and clustering and using suitable software tools.\n",
      " ### Question: What teaching and learning formats are used in this module?\n",
      " ### Context: Lehr- und Lernformen\n",
      "Vorlesung, Übung, Selbststudium, Hausarbeit, Präsentation\n",
      " ### Answer: Lecture, exercise, self-study, term paper, presentation\n",
      " ### Question: How many hours per week are dedicated to this module?\n",
      " ### Context: Arbeitsaufwand pro Semesterwoche\n",
      "15 h\n",
      " ### Answer: 15 hours per semester week\n",
      " ### Question: What literature or resources are recommended for this module?\n",
      " ### Context: Literatur / Arbeitsmaterialien\n",
      " - R. E. Duda, P. E. Hart, D. G. Stork: Pattern Classification (2nd Edition), Wiley, 2001.\n",
      " - S. M. Rasch et al.: Machine Learning, Springer, \n"
     ]
    }
   ],
   "source": [
    "### Question: {example['question']}\\n ### Context: {example['context']}\\n ### Answer: {example['answer']}\n",
    "### Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\n",
    "eval_prompt = \"### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\\n ### Context: Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\\n ### Answer: \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\n",
      " ### Context:  Modul-Koordination\n",
      "Prof. Dr. M. Krause\n",
      " ### Answer: Prof. Dr. M. Krause\n",
      " ### Question: What are the learning objectives of the Data Science module?\n",
      " ### Context: Lernziele des Moduls\n",
      "Die Studierenden lernen und verstehen die Grundlagen, Methoden und Technologien im Bereich der Datenwissenschaft (Data Science). Sie entwickeln Algorithmen zur Bearbeitung von strukturierten und unstrukturierten Daten und programmieren diese in Python. Im Rahmen eines größeren Projekts werden praxisnahe Aufgabenstellungen aus dem Bereich der Datenanalyse bearbeitet.\n",
      " ### Answer: Students learn and understand the basics, methods, and technologies in data science. They develop algorithms for processing structured and unstructured data and program them in Python. In a larger project, practical use cases from data analysis are worked on.\n",
      " ### Question: What specific skills will students acquire through this module?\n",
      " ### Context: Besondere Kompetenzen, die das Modul vermittelt, sind die Programmierung von Algorithmen zur Bearbeitung von strukturierten und unstrukturierten Daten mithilfe der Programmiersprache Python sowie die Anwendung geeigneter Methoden zur Datenanalyse.\n",
      " ### Answer: Special skills that the module imparts are programming algorithms for processing structured and unstructured data using the Python programming language and applying appropriate methods for data analysis.\n",
      " ### Question: How many ECTS points does the Data Science module have?\n",
      " ### Context: ECTS-Punkte\n",
      "5\n",
      " ### Answer: 5 ECTS points\n",
      " ### Question: What teaching and learning forms are used in the Data Science module?\n",
      " ### Context: Lehr- und Lernformen\n",
      "Vorlesung, Übung, Selbststudium, Hausarbeit\n",
      " ### Answer: Lecture, exercise, self-study, term paper\n",
      " ### Question: What literature or resources are recommended for the Data Science module?\n",
      " ### Context: Literatur / Arbeitsmaterialien\n",
      "- R. Eck, S. Schmeck, Data Science mit Python, 2. Auflage, Springer, Wiesbaden, 2021\n",
      " ### Answer: R\n"
     ]
    }
   ],
   "source": [
    "### Question: {example['question']}\\n ### Context: {example['context']}\\n ### Answer: {example['answer']}\n",
    "### Modul-Koordination\\nProf. Dr. O. D\\u00fcrr\n",
    "eval_prompt = \"### Question: Who is the coordinator for the Data Science module at Hochschule Konstanz?\\n ### Context: \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=500, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
